2019,broom open-source out-of-order processor resilient low-voltage operation 28-nm cmos,berkeley resilient out-of-order machine  resilient wide-voltage-range implementation open-source out-of-order  risc-v processor implemented asic flow -nm test-chip contains boom ooo core -mib level-  cache enhanced architectural error tolerance low-voltage operation implemented using agile design methodology initial ooo architecture transformed perform well high-performance low-leakage cmos process informed synthesis place route data using foundry-provided standard-cell library memory compiler two-person-team productivity improved part thanks number open-source artifact chisel hardware construction language risc-v instruction set architecture rocket-chip soc generator open-source boom core resulting chip taped using tsmcs -nm hpm process run  ghz  v able operate  v
2019,fpga accelerated indel realignment cloud,amount data generated genomics predicted   exabyte per year next decade making genomic analysis new frontier new challenge precision medicine paper explores targeted deployment hardware accelerator cloud improve runtime throughput immensescale genomic data analysis particular indel  realignment critical operation enables diagnostic testing cancer error correction prior variant calling slowest part somatic  genomic analysis pipeline alignment refinement pipeline represents roughly one-third execution time timesensitive diagnostics acute cancer patient accelerate genomic analysis paper describes hardware accelerator indel realignment  hardware-software framework leveraging fpgas-as-a-service cloud chose implement genomics analytics fpgas genomic algorithm still rapidly evolving  chose deploy genomics accelerator cloud reduce capital expenditure provide quantitative performance cost analysis built deployed sea ir accelerator using hardware-software accelerator development framework aws ec f instance show ir accelerator system performed × better multi-threaded genomic analysis software × cost efficient
2018,new golden age computer architecture empowering machine-learning revolution,end moore law dennard scaling led end rapid improvement general-purpose program performance machine learning  particular deep learning attractive alternative architect explore recently revolutionized vision speech language understanding many field promise help grand challenge facing society computation core low-precision linear algebra thus ml broad enough apply many domain narrow enough benefit domain-specific architecture google tensor processing unit  moreover growth demand ml computing exceeds moore law peak fading hence ml expert computer architect must work together design computing system required deliver potential ml article offer motivation suggestion warning computer architect best contribute ml revolution
2018,motivation evaluation first tensor processing unit,first-generation tensor processing unit  run deep neural network  inference - time faster - time better energy efficiency contemporary cpu gpus similar semiconductor technology domain-specific architecture  custom chip deployed google datacenters since  serf billion people
2018,50 year computer architecture mainframe cpu domain-specific tpu open risc-v instruction set,ibm four incompatible computer line unique instruction-set architecture  i/o system system software  market niche  ibm engineer bet could invent single isa would work customer four line moreover program would run correctly implementation isa though different speed cost vision required new way build computer would binary compatible cheapest -bit model fastest -bit version
2018,out-of-order risc-v processor resilient low-voltage operation 28nm cmos,open-source out-of-order superscalar processor implement -bit risc-v instruction set architecture  achieves  coremark/mhz  mm× mm chip includes one core operating  ghz nominal  v  mb level-  cache  nm hpm process line recycling  technique reuses faulty cache line fail low voltage correct error  l area overhead lr reduces minimum operating voltage  v improving energy efficiency  negligible impact cpi
2017,reduced instruction set computer,widely cited computer article published  described reduced instruction set computer  alternative general trend time toward increasingly complex instruction set risc executes instruction single short cycle
2017,reducing pagerank communication via propagation blocking,reducing communication important objective save energy improve performance communication-bound application graph algorithm pagerank computes importance vertex graph serf important benchmark graph algorithm performance input graph pagerank poor locality execution need read many cache line memory may fully utilized present propagation blocking optimization improve spatial locality demonstrate application pagerank contrast cache blocking partition graph partition data transfer vertex  input graph poor locality approach reduce communication approach reduces communication conventional cache blocking input graph sufficiently sparse number vertex sufficiently large relative cache size evaluate approach use simple analytic model gain insight precise hardware performance counter measurement compare implementation suite  real-world synthetic graph demonstrate parallel implementation substantially outperform prior work execution time communication volume although present  pagerank propagation blocking could generalized spmv  graph programming model
2017,in-datacenter performance analysis tensor processing unit,many architect believe major improvement cost-energy-performance must come domain-specific hardware paper evaluates custom asic-called tensor processing unit -deployed datacenters since  accelerates inference phase neural network  heart tpu  -bit mac matrix multiply unit offer peak throughput  teraops/second  large  software-managed on-chip memory tpus deterministic execution model better match th-percentile response-time requirement nn application time-varying optimization cpu gpus help average throughput guaranteed latency lack feature help explain despite myriad mac big memory tpu relatively small low power compare tpu server-class intel haswell cpu nvidia k gpu contemporary deployed datacenters workload written high-level tensorflow framework us production nn application  represent  datacenters nn inference demand despite low utilization application tpu average xx faster contemporary gpu cpu tops/watt xx higher moreover using gpus gddr memory tpu would triple achieved top raise tops/watt nearly x gpu x cpu
2016,genap distributed sql interface genomic data,impressively low cost improved quality genome sequencing provides researcher genetic disease cancer powerful tool better understand underlying genetic mechanism disease treat effective targeted therapy thus number project today sequence dna large patient population produce least hundred terra-bytes data challenge provide produced data demand interested partiesin paper show response challenge modified version spark sql distributed sql execution engine handle efficiently join use genomic interval key modification spark sql serf join  faster existing brute force approach  faster similar distributed implementation thus spark sql replace existing practice retrieve genomic data show allow user reduce number line software code need developed query data order magnitude
2016,agile approach building risc-v microprocessor,final phase cmos technology scaling provides continued increase already vast transistor count minimal improvement energy efficiency thus requiring innovation circuit architecture however even huge team struggling complete large complex design schedule using traditional rigid development flow article present agile hardware development methodology author adopted  risc-v microprocessor tape-outs modern -nm -nm cmos process past five year author discus approach enabled small team build energy-efficient cost-effective industry-competitive high-performance microprocessor matter month agile methodology relies rapid iterative improvement fabricatable prototype using hardware generator written chisel new hardware description language embedded modern programming language parameterized generator construct highly customized system based free open extensible risc-v platform author present case study one prototype featuring risc-v vector microprocessor integrated switched-capacitor dc-dc converter alongside adaptive clock generator -nm fully depleted silicon-on-insulator process
2016,proprietary versus open instruction set,article present position statement question-and-answer session panelist th workshop computer architecture research direction subject debate proprietary versus free open instruction set architecture
2015,do-it-yourself textbook publishing,comparing experience publishing textbook using traditional publisher do-it-yourself method
2015,nih bd2k center big data translational genomics,world genomics data never stored single repository  rather distributed among many site many country one site enough data explain genotype phenotype relationship rare disease therefore site must share data accomplish genetics community must forge common standard protocol make sharing computing data among many site seamless activity global alliance genomics health pioneering development shared application programming interface  connect world genome repository parallel developing open source software stack  us apis combination create cohesive genome informatics ecosystem using container facilitating deployment software diverse array environment benchmarking effort big data driver project ensuring adam performance utility
2015,diablo warehouse-scale computer network simulator using fpgas,motivated rapid software hardware innovation warehouse-scale computing  visit problem warehouse-scale network design evaluation wsc composed  array cluster contains  server leading total  server per wsc found many prior experiment conducted relatively small physical testbeds often assume workload static computation loosely coupled adaptive networking stack present novel cost-efficient fpgabased evaluation methodology called datacenter-in-a-box low cost  treat array whole computer tightly integrated hardware software built -node prototype running full wsc software stack using prototype successfully reproduced wsc phenomenon tcp incast memcached request latency long tail found  indeed change scale version full software stack
2015,scientific computing meet big data technology astronomy use case,scientific analysis commonly compose multiple single-process program dataflow end-to-end dataflow single-process program known many-task application typically tool hpc software stack used parallelize analysis work investigate alternate approach us apache spark - modern big data platform - parallelize many-task application present kira flexible distributed astronomy image processing toolkit using apache spark use kira toolkit implement source extractor application astronomy image called kira se kira se use case study programming flexibility dataflow richness scheduling capacity performance apache spark running ec cloud exploiting data locality kira se achieves  χ speedup equivalent c program analyzing tb dataset using  core amazon ec cloud furthermore show leveraging software originally designed big data infrastructure kira se achieves competitive performance c implementation running nersc edison supercomputer experience kira indicates emerging big data platform apache spark performant alternative many-task scientific application
2015,magic massive automated grading cloud,describe experience developing using specific category cloud-based autograder  software engineering establish position landscape autograder fully automatic rather assisting instructor performing manual grading test based exercise student code controlled condition rather relying static analysis comparing output student program reference output include brief description course autograders built engineering software service rationale building first place since surmount new obstacle related scale delivery mechanism course three year using autograders conjunction software engineering mooc residential course mooc based reliably graded hundred thousand student assignment currently refactored make code easily extensible maintainable found cloud-based autograding scalable sandboxable reliable student value near-instant feedback opportunity resubmit homework assignment autograder architecture implementation open source cloud-based lms-agnostic easily extensible new type grading engine goal make specific research claim behalf system extract experience engineering lesson others interested building adapting similar system
2015,locality exists graph processing workload characterization ivy bridge server,graph processing increasingly important application domain typically communication-bound work analyze performance characteristic three high-performance graph algorithm codebases using hardware performance counter conventional dual-socket server unlike many communication-bound workload graph algorithm struggle fully utilize platform memory bandwidth increasing memory bandwidth utilization could effective decreasing communication based observation simultaneous low compute bandwidth utilization find substantial room different processor architecture improve performance without requiring new memory system
2015,gail graph algorithm iron law,new application graph algorithm emerge great deal research interest improving graph processing however often difficult understand new contribution improve performance execution time commonly reported metric distinguishes alternative fastest give insight new contribution may algorithmic innovation allows examine fewer graph edge could also implementation optimization reduces communication could even optimization allow increase memory bandwidth utilization interestingly new innovation may simultaneously affect three factor  present graph algorithm iron law  quantify tradeoff help understand graph algorithm performance
2015,rethinking data-intensive science using scalable analytics system,next generation data acquisition technology allowing scientist collect exponentially data lower cost trend broadly impacting many scientific field including genomics astronomy neuroscience attack problem caused exponential data growth applying horizontally scalable technique current analytics system accelerate scientific processing pipelinesin paper describe adam example genomics pipeline leverage open-source apache spark parquet system achieve x speedup current genomics pipeline reducing cost  building system able distill set technique implementing scientific analysis efficiently using commodity big data system demonstrate generality architecture implement scalable astronomy image processing system achieves --x improvement state-of-the-art mpi-based system
2015,past future hardware architecture,start looking back  year computer architecture philosophical debate instruction set  parallel architecture  settled billion dollar investment side second half look forward first moore law ending free ride software-oblivious increasing performance since weve already played multicore card most-likely/only path left domain-specific processor memory system radically changing first jim gray decade-old prediction finally true tape dead flash disk disk tape new way connect dram new non-volatile memory technology promise make memory hierarchy even deeper finally surprisingly widespread agreement instruction set architecture namely reduced instruction set computer however unlike field despite harmony open alternative proprietary offering arm intel risc-v  proposed free open champion small base classic risc instruction run full open-source software stack opcodes reserved tailoring system-on-a-chip  application standard instruction extension optionally included soc unrestricted cost paperwork anyone use ability prototype using ever-more-powerful fpgas astonishingly inexpensive custom chip combined collaboration open-source software hardware offer hope new golden era hardware/software system
2014,smash benchmarking toolkit human genome variant calling,motivationcomputational method essential extract actionable information raw sequencing data thus fulfill promise next-generation sequencing technology unfortunately computational tool developed call variant human sequencing data disagree many prediction current method evaluate accuracy computational performance ad hoc incomplete agreement benchmarking variant calling method would stimulate development genomic processing tool facilitate communication among researcherswe propose smash benchmarking methodology evaluating germline variant calling algorithm generate synthetic datasets organize interpret wide range existing benchmarking data real genome propose set accuracy computational performance metric evaluating variant calling method benchmarking data moreover illustrate utility smash evaluate performance leading single-nucleotide polymorphism indel structural variant calling algorithm
2014,build bad research center,sharing lesson learned experience creating successful multidisciplinary research center
2014,changepoint analysis efficient variant calling,present cage statistical algorithm exploit high sequence identity sampled genome reference assembly streamline variant calling process using combination changepoint detection classification online variant detection cage able call simple variant quickly accurately - sampled genome differs little reference correctly learning remaining - must processed using computationally expensive method cage run deeply sequenced human whole genome sample approximately  minute potentially reducing burden variant calling order magnitude one memory-efficient pas data
2013,using cloud mapreduce measurement assignment,describe experience teaching mapreduce large undergraduate lecture course using public cloud service standard hadoop api using standard api student directly experienced quality industrial big-data tool using cloud every student could carry scalability benchmarking assignment realistic hardware would impossible otherwise two semester  student took course believe first large-scale demonstration feasible use pay-as-you-go billing cloud large undergraduate course modest instructor effort sufficient prevent student overspending average per-pupil expense cloud $ student excited assignment  said thought retained future course offering
2013,new software engineering curriculum agile,last standardization effort done  software engineering curriculum currently revised havent reached point agile development part software engineering curriculum shouldnt new curriculum standard ensure thus answer question title article affirmative even computer science standard committee absent-minded instructor follow initial call standard project student team using agile process natural match long review plan-and-document agile process lecture student become familiar set term concept demanding outcome met project well provided look deeper meaning behind plan-and-document term see agile fit
2013,direction-optimizing breadth-first search,breadth-first search important kernel used many graph-processing application many emerging application bfs analyzing social network input graph low-diameter scale-free propose hybrid approach advantageous low-diameter graph combine conventional top-down algorithm along novel bottom-up algorithm bottom-up algorithm dramatically reduce number edge examined turn accelerates search whole multi-socket server hybrid approach demonstrates speedup  range standard synthetic graph speedup  graph real social network compared strong baseline also typically double performance prior leading shared memory  implementation
2013,distributed memory breadth-first search revisited enabling bottom-up search,breadth-first search  fundamental graph primitive frequently used building block many complex graph algorithm worst case complexity bfs linear number edge vertex conventional top-down approach always take much time worst case recently discovered bottom-up approach manages cut complexity way number vertex best case typically least order magnitude le number edge bottom-up approach always advantageous combined top-down approach make direction-optimizing algorithm adaptively switch top-down bottom-up frontier expands present scalable distributed-memory parallelization challenging algorithm show order magnitude speedup compared earlier purely top-down code approach also us decomposition graph previously shown superior decomposition using default parameter graph benchmark new algorithm achieves performance rate  billion edge per second  thousand core cray xe make × faster conventional top-down algorithm using set optimization data distribution
2013,hardware evaluation cache partitioning improve utilization energy-efficiency preserving responsiveness,computing workload often contain mix interactive latency-sensitive foreground application recurring  computation guarantee responsiveness interactive batch application often run disjoint set resource incurs additional energy power capital cost paper evaluate potential hardware cache partitioning mechanism policy improve efficiency allowing  application run simultaneously interactive foreground application avoiding degradation interactive responsiveness evaluate tradeoff using commercial x multicore hardware support cache partitioning find real hardware measurement full application provide different observation past simulation-based evaluation co-scheduling application without llc partitioning lead  energy improvement average throughput improvement  compared running task separately result foreground performance degradation  average  optimal static llc partitioning average energy improvement increase  average throughput improvement  worst case slowdown reduced noticeably  average slowdown  also evaluate practical low-overhead dynamic algorithm control partition size able realize potential performance guarantee optimal static approach increasing  throughput additional 
2013,generalized scale independence incremental precomputation,developer rapidly growing application must able anticipate potential scalability problem cause performance issue production environment new type data independence called scale independence seek address challenge guaranteeing bounded amount work required execute query application independent size underlying data optimization strategy developed provide guarantee class query scale-independent executed using simple index important query technique insufficientexecuting complex query scale-independently requires precomputation using incrementally-maintained materialized view however since precomputation effectively shift query processing burden execution time insertion time scale-independent system must careful ensure storage maintenance cost threaten scalability paper describe scale-independent view selection maintenance system us novel static analysis technique ensure created view become scaling bottleneck finally present empirical analysis includes query tpc-w benchmark validates implementation ability maintain nearly constant high-quantile query update latency even application scale hundred machinesreferences
2012,crossing software education chasm,agile approach exploit cloud computing
2012,better worse benchmark shape field technical perspective,n/a
2012,diversity within crowd,though crowdsourcing hold great promise many struggle framing task determining member crowd recruited obtain reliable output case expert knowledge desired given time cost constraint problem may available case would beneficial augment expert input available input member general population believe reduced reliance expert case lead acceptable performance reducing cost latency work show able approach performance expert group image labeling task reducing reliance expert incorporating non-expert response
2012,experience teaching mapreduce cloud,describe experience teaching mapreduce large undergraduate lecture course using public cloud service using cloud every student could carry scalability benchmarking assignment realistic hardware would impossible otherwise two semester  student took course believe first large-scale demonstration feasible use pay-as-you-go billing cloud large undergraduate course modest instructor effort sufficient prevent student overspending average per-pupil expense cloud $ le half available grant funding student excited assignment  said thought retained future course offering
2011,piql success-tolerant query processing cloud,newly-released web application often succumb success disaster overloaded database machine resulting high response time destroy previously good user experience unfortunately data independence provided traditional relational database system useful agile development exacerbates problem hiding potentially expensive query simple declarative expression result developer application increasingly abandoning relational database favor imperative code written distributed key/value store losing many benefit data independence process instead propose piql declarative language also provides scale independence calculating upper bound number key/value store operation performed query coupled service level objective  compliance prediction model piqls scalable database architecture bound make easy developer write success-tolerant application support arbitrarily large number user still providing acceptable performance paper present piql query processing system evaluate scale independence hundred machine using two benchmark tpc-w scadr 
2011,scad director scaling distributed storage system stringent performance requirement,elasticity cloud computing environment provides economic incentive automatic resource allocation stateful system running cloud however system meet strict performance service-level objective  expressed using upper percentile request latency th latency measurement noisy complicates design dynamic resource allocation design evaluate scad director control framework reconfigures storage system on-the-fly response workload change using performance model system demonstrate framework respond unexpected data hotspot diurnal workload pattern without violating strict performance slos
2011,cuda-level performance python-level productivity gaussian mixture model application,typically scientist computational need prefer use high-level language python matlab however large computationally-intensive problem must eventually recoded low level language c fortran expert programmer order achieve sufficient performance addition multiple strategy may exist mapping problem onto parallel hardware unless hardware geometry problem dimension taken account large factor performance may left table show preserve productivity high-level language obtaining performance best low-level language code variant given hardware platform problem size using sejits  set technique leverage just-in-time code generation compilation combined reflection metaprogramming case study demonstrate technique gaussian mixture model training using em algorithm addition one line code import framework domain programmer using existing python gmm library run program unmodified gpu-equipped computer achieve performance meet beat gpu code hand-crafted human expert also show despite overhead allowing domain expert program use python overhead just-in-time code generation compilation approach still  performance competitive hand-crafted gpu code
2010,view cloud computing,clearing cloud away true potential obstacle posed computing capability
2010,diverse connection,n/a
2010,ubiquitous parallel computing berkeley illinois stanford,parlab berkeley upcrc-illinois pervasive parallel laboratory stanford studying make parallel programming succeed given industry recent shift multicore computing three center assume future microprocessor hundred core working application programming environment architecture meet challenge article briefly survey similarity difference research
2010,case piql performance insightful query language,large-scale user-facing application increasingly moving relational database distributed key/value store high-request-rate low-latency workload often move motivated key/value store ability scale simply adding hardware also easy understand predictable performance provide operation complex query approach often requires onerous explicit index management imperative data lookup developer propose piql performance insightful query language allows developer express many query found website still providing strict bound number i/o operation performed
2010,characterizing modeling generating workload spike stateful service,evaluating resiliency stateful internet service significant workload spike data hotspot requires realistic workload trace usually difficult obtain popular approach create workload model generate synthetic workload however exists characterization model stateful spike paper analyze five workload data spike find vary significantly many important aspect steepness magnitude duration spatial locality propose validate model stateful spike allows u synthesize volume data spike could thus used cloud computing user provider stress-test infrastructure
2010,ramp gold fpga-based architecture simulator multiprocessor,present ramp gold economical fpga-based architecture simulator allows rapid early design-space exploration manycore system ramp gold prototype high-throughput cycle-accurate full-system simulator run single xilinx virtex- fpga board simulates -core shared-memory target machine capable booting real operating system improve fpga implementation efficiency functionality timing modeled separately host multithreading used model evaluate prototype performance using modern parallel benchmark suite running manycore research operating system achieving two order magnitude speedup compared widely-used software-based architecture simulator
2010,statistics-driven workload modeling cloud,recent trend data-intensive computation use pay-as-you-go execution environment scale transparently user however provider environment must tackle challenge configuring system provide maximal performance minimizing cost resource used paper use statistical model predict resource requirement cloud computing application prediction framework guide system design deployment decision scale scheduling capacity addition present initial design workload generator used evaluate alternative configuration without overhead reproducing real workload paper focus statistical modeling application data-intensive workload
2010,detecting large-scale system problem mining console log,surprisingly console log rarely help operator detect problem large-scale datacenter service often consist voluminous intermixing message many software component written independent developer propose general methodology mine rich source information automatically detect system runtime problem first parse console log combining source code analysis information retrieval create composite feature analyze feature using machine learning detect operational problem show method enables analysis impossible previous method superior ability create sophisticated feature also show distill  analysis operator-friendly one-page decision tree showing critical message associated detected problem validate approach using darkstar online game server hadoop file system detect numerous real problem high accuracy false positive hadoop case able analyze  million line console log  minute methodology work textual console log size requires change service software human input knowledge software internals
2010,case fame fpga architecture model execution,given multicore microprocessor revolution argue architecture research community need dramatic increase simulation capacity believe fpga architecture model execution  simulator increase number useful architecture research experiment per day two order magnitude software architecture model execution  simulator clear misconception fpga-based simulation methodology propose fame taxonomy distinguish costperformance variation idea demonstrate simulation speedup claim case study wherein employ prototype fame simulator ramp gold research interaction hardware partitioning mechanism operating system scheduling policy study demonstrates fame capability run modern parallel benchmark suite research operating system simulate -core target architecture multi-level memory hierarchy timing model add experimental hardware mechanism target machine simulation speedup achieved adoption fame--enables experiment realistic time scale data set size thanare possible
2010,graphical representation identifier structure log,application console log ubiquitous tool diagnosing system failure anomaly several technique exist interpret log describing assessing log quality remains relatively unexplored paper describe abstract graphical representation console log called identifier graph visualization based representation representation break log message type identifier field show interrelation twowe describe two application visualization apply hadoop log two different deployment showing capture important property hadoops logging well relevant difference two site also apply technique log two system development show representation help highlight flaw underlying application logging
2010,piql performance insightful query language,large-scale website increasingly moving relational database distributed key-value store high request rate low latency workload often move motivated key-value store ability scale simply adding hardware also easy understand predictable performance provide operation data model work well lookup done primary key complex query require onerous explicit index management imperative data lookup developer demonstrate piql performance insightful query language allows developer express many query found website still providing strict bound number i/o operation query
2010,parallel revolution started part solution part problem - overview research berkeley parallel computing laboratory,par lab started  based earlier technical report “the berkeley view” parallel computing challenge  talk give update two year par lab picked five application drive research believe collectively capture many important feature future client application even become actual future “killer app” personalized medicine application focus detailed modeling individual’s response treatment representing important health market music application emphasizes real-time responsiveness rich human input high-performance many-channel audio synthesis speech application focus making speech input work well real-world noisy environment mobile device operated content-based image recognition  application represents growing practical use machine vision finally parallel web browser currently perhaps important single application client device well representative many interactive rich-document processing tasksour first step attacking parallel programming challenge analyze wide range application including workload embedded computing desktop computing game database machine learning scientific computing well five driving application discovered surprisingly compact set recurring computational pattern termed “motifs” greatly expanded work believe successful software architecture parallel serial described hierarchy pattern divide pattern either computational pattern describe computation performed structural pattern describe computation composed pattern proven central ourresearch effort serving common human vocabulary multidisciplinary discussion spanning application developer hardware architect well organizing structure software development another organizing principle original proposal divide software development stack two layer efficiency productivity programmer working efficiency layer generally expert achieving high performance underlying hardware necessarily knowledgeable given application domain programmer working productivity layer generally knowledgeable application domain le concerned hardware detail pattern bridge two layer efficiency programmer develop library framework efficiently implement standard pattern productivity programmer decompose application pattern use high-level language compose corresponding library framework form applicationsto improve quality portability efficiency-level library proposed leverage earlier work autotuning autotuning automatic search-based optimization process whereby multiple variant routine generated empirically evaluated hardware platform also included major effort parallel program correctness help programmer test verify debug code different correctness technique apply efficiency layer low-level data race deadlock concern productivity layer wish ensure semantic determinism atomicity whole pattern-based component approach software stack hinge ability efficiently flexibly compose software module developed low-level user-level scheduling substrate called “lithe” support efficient sharing processing resource arbitrary module even written different language different programming modelsour operating system architecture research devoted supporting software stack o based space-time partitioning export stable partition machine resource quality-of-service guarantee application two-level scheduling allows user-level scheduler lithe perform detailed application-specific scheduling within partition architecture research focus technique support o resource partitioning performance counter support application adaptivity software-managed memory hierarchy increase memory efficiency scalable coherence synchronization mechanism lower parallel system overhead experiment behavior new software stack new o hardware mechanism developed fpga-based simulation environment “ramp gold” running full application o software environment fast architectural simulator quickly iterate across level system stack
2010,software know best portable parallelism requires standardized measurement transparent hardware,hardware trend last  year dynamically trying improve performance little software visibility irrelevant today counterproductive adaptivity must software level parallel software going portable fast energy-efficient portable parallel program oxymoron today reason parallel slow parallel cant fast portable hence portable parallel program future must able understand measure /any/ computer run adapt effectively suggests hardware measurement standardized processor performance energy consumption become transparentin addition software-controlled adaptivity execution efficiency using technique like autotuning dynamic scheduling modern software environment adapt improve /programmer/ efficiency  classic example include dynamic linking dynamic memory allocation garbage collection interpreter just-in-time compiler debugger-support example recent selective embedded time specialization   highly productive language like python ruby thus future programming likely involve program generator many level hierarchy tailoring application machine productivity advance via adaptivity reflected modern benchmark virtually one writes statically linked highest-level-optimized c program foundation benchmark suitesthe dream improve productivity without sacrificing much performance indeed often heard claim new productive environment almost fast c almost fast java implication necessary tie productivity performance manycore era modern environment must able utilize manycore well gap highly efficient code highly productive code grow number coresfor industry bet manycore win therefore high level low level programming environment need able understand measure underlying hardware adapt execution portable relatively fast energy-efficienthence argue standard accurate hardware operation tracker  would huge positive impact making parallel software portable good performance energy efficiency similar impact ieee- standard portability numerical software particular believe shot lead much larger improvement portability performance energy efficiency parallel code recent architectural fad like opportunistic turbo mode transactional memory reconfigurable computing
2009,viewpoint - student legacy,viewpoint boil magazine page ive learned  year mentoring phd student
2009,roofline insightful visual performance model multicore architecture,roofline model offer insight improve performance software hardware 
2009,view parallel computing landscape,writing program scale increasing number core easy writing program sequential computer
2009,scad scale-independent storage social computing application,collaborative web application facebook flickr yelp present new challenge storing querying large amount data user developer focused performance single copy consistency ability perform ad-hoc query exists opportunity highly-scalable system tailored specifically relaxed consistency pre-computed query web  development model demand ability rapidly deploy new feature automatically scale number user many successful distributed key-value store far none provide rich query language sql propose new architecture scad allows developer declaratively state application specific consistency requirement take advantage utility computing provide cost effective scale-up scale-down use machine learning model introspectively anticipate performance problem predict resource requirement new query execution
2009,statistical machine learning make automatic control practical internet datacenters,horizontally-scalable internet service cluster commodity computer appear great fit automatic control target output  observed output  gain controller  yet datacenters automated way practice due part well-founded skepticism whether simple model often used research literature capture complex real-life workload/performance relationship keep changing condition might invalidate model argue shortcoming fixed importing modeling control analysis technique statistic machine learning particular apply rich statistical model application performance simulation-based method finding optimal control policy change-point method find abrupt change performance preliminary  running aweb  benchmark application driven real workload trace amazon ec cloud show method effectively control number server even face performance anomaly
2009,predicting multiple metric query better decision enabled machine learning,one challenging aspect managing large data warehouse identifying query behave start executing yet knowing performance characteristic - runtimes resource usage - solve two important problem first every database vendor struggle managing unexpectedly long-running query long-running query identified start rejected scheduled cause extreme resource contention query system second deciding whether system complete given workload given time period  depends knowing resource requirement query workload developed system us machine learning accurately predict performance metric database query whose execution time range millisecond hour training testing system used real customer query query generated extended set tpc-ds template extension mimic query caused customer problem used query compare accurately different technique predict metric elapsed time record used disk i/os message byte promising technique accurate also predicted metric simultaneously using information available prior query execution validated accuracy machine learning technique number hp neoview configuration able predict individual query elapsed time within  actual time  test query importantly able correctly identify short long-running  query inform workload management capacity planning
2009,online system problem detection mining pattern console log,describe novel application using data mining statistical learning method automatically monitor detect abnormal execution trace console log online setting different existing solution use two stage detection system first stage us frequent pattern mining distribution estimation technique capture dominant pattern  second stage use principal component analysis based anomaly detection technique identify actual problem using real system data -node hadoop cluster show achieve highly accurate fast problem detection also help operator better understand execution pattern system
2008,technical perspective data center computer,internet service already significant force searching retail purchase music downloads auction one vision st century user accessing service descendant cell phone rather running shrink-wrapped software descendant pc 
2008,design implementation trade-off wide-area resource discovery,paper describes design implementation sword scalable resource discovery service wide-area distributed system contrast previous system sword allows user describe desired resource topology interconnected group required intragroup intergroup per-node characteristic along utility application derives various range value characteristic design give user flexibility find geographically distributed resource application sensitive node network characteristic allows system rank acceptable configuration based quality application explore variety architecture deliver sword functionality scalable highly-available manner -node modelnet evaluation using workload measurement collected planetlab show architecture based -node server cluster site network peering facility outperforms decentralized dht-based resource discovery infrastructure smallest number site centralized architecture show significant promise find decentralized implementation emulation running continuously  planetlab node performs well benefiting dhts self-healing property
2008,mining console log large-scale system problem detection,console log generated application contain message application developer believed would useful debugging monitoring application despite ubiquity large size log rarely exploited systematic way monitoring debugging readily machine-parsable paper propose novel method mining rich source information first combine log parsing text mining source code analysis extract structure console log second extract feature structured information order detect anomalous pattern log using principal component analysis  finally use decision tree distill  pca-based anomaly detection format readily understandable domain expert  need familiar anomaly detection algorithm case study distill one million line console log hadoop file system simple decision tree domain expert readily understand process requires operator intervention detect large portion runtime anomaly commonly overlooked
2008,stencil computation optimization auto-tuning state-of-the-art multicore architecture,understanding efficient design utilization emerging multicore system one challenging question faced mainstream scientific computing industry several decade work explores multicore stencil  computation - class algorithm heart many structured grid code including pde solver develop number effective optimization strategy build auto-tuning environment search optimization parameter minimize runtime maximizing performance portability evaluate effectiveness strategy explore broadest set multicore architecture current hpc literature including intel clovertown amd barcelona sun victoria fall ibm q powerxcell nvidia gtx overall auto-tuning optimization methodology  fastest multicore stencil performance date finally present several key insight architectural tradeoff emerging multicore design implication scientific algorithm development
2007,embracing extending 20th-century instruction set architecture,vector case study show new functionality added extend time powerpc architecture support full vector architecture primarily enhancing multimedia extension provide better model compiler easier-to-understand model programmer
2007,ramp research accelerator multiple processor,ramp project goal enable intensive multidisciplinary innovation computing industry need tackle problem parallel processing ramp open-source community-developed fpga-based emulator parallel architecture design framework let large collaborative community develop contribute reusable composable design module three complete design - transactional memory distributed system distributed-shared memory - demonstrate platform potential
2007,parallel computing landscape berkeley view,n/a
2006,new direction cacm,much changed since current format communication acm cast mission acms flagship publication st century
2006,offshoring finally fact v folklore,acm job migration study released last month includes many recommendation current future computing professional educator
2006,computer science education 21st century,draw student c must first look create curriculum reflects exciting opportunity challenge today versus future student faculty would greatly benefit reinvigorated c curriculum
2006,reviving favorite c book,n/a
2006,ramp research accelerator multiple processor - community vision shared experimental parallel hw/sw platform,summary form given vast majority computer architect believe future microprocessor hundred thousand processor  chip given widespread agreement surprising much research remains done algorithm computer architecture network operating system file system compiler programming language application realize vision fortunately moore law enabled dense multi-core chip also enabled extremely dense fpgas today one two dozen soft core programmed single fpga multiple fpgas board multiple board system -processor design economically rapidly explored make happen however requires significant amount infrastructure hardware software call gateware register-transfer level model fill fgpas using berkeley emulation engine board created purpose hardware already done group architect plan design gateware create infrastructure share  open-source fashion every institution could system would invigorate multiprocessor research architecture community since processor core run   mhz large scale multiprocessor would fast enough run operating system large program speed sufficient support software research moreover new generation fpgas every  month capacity twice many core run faster future multiboard fpga system even attractive hence believe system would accelerate research across field touch multiple processor thus acronynm ramp research accelerator multiple processor ramp potential transform parallel computing community computer science simulation-driven prototype-driven
2006,berkeley view new framework new platform parallel research,recent switch parallel microprocessor milestone history computing industry laid roadmap multicore design preserve programming paradigm past via binary-compatibility cache-coherence conventional wisdom double number core chip silicon generation multidisciplinary group berkeley researcher met  month discus change investigation future opportunity led follow recommendation revolutionary industry plan dothe target core per chip hardware efficient mips per watt mips per area silicon mips per development dollarto maximize application efficiency programming model support wide range data type successful model parallelism data-level parallelism independent task parallelism instructionlevel parallelismshould play larger role conventional compiler translating parallel programsthe conventional path architecture innovation study benchmark suite like spec splash guide evaluate innovation problem innovation parallelism iit best hence seems unwise let set old program past drive investigation parallel computing future
2006,window xp kernel crash analysis,pc user started viewing crash fact life rather problem improve operating system dependability system designer programmer must analyze understand failure data paper analyze window xp kernel crash data collected population volunteer contribute berkeley open infrastructure network computing  project found o crash predominantly caused poorly-written device driver code user well product developer benefit understanding crash behavior elaborated paper
2006,service placement shared wide-area platform,emerging federated computing environment offer attractive platform test deploy global-scale distributed application node platform time-shared among competing application available resource varyacross node time thus one open architectural question system map application available nodes--that discover select resource using six-month trace planetlab resource utilization data resource demand three long-running planetlab service quantitatively characterize resource availability application usage behavior across node time investigate potential mitigate application impact resource variability intelligent service placement migrationwe find usage cpu network resource heavy highly variable argue variability call intelligently mapping application available node find node placement decision become ill-suited  minute suggesting application benefit migration timescale placement migration decision safely based data collected roughly timescale find inter-node latency stable good predictor available bandwidth observation argues collecting latency data relatively coarse timescales bandwidth data even coarser timescales using former predict latter measurement finally find although utilization particular resource particular node good predictor node utilization resource near future exist correlation support predicting one resource availability based availability resource node time availability resource node site time-series forecast assume daily weekly regression mean
2005,minority-minority minority-majority technology transfer,finding technology solution help need often lead welcomed answer look big picture
2005,20th century v 21st century c&c spur manifesto,technologist must confront current weakness deliver potential opportunity computer communication technology st century consider call arm tackling challenge
2005,state funding new initiative computer science engineering,intellectual opportunity huge social benefit transforming yet redesigning workable funding model cs&e research require collective imagination collaboration many sector
2005,recognizing individual excellence help u,addition honoring individual advanced field recognizing technical excellence enhances image profession help attract best brightest field
2005,reflection programming olympiad,acms programming contest give insight relative strength education around world
2005,acm support matter conference journal,acm one many organization sponsor conference journal use acm
2005,restoring popularity computer science,inaccurate impression opportunity st century c shrinking next generation professional help dispelling incorrect belief employment helping improve pre-college education
2005,new professional development centre boast 1 000 course oreilly book c classic,acm expanding pdc along three ax doubling number online course adding  book safari  classic computer science book help select
2005,rescuing family neighbor,computer scientist engineer take greater responsibility help reduce loss life property damage natural disaster
2005,robot desert research parable time,darpa grand challenge spurred advance application ai ironically acted referendum de-emphasis academic research
2005,computing research looming crisis,june  vint cerf bob kahn received computing highest prize turing award association computing machinery transmission control protocol  created  became language internetin may  issue science  used news hook invited editorial current state computer science research united state next generation groundbreaking innovation arise asked turing awardees  year hence reside  given current trend answer question likely united stateswe take opportunity explore greater depth issue raised editorial trend concern u u computer scientist reverse
2005,guest editor introduction approach recovery-oriented computing,given hardware fails software bug human operator make mistake researcher must increasingly consider recovery-oriented approach dependability article issue theme section describe range technique based perspective canaugment complement effort improve dependability
2005,stop whining outsourcing!,im sick hearing whining outsourcing going migrate job country lowest wage
2005,crash data collection window case study,reliability rapidly growing concern contemporary personal computer  industry computer user well product developer improve dependability system designer programmer must consider failure usage data operating system well application paper discus experience crash usage data collection window machine analyze  based crash uc berkeley eec department
2005,control consideration scalable event processing,growth scale system network created many challenge management especially event processing premise scaling event processing requires parallelism end observe event processing divided intra-event processing filtering inter-event processing root cause analysis since intra-event processing easily parallelized propose architecture intra-event processing element  replicated scale larger event input rate address two challenge architecture first iaps subject overload require effective flow control capability present component used build iaps second need balance load iaps avoid creating resource bottleneck challenge complicated presence disturbance cpu intensive administrative task reduce event processing rate address challenge using design based control theory technique analyzing stability accuracy settling time demonstrate effectiveness approach testbed experiment include disturbance form cpu intensive application
2005,design implementation tradeoff wide-area resource discovery,paper describes design implementation sword scalable resource discovery service wide-area distributed system contrast previous system sword allows user describe desired resource topology interconnected group required intragroup intergroup per-node characteristic along utility application derives various range value characteristic design give user flexibility find geographically distributed resource application sensitive node network characteristic allows system rank acceptable configuration based quality application explore variety architecture deliver sword functionality scalable highly-available manner -node modelnet evaluation using workload measurement collected planetlab show architecture based -node server cluster site network peering facility outperforms decentralized dht-based resource discovery infrastructure smallest number site centralized architecture show significant promise find decentralized implementation emulation running continuously  planetlab node performs well benefiting dhts self-healing property
2005,combining visualization statistical analysis improve operator confidence efficiency failure detection localization,web application suffer software configuration fault lower availability recovering failure dominated time interval fault appear detected site operator introduce set tool augment ability operator perceive presence failure automatic anomaly detector scour http access log find change user behavior indicative site failure visualizer help operator rapidly detect diagnose problem visualization address key question autonomic computing win operator confidence new tool embraced evaluation performed using http log ebatescom demonstrates tool enhance detection failure well shorten detection time approach application-generic applied web application without need instrumentation
2005,latency lag bandwidth,summary form given review performance trend struck consistent theme across many technology many year bandwidth improves much quickly latency four different technology disk network memory processor rule thumb quantify imbalance bandwidth improves square improvement latency paper list half-dozen performance milestone document observation many reason happens way cope two small example might design system differently kept simple rule thumb mind
2004,hot link,n/a
2004,latency lag bandwith,review performance trend struck consistent theme across many technology bandwidth improves much quickly latency list half-dozen performance milestone document observation many reason happens way cope rule thumb quantify plus example design system differently based observation
2004,health research conference dearth big idea paper,n/a
2004,recovery-oriented computing building multitier dependability,building system recover fast may productive aiming system never fail recovery immune failure either author advocate multiple line defense managing failure
2004,experience evaluating human-assisted recovery process,describe approach quantitatively evaluating human-assisted failure-recovery tool process environment modern internetand enterprise-class server system approach quantify dependability impact single recovery system also enables comparison different recovery approach approach combine aspect dependability benchmarking human user study incorporating human participant system evaluation yet still producing typical dependability-related metric  illustrate methodology via case study system-wide undo/redo recovery tool e-mail service approach able expose dependability benefit tool well point area behavior could use improvement
2004,path-based failure evolution management,present new approach managing failure evolution large complex distributed system using runtime path use path request follow move system core abstraction macro approach focus component interaction rather detail component path record component performance interaction user- request-centric occur sufficient volume enable statistical analysis way easily reusable across application automated statistical analysis multiple path allows detection diagnosis complex failure assessment evolution issue particular approach enables significantly stronger capability failure detection failure diagnosis impact analysis understanding system evolution explore capability three real implementation two service million request per day contribution include approach maintainable extensible reusable architecture various statistical analysis engine discussion experience high-volume production service several year
2004,distributed resource discovery planetlab sword,describe sword decentralized service resource discovery service placement sword find optimal embedding user resource request  topology available node sword consists two part multi-attribute distributed range query engine built top distributed hashtable optimizer whose work parallelized per-query basis paper focus sword planetlab deployment lesson learned deployment find generally acceptable performance decentralized implementation although find even small  ``centralized solution offer superior performance term median distributed query latency reporting querying node population size planetlab deployment led qualitative observation usefulness dht service building block benefit danger automatic application restart benefit exporting simple external interface semantically close service internal representation user query
2004,combining statistical monitoring predictable recovery self-management,complex distributed internet service form basis e-commerce increasingly mission-critical network-based application new workload internal architecture three-tier enterprise application present opportunity new approach keeping running face many common recoverable failure core approach anomaly detection localization based statistical machine learning technique unlike previous approach propose anomaly detection pattern mining operational statistic mean response time also structural behavior system---what part system combination exercised response different kind external stimulus addition rather building baseline model priori extract observing behavior system short period time normal operation explain necessary underlying assumption realized system research report early success using approach describe benefit approach make competitive path toward self-managing system outline research challenge hope approach enable new science design self-managing system allowing rapid widespread application statistical learning theory technique  problem system dependability
2003,linear programming approach discriminant analysis reserved-judgment region,linear-programming model proposed deriving discriminant rule allow allocation entity reserved-judgment region size reserved-judgment region controlled varying parameter within model dictate level aggressiveness  allocating  entity group  simulation experiment various configuration normal contaminated normal three-group population reported variety parameter selection  cross-validation experiment using real data set also reported simulation cross-validation experiment include comparison discriminant analysis technique  demonstrate proposed model useful deriving discriminant rule reduce chance misclassification maintaining reasonable level correct classification
2003,scalable vector processor embedded system,embedded application data-level parallelism vector processor offer high performance low power consumption low design complexity unlike superscalar vliw design vector processor scalable optimally match specific application requirementsto demonstrate vector architecture meet requirement embedded medium processing evaluate vector iram viram  architecture developed uc berkeley using benchmark embedded microprocessor benchmark consortium  evaluation cover three component viram architecture instruction set vectorizing compiler processor microarchitecture show compiler vectorize embedded task automatically without compromising code density also describe prototype vector processor outperforms high-end superscalar vliw design x x medium task without compromising power consumption finally demonstrate clustering modular design technique let vector processor scale ten arithmetic data path wide instruction-issue capability become necessary
2003,overcoming limitation conventional vector processor,despite superior performance multimedia application vector processor three limitation hinder widespread acceptance first complexity size centralized vector register file limit number functional unit second precise exception vector instruction difficult implement third vector processor require expensive on-chip memory system support high bandwidth low access latency paper introduces code scalable vector microarchitecture address three shortcoming designed around clustered vector register file us separate network operand transfer across functional unit extensive use decoupling hide latency communication across functional unit provides  performance improvement centralized organization code scale efficiently  functional unit without requiring wide instruction issue capability renaming table make clustered register file transparent instruction set level renaming also enables precise exception vector instruction performance loss le  finally decoupling allows code tolerate large increase memory latency sub-linear performance degradation without using on-chip cache thus code use economical off-chip memory system
2003,undo operator building undoable e-mail store,system operator play critical role maintaining server dependability yet lack powerful tool help help address unfulfilled need describe operator undo tool provides forgiving operation environment allowing operator recover mistake unanticipated software problem intentional accidental data corruption operator undo start intercepting logging user interaction network service enter system creating record user intent undo cycle system hard state physically rewound allowing operator perform arbitrary repair repair complete lost user data reintegrated repaired system replaying logged user interaction tracking compensating resulting externally-visible inconsistency describe design implementation application-neutral framework operator undo detail process instantiated framework form undo-capable e-mail store supporting smtp mail delivery imap mail retrieval proof-of-concept e-mail implementation imposes small performance overhead store day week recovery log single disk
2003,internet service fail done, jim gray published landmark study cause failure tandem system technique tandem used prevent failure see j gray computer stop done symposium reliability distributed software database system  seventeen year later internet service replaced fault-tolerant server new kid x-availability block using data three large-scale internet service analyzed cause failure  effectiveness various technique preventing mitigating service failure find  operator error largest single cause failure two three service  operator error often take long time repair  configuration error largest category operator error  failure custom-written front-end software significant  extensive online testing thoroughly exposing detecting component failure would reduce failure rate least one service qualitatively find improvement maintenance tool system used service operation staff would decrease time diagnose repair problem
2002,architecture dependability large-scale internet service,popularity large-scale internet infrastructure service aol google hotmail grown enormously scalability availability requirement service led system architecture diverge significantly traditional system like desktop enterprise server database given need thousand node cost necessitates use inexpensive personal computer wherever possible efficiency often requires customized service software likewise addressing goal zero downtime requires human operator involvement pervasive redundancy within cluster globally distributed data center despite service success architectures-hardware software operational-have developed ad hoc manner surveyed analyzed moreover public know little service fail operational practice used attempt keep running / first step toward formalizing principle building highly available maintainable large-scale internet service surveying existing service architecture dependability article describes observation date
2002,roc-1 hardware support recovery-oriented computing,introduce roc- hardware platform large-scale cluster system designed provide high availability internet service application roc- prototype embodies philosophy recovery-oriented computing  emphasizing detection recovery failure inevitably occur internet service environment rather simple avoidance failure roc- promise greater availability existing server system incorporating four technique applied ground hardware software redundancy isolation online self-testing verification support problem diagnosis concern human interaction system
2002,introduction dependability,n/a
2002,sigarch conference guideline,n/a
2002,recovery oriented computing new research agenda new century,summary form given follows  year successfully improving cost-performance time new challenge system research community result focus cost-performance fabled five availability  look much easier achieve advertising computer cost managing system five time cost hardware post-pc era wireless gadget using service internet one new challenge building service really dependable much le expensive maintain traditional fault-tolerant computing concentrate tolerating hardware operating system fault ignoring fault human operator even application recovery oriented computing  aim improving mean time recover lower cost management improve availability whole system including people operate look civil engineering diplomacy inspire principle roc design talk outline motivation proposed principle roc design plus concrete  area benchmarking availability
2002,simple way estimate cost downtime,system dependable le expensive maintain may expensive purchase ordinary customer cannot calculate cost downtime system may succeed difficult justify higher price hence propose easy-to-calculate estimate downtimeas one reviewer commented cost estimate propose ``is simply symbolic translation obvious common sense approach problem take remark complement noting prior work ignored piece obvious formulawe introduce formula argue important formula easily calculated suggest hard get accurate estimate give exampleswidespread use obvious formula lay foundation system reduce downtime
2002,vector v superscalar vliw architecture embedded multimedia benchmark,multimedia processing embedded device requires architecture lead high performance low power consumption reduced design complexity small code size paper use eembc industrial benchmark suite compare viram vector architecture superscalar vliw processor embedded multimedia application comparison cover viram instruction set vectorizing compiler prototype chip integrates vector processor dram main memory demonstrate executable code viram  time smaller vliw code comparable /spl times/ cisc code simple cache-less viram chip  time faster -way superscalar risc processor us  time faster clock frequency consumes  time power viram also  time faster cache-based vliw processor even manual optimization vliw code insertion simd dsp instruction single-issue viram processor  faster -way -way vliw design
2002,rewind repair replay three r dependability,motivated growth web infrastructure service susceptibility human operator-related failure introduce system-level undo recovery mechanism designed improve service dependability undo enables system operator recover inevitable mistake furthermore enables retroactive repair problem fixed quickly enough prevent detrimental effect present three r model undo match need human error recovery retroactive repair discus several issue raised undo model introduce initial architectural framework undoable system using example undoable e-mail service system
2002,studying using failure data large-scale internet service,large-scale internet service newest arguably commercially important class system requiring x availability result little information published cause failure attempt address deficiency analyzed detailed failure report three large-scale internet service goal  identify major factor contributing user-visible failure  evaluate  effectiveness various technique preventing mitigating service failure  build fault model service-level dependability recovery benchmark initial  indicate operator error network problem leading contributor user-visible failure failure custom-written front-end software significant online testing thoroughly exposing handling component failure would reduce failure rate least one service
2000,art massive storage web image archive,museum make entire collection available world via internet thinker imagebase san francisco fine art museum online art image database demonstrates issue involved managing large storage system delivering content user
2000,ideal bootstrap estimation expected prediction error k-nearest neighbor classifier application classification error assessment,euclidean distance k-nearest neighbor  classifier simple nonparametric classification rule bootstrap method widely used estimating expected prediction error classification rule motivated objective calculating ideal bootstrap estimate expected prediction error practice bootstrap method use monte carlo resampling estimate ideal bootstrap estimate exact calculation generally intractable article present analytical formula exact calculation ideal bootstrap estimate expected prediction error k-nn classifier propose new weighted k-nn classifier based resampling idea resampling-weighted k-nn classifier replaces k-nn posterior probability estimate expectation resampling predicts unclassified covariate belonging group largest resampling expectation simulation study application involving remotely sensed data show resampling-weighted k-nn classifier compare favorably unweighted distance-weighted k-nn classifier
2000,exploiting on-chip memory bandwidth viram compiler,many architectural idea appear useful hardware standpoint fail achieve wide acceptance due lack compiler support paper explore design viram architecture perspective compiler writer describing code generation problem arise viram solution viram compiler viram single chip system designed primarily multimedia combine vector processing mixed logic dram achieve high performance relatively low energy area design complexity paper focus two aspect viram compiler architecture first problem take advantage on-chip bandwidth memory-intensive application including non-contiguous unpredictable memory access pattern second problem support kind narrow data type arise medium processing including processing  -bit data
2000,towards availability benchmark case study software raid system,benchmark historically played key role guiding progress computer science system research development traditionally neglected area availability maintainability evolutionary growth area recently become critically important high-end system design first step addressing deficiency introduce general methodology benchmarking availability computer system methodology us fault injection provoke situation availability may compromised leverage existing performance benchmark workload generation data collection produce  detail-rich graphical presentation distilled numerical summary apply methodology measure availability software raid system shipped linux solaris  server window  server find methodology powerful enough quantify impact various failure condition availability system also unearth design philosophy respect transient error recovery policy
1999,istore introspective storage data-intensive network service,today fast-growing data-intensive network service place heavy demand back-end server support paper introduces istore novel server architecture couple lego-like plug-and-play hardware generic framework constructing adaptive software leverage continuous self-monitoring istore exploit introspection provide high availability performance scalability drastically reducing cost complexity administration istore-based server monitor adapts change imposed workload unexpected system event hardware failure adaptability enabled combination intelligent self-monitoring hardware component extensible software framework allows target application specify monitoring adaptation policy system
1999,cluster i/o river making fast case common,introduce river data-flow programming environment i/o substrate cluster computer river designed provide maximum performance common case  even face nonuniformity hardware software workload river based two simple design feature high-performance distributed queue storage redundancy mechanism called graduated declustering implemented number data-intensive application river validate design near-ideal performance variety non-uniform performance scenario
1999,retrospective twelve year lisa proceeding,examine two model categorizing task performed system administrator first model traditional task based model second model break task source problem look historical trend last  year lisa proceeding based model finally analyze important task done system administrator propose future research area hope academic rigor analyzing research brought system administration without losing practicality make research valuable
1999,usage pattern web-based image collection,paper present study user access pattern large web-based image collection image entire collection fine art museum san francisco largest on-line collection high resolution art image world image served using tile-based solution allows user zoom-in navigate within image studied five month web log data collection analysis revealed following le  available document site accessed five month period document popularity appears follow zipf distribution also image interesting area viewed others image resolution viewed far others user navigation pattern vary resolution sensitive download time paper discus  implication design cache archival storage system support type workload
1999,designing self-maintaining storage system,paper show suitability self-maintaining approach tertiary disk large-scale disk array system built commodity component instead incurring cost custom hardware attempt solve various problem design software built cluster storage node connected switched ethernet storage node pc hosting dozen scsi disk running freebsd operating system system used web-based image server zoom project cooperation fine art museum san francisco  designing self-maintenance extension o run cluster mitigate system administrator burden several component required building self-maintaining system one decoupling time failure time hardware replacement implies system must amount redundancy single point failure system fully redundant everything constructed avoid single point failure another correctly identifying failure dependency paper also outline several approach lower human cost system administration system making system autonomous possible
1999,virtual log based file system programmable disk,paper study minimize latency small transactional writes disk basic approach write free sector near current disk head location leveraging embedded processor core inside disk develop number analytical model demonstrate performance potential approach present design variation log-structured file system based concept virtual log support fast small transactional writes without extra hardware support compare approach traditional update-in-place logging system modifying solaris kernel serve simulation engine evaluation show random synchronous update unmodified ufs execute order magnitude faster virtual log conventional disk virtual log also significantly improve lf case delaying small writes option on-line cleaning would degrade performance current trend disk technology continue expect performance advantage approach become even pronounced future
1998,new direction computer architecture research,past year two important trend evolved could change shape computing multimedia application portable electronics together trend lead personal mobile-computing environment small device carried time incorporates function pager cellular phone laptop computer pda digital camera video game microprocessor needed device actually merged general-purpose processor digital-signal processor power budget latter yet almost two decade architecture research focused desktop server machine designing processor future heavy bias toward past design successful processor architecture future first need explore future application match requirement scalable cost-effective way author describe vector iram initial approach direction challenge others successful computer architecture community investigate architecture heavy bias future
1998,case intelligent disk idisks,decision support system  data warehousing workload comprise increasing fraction database market today i/o capacity associated processing requirement ds workload increasing rapid rate doubling roughly every nine twelve month  response increasing storage computational demand present computer architecture decision support database server utilizes intelligent disk  idisks utilize low-cost embedded general-purpose processing main memory high-speed serial communication link disk idisks connected via serial link high-speed crossbar switch overcoming i/o bus bottleneck conventional system off-loading computation expensive desktop processor idisk system may improve cost-performance importantly idisk architecture allows processing system scale increasing storage demand
1998,architectural cost streaming i/o comparison workstation cluster smps,investigate resource usage performing streaming i/o contrasting three architecture single workstation cluster smp various i/o benchmark derive analytical empirically-based model resource usage data transfer examining i/o bus memory bus network processor system investigating resource detail ass comprises well-balanced system workload find architecture study well balanced streaming i/o application across platform main limitation attaining peak performance cpu due lack data locality increasing processor performance  great aid workload future cluster workstation i/o bus major system bottleneck increased load placed network communication well-balanced cluster workstation copious i/o bus bandwidth perhaps via multiple i/o bus smp suffers poor memory-system performance even true parallelism benchmark contention shared-memory system lead reduced performance result clustered workstation provide higher absolute performance streaming i/o workload
1998,retrospective retrospective high-level language computer architecture,n/a
1998,performance characterization quad pentium pro smp using oltp workload,commercial application important yet often overlooked workload significantly different characteristic technical workload potential impact difference computer optimized technical workload may provide good performance commercial application application may fully exploit advance processor design evaluate issue use hardware counter measure architectural feature four-processor pentium pro-based server running tpc-c-like workload informix database examine effectiveness out-of-order execution branch prediction speculative execution superscalar issue retire caching multiprocessor scaling find out-of-order execution superscalar issue retire branch prediction effective database workload technical workload spec find cache effective reducing processor traffic memory even larger cache would helpful satisfy data request multiprocessor scaling workload good even modest bus utilization degrades application memory latency limiting database throughput
1998,retrospective risc reduced instruction set computer,n/a
1998,retrospective high-level language computer architecture,high-level language computer  attracted interest architectural programming community last  year proposal made machine directed towards execution various language algol  apl  basic  cobol  fortran lisp  pascal  pl/i  snobol  host specialized language though numerous design proposed handful high-level language computer actually implemented  examining goal success high-level language computer author found design suffer fundamental problem stemming misunderstanding issue involved design use implementation cost-effective computer system intent paper identify discus several issue applicable high-level language computer architecture provide concrete definition high-level language computer suggest direction high-level language computer architecture future
1998,risc reduced instruction set vlsi computer,reduced instruction set computer  project investigates alternative general trend toward computer increasingly complex instruction set proper set instruction corresponding architectural design machine high effective throughput achieved simplicity instruction set addressing mode allows instruction execute single machine cycle simplicity instruction guarantee short cycle time addition machine much shorter design time paper present architecture risc novel hardware support scheme procedure call/return overlapping set register bank pas parameter directly subroutine largely responsible excellent performance risc static dynamic comparison new architecture traditional machine given although instruction simpler average length program found exceed program dec vax  factor  preliminary benchmark demonstrate performance advantage risc appears possible build single chip computer faster vax /
1997,constrained discriminant analysis via 0/1 mixed integer programming,nonlinear / mixed integer programming model presented constrained discriminant analysis problem model place restriction number misclassifications allowed among training entity incorporates reserved judgment region entity whose classification difficult determine may allocated two linearizations model given one heuristic one exact numerical  real-world machine-learning datasets presented
1997,scalable processor billion-transistor era iram,member university california berkeley argue memory system greatest inhibitor performance gain future architecture thus propose intelligent ram iram approach greatly increase on-chip memory capacity using dram technology instead much le dense sram memory cell resultant on-chip memory capacity coupled high bandwidth available chip allow cost-effective vector processor reach performance level much higher traditional architecture although vector processor require explicit compilation author claim vector compilation technology mature  furthermore future workload contain heavily vectorizable component
1997,case intelligent ram,two trend call question current practice fabricating microprocessor dram different chip different fabrication line gap processor dram speed growing  per year size organization memory single dram chip becoming awkward use yet size growing  per year intelligent ram iram merges processing memory single chip lower memory latency increase memory bandwidth improve energy efficiency also allows flexible selection memory size organization promise saving board area article review state microprocessor dram today explores opportunity challenge irams finally estimate performance energy efficiency three iram design
1997,new voting based hardware data prefetch scheme,dramatic increase processor memory gap recent year led development technique like data prefetching hide latency cache miss two hardware technique stream buffer stride predictor dissimilar architecture effective different kind memory access pattern require different amount extra memory bandwidth compare performance two technique propose scheme unifies simulation study six benchmark program confirm combined scheme effective reducing average memory access time  either two individually
1997,intelligent ram iram industrial setting application architecture,goal intelligent ram  design cost-effective computer designing processor memory fabrication process instead conventional logic fabrication process include memory on-chip design processor dram process one must learn business culture dram quite different microprocessor author describe difference current vision iram application architecture implementation
1997,energy efficiency iram architecture,portable system demand energy efficiency order maximize battery life iram architecture combine dram processor chip dram process energy efficient conventional system high density dram permit much larger amount memory on-chip traditional sram cache design logic process allows iram memory access satisfied on-chip thus much le need drive high-capacitance off-chip bus contribute significantly energy consumption system quantify advantage apply model energy consumption dram sram memory  cache simulation application reflective personal productivity task low power system find iram memory hierarchy consume little  energy consumed conventional memory hierarchy memory-intensive application delivering comparable performance furthermore energy consumed system consisting iram memory hierarchy combined energy efficient cpu core little  cpu core traditional memory hierarchy
1997,extensible scalable monitoring cluster computer,describe card  system monitoring large cluster cooperating computer card scale capacity visualization least  machine principle scale far beyond architecture easily extensible monitor new cluster software hardware card detects automatically recovers common fault card us java applet primary interface allowing user anywhere world monitor cluster browser
1997,high-performance sorting network workstation,report performance now-sort collection sorting implementation network workstation  find parallel sorting competitive sorting large-scale smps traditionally held performance record -node cluster sort  gb one minute -node cluster finish datamation benchmark  secondsour implementation applied variety disk memory processor configuration highlight salient issue tuning component system evaluate use commodity operating system hardware parallel sorting find existing o primitive memory management file access adequate due aggregate communication disk bandwidth requirement bottleneck system workstation i/o bus
1996,logp practical model parallel computation,n/a
1996,microcelebration,n/a
1996,serverless network file system,propose new paradigm network file system design serverless network file system  traditional network file system rely central server machine serverless system utilizes workstation cooperating peer provide file system service machine system store cache control block data approach us location independence combination fast local area network provide better performance scalability traditional file system furthermore machine system assume responsibility failed component serverless design also provides high availability via redundatn data storage demonstrate approach implemented prototype serverless network file system called xfs preliminary performance measurement suggest architecture achieves goal scalability instance -node xfs system  active client client receives nearly much read write throughput would see active client
1995,case network workstation,network workstation poised become primary computing infrastructure science engineering now may dramatically improve virtual memory file system performance achieve cheap highly available scalable file storage provide multiple cpu parallel computing hurdle remain include efficient communication hardware software global coordination multiple workstation operating system enterprise-scale network file system -node prototype aim demonstrate practical solution challenges< >
1995,truth spec benchmark,system performance evaluation cooperative  benchmark set integer floating-point program intended effective fair comparing performance high performance computing system spec rating often quoted company advertising trusted de facto measure comparison computer system recently concern regarding fairness value benchmark comparing computer systemsin paper investigate following two question regarding spec benchmark suite  sensitive spec rating various tuning  reproducible published  six vendor compare published specpeak specbase rating observe  average improvement specpeak rating due change compiler flag alone attempt reproduce published spec rating came across various explicit hidden tuning parameter consider unrealistic suggest new unit called specsimple requires using -o compiler optimization flag shared library standard system configuration specsimple designed better match performance experienced typical user measured specsimples - advertised specpeak performance conclude paper citing case compiler optimization specifically designed spec program performance decrease drastically computed  incorrect compiled program exactly match spec benchmark program finding show fairness value popular spec benchmark questionable
1995,berkeley network workstation project,paper describes berkeley network workstation  project project leverage high bandwidth switch based local area network custom low latency network interface global layer operating system make building full desktop computer act single large computer building computer
1995,choosing best storage system video service,n/a
1995,storage system movies-on-demand video server,evaluate storage system alternative movies-on-demand video server begin characterizing movies-on-demand workload briefly discus performance disk array first study disk farm one movie stored per disk simple scheme waste substantial disk bandwidth disk holding le popular movie underutilized also good performance requires movie replicated reflect user request pattern next examine disk farm movie striped across disk find striped video server offer nearly full utilization disk achieving better load balancing remainder paper concentrate tertiary storage system evaluate use storage hierarchy video service hierarchy include tertiary library along disk farm examine magnetic tape library optical disk jukebox show unfortunately performance neither tertiary system performs adequately part storage hierarchy service predicted distribution movie access suggest change tertiary library would make better-suited application
1995,case network workstation - abstract,apparatus disclosed achieving interference-free fluid velocity distribution plane wall subsonic wind tunnel adjustable slat longitudinal baffle therebetween make test section wall excluding ground plane extend upstream downstream vehicle tested static pressure measurement along centerline slat provide information enables calculation slat contour required achieve close matching streamlines within tunnel occurring road 
1995,interaction parallel sequential workload network workstation,paper examines plausibility using network workstation  mixture parallel sequential job simulation study examines issue arise combining two workload single platform starting dedicated parallel program incrementally relax uniprogramming restriction multi-programmed multi-user interactive sequential user parallel program show number issue associated distributed environment  small noticeable effect parallel program performance also find efficient migration idle workstation necessary maintain acceptable parallel application performance furthermore present methodology deriving optimal delay time recruiting idle machine use parallel program recruitment threshold  minute research cluster measured finally quantify effect additional parallel load upon interactive user keeping track potential number user delay simulation limit maximum number delay per user still maintain acceptable parallel program performance summary find workload  rule applies cluster approximately  machine sustain -node parallel workload addition sequential load placed upon interactive user
1994,coding technique handling failure large disk array,crucial issue design large disk array protection data catastrophic disk failure although today single disk highly reliable disk array consists   disk probability least one disk fail within day week high paper address problem designing erasure-correcting binary linear code protect loss data caused disk failure large disk array describe code used encode data disk array give simple method data reconstruction discus important reliability performance constraint code show constraint relate property parity check matrix code transform code design problem combinatorial problem using combinatorial framework present code prove optimal respect various reliability performance constraint
1994,raid high-performance reliable secondary storage,disk array proposed way use parallelism multiple disk improve aggregate i/o performance today appear product line major computer manufacturer article give comprehensive overview disk array provides framework organize current future work first article introduces disk technology review driving force popularized disk array performance reliability discus two architectural technique used disk array striping across multiple disk improve performance redundancy improve reliability next article describes seven disk array architecture called raid  level  compare performance cost reliability go discus advanced research implementation topic refining basic raid level improve performance designing algorithm maintain data consistency last article describes six disk array prototype product discus future opportunity research annotated bibliography disk array-related literature
1994,performance design evaluation raid-ii storage server,raid-ii high-bandwidth network-attached storage server designed implemented university california berkeley paper measure performance raid-ii evaluate various architectural decision made design process first measure end-to-end performance system approximately  mb/s disk array read writes perform bottleneck analysis examining performance individual subsystem conclude disk subsystem limit performance adding custom interconnect board high-speed memory bus system parity engine able achieve performance speedup   comparative system using off-the-shelf hardware
1994,new approach i/o performance evaluation - self-scaling i/o benchmark predicted i/o performance,current i/o benchmark suffer several chronic problem quickly become obsolete stress i/o system help much understanding i/o system performance propose new approach i/o performance analysis first propose self-scaling benchmark dynamically adjusts aspect workload according performance characteristic system measured benchmark automatically scale across current future system evaluation aid understanding system performance reporting performance varies according five workload parameter second propose predicted performance technique using  self-scaling evaluation estimate quickly performance workload measured show technique yield reasonably accurate performance estimate argue method give far accurate comparative performance evaluation traditional single-point benchmark apply new evaluation technique measuring sparcstation + one scsi disk hp  one scsi-ii disk decstation / running sprite lf operating system three-disk disk array convex c minisupercomputer four-disk disk array solbourne e/ fileserver two-disk disk array
1994,terabyte >> teraflop work processor i/o action abstract,n/a
1994,case networks-of-workstations,n/a
1994,raid-ii high-bandwidth network file server, raid  group uc berkeley built prototype disk array called raid-i bandwidth delivered client raid-i severely limited memory system bandwidth disk array host workstation designed second prototype raid-ii deliver disk array bandwidth file server client custom-built crossbar memory system called xbus board connects disk directly high-speed network allowing data large request bypass server workstation raid-ii run log-structured file system  software optimize performance bandwidth-intensive application raid-ii hardware single xbus controller board delivers  megabytes/second large random read operation  megabytes/second sequential read operation preliminary implementation lf raid-ii delivers  megabytes/second large read request  megabytes/second large write operations< >
1994,storage alternative video service,next decade video-on-demand  service widely available customer potentially highly profitable service provider order provide access many movie video storage server may contain magnetic disk also high-capacity tertiary storage device paper study two storage device alternative array magnetic disk array magnetic tape magnetic disk array provide high-bandwidth low-latency retrieval moderate storage capacity high cost magnetic tape array provide low-bandwidth high-latency retrieval high storage capacity low cost evaluate two storage system alternative determine number user support simulation show magnetic disk array support considerably user lower cost per user magnetic tape arrays< >
1994,cooperative caching using remote client memory improve file system performance,emerging high-speed network allow machine access remote data nearly quickly access local data trend motivates use cooperative caching coordinating file cache many machine distributed lan form effective overall file cache paper examine four cooperative caching algorithm using trace-driven simulation study simulation indicate system studied cooperative caching halve number disk access improving file system read response time much  based simulation conclude cooperative caching significantly improve file system read response time relatively simple cooperative caching algorithm sufficient realize potential performance gain
1994,quantitative analysis cache policy scalable network file system,current network file system protocol rely heavily central server coordinate file activity among client workstation central server become bottleneck limit scalability environment large number client central server system nfs afs client writes cache miss coherence message handled server keep workload expensive server machine needed configured high-performance cpu memory system i/o channel since server store data must physically capable connecting many disk reliance central server also make current system inappropriate wide area network use network bandwidth server may limitedin paper investigate quantitative performance effect moving many server responsibility possible client workstation reduce need high-performance server machine devised cache protocol data reside client data transfer proceed directly client client server used coordinate data transfer protocol incorporated part experimental file system xfs present  trace-driven simulation study protocol using trace  client nfs installation find xfs protocol reduces server load factor six compared afs without significantly affecting response time file availability
1994,toward workload characterization video server digital library application,energy-efficient automatic sluice gate sustaining fluid level separating upstream pool downstream pool irrigation system enabling level water one pool kept constant settable value sluice gate separate upstream pool  downstream pool  enables level one pool kept constant settable value said gate comprising baffle  movable horizontal rotational shaft  whereby rotation baffle shaft determines flow water downstream said baffle constituting segment cylinder said rotational shaft axis comprising box member  second box member  moving baffle dipping respectively upstream pool downstream pool mean  least partially filling box member mean  keeping constant level first second box member according whether level upstream pool downstream pool kept constant mean  setting said constant level value
1993,designing disk array high data reliability,redundancy based parity encoding proposed ensuring disk array provide highly reliable data parity-based redundancy tolerates many independent dependent disk failure  without on-line spare disk many failure on-line spare disk paper explores design reliable redundant disk array context -disk strawman array present applies analytic simulation model time data lost show balance requirement high data reliability overhead cost redundant data on-line spare on-site repair personnel term array architecture component reliability repair policy
1993,massive parallelism massive storage trend prediction 1995 2000,mainline technology driving computer industry microprocessor dram graph predict dram capacity microprocessor performance extrapolating past expect gigabit dram microprocessor  time faster vax-/ end decade building block network computer containing hundred thousand processor-memory module talk describes characteristic machine make similar prediction secondary tertiary memory 
1993,logp towards realistic model parallel computation,vast body theoretical research focused either overly simplistic model parallel computation notably pram overly specific model representative real world kind model encourage exploitation formal loophole rather rewarding development technique yield performance across range current future parallel machine paper offer new parallel machine model called logp reflects critical technology trend underlying parallel computer intended serve basis developing fast portable parallel algorithm offer guideline machine designer model must strike balance detail simplicity order reveal important bottleneck without making analysis interesting problem intractable model based four parameter specify abstractly computing bandwidth communication bandwidth communication delay efficiency coupling communication computation portable parallel algorithm typically adapt machine configuration term parameter utility model demonstrated example implemented cm-
1992,tradeoff supporting two page size,computer system main memory get larger processor cycles-per-instruction  get smaller time spent handling translation lookaside buffer  miss could become performance bottleneck explore relieving bottleneck  increasing page size  supporting two page sizeswe discus build tlb support two page size examine alternative experimentally dozen uniprogrammed user-mode trace sparc architecture  show increasing page size kb cause significant increase average working set size  significant reduction tlbs contribution cpi cpitlb  compared using kb page  using two page size kb kb page hand show small increase working set size  variable decrease cpitlb  cpitlb using two page size consistently better fully associative tlbs set-associative onesour  preliminary however since  trace include multiprogramming operating system behavior  page-size assignment policy may reflect real operating system policy
1991,towards guideline sigarch sponsored conference,almost  year program chair invent policy offering conference seems time coalesce experience set forth guideline conference sponsored sigarch last business meeting proposed sigarch adopt official set guideline aid program chair matter policy sigarch sponsored conference  attendee meeting voted proposal draft proposed guideline distributed meeting decided proposed guideline appear comment community comment please send final vote content guideline occur next sigarch business meeting held th isca may   queensland australia 
1990,maximizing performance striped disk array,improvement disk speed kept improvement processor memory speed one way correct resulting speed mismatch stripe data across many disk paper address stripe data get maximum performance disk specifically examine choose striping unit ie amount logically contiguous data disk synthesize rule determining best striping unit given range workloadswe show choice striping unit depends two parameter  number outstanding request disk system given time  average positioning time  data transfer rate disk derive equation optimal striping unit function two parameter also show choose striping unit without prior knowledge workload
1990,evaluation redundant array disk using amdahl 5890,recently presented several disk array architecture designed increase data rate i/o rate supercomputing application transaction processing file system  paper present hardware performance measurement two architecture mirroring rotated parity see throughput two architecture affected response time requirement request size read write ratio find application large access many supercomputing application rotated parity disk array far outperforms traditional mirroring architecture application dominated small access transaction processing mirroring architecture higher performance per disk rotated parity architecture
1989,failure correction technique large disk array,ever increasing need ii bandwidth met ever larger array disk array require redundancy protect data loss paper examines alternative choice encoding code reliably store information disk array code selected maximize mean time data loss minimize disk containing redundant data constrained minimize performance penalty associated updating information recovering catastrophic disk failure show code give highly reliable data storage low redundant data overhead array  information disk proliferating processing power provided advanced vlsi technology parallel architecture come inflating demand input/output  performance mainstay online secondary storage magnetic disk providing neither data rate required application process large amount sequential data access rate required application process large number random access  widening gap led i/o system achieve performance disk parallelism using technique disk striping  higher data rate data distributing greater access rate  trend led explore replacement individual large form-factor drive many smaller form-factor drive  electronics general  exponential random variable model rate failure i/o system directly proportional number disk even disk  time reliable best market today first unrecoverable failure non-redundant array thousand disk expected le two week high rate data loss impel inclusion data redundancy allow information survive hardware failure today magnetic disk drive suffer three primary type failure transient noise-related error corrected repeating offending operation applying per sector error-cone & facility
1989,introduction redundant array inexpensive disk raid,author discus various type raid  cost-effective option meet challenge exponential growth processor memory speed argue size reduction personal-computer  disk key success disk array large array mainframe processor possible certainly easier construct array number microprocessor  advantage cost-performance reliability power consumption floor space author expect raid replace large drive future i/o systems< >
1989,reliable raid,disk array offer greatly increased transfer bandwidth low cost without additional data redundancy suffer significantly degraded reliability author examine reliability raid  system find although extremely reliable disk array cannot attained data redundancy alone raid system reliability made better conventional large disk little extra hardware show rest system component host bus adapter power supply fan cannot ignored author present scheme system support component organized group orthogonal data redundancy group thus guaranteeing single disk component failure permanently lose data approach yield disk array reliability  greater conventional disk subsystem reliability improvement sought various part support hardware made redundant author shown affect design -data-disk raid< >
1988,project high performance i/o subsystem,n/a
1988,scalable processor architecture sparc,introduction given sparc architecture interesting feature discussion cover register  instruction including format load/store integer computation control transfer floating-point computation coprocessor brief comparison berkeley risc  soar provided< >
1988,case redundant array inexpensive disk raid,increasing performance cpu memory squandered matched similar performance increase i/o capacity single large expensive disk  grown rapidly performance improvement sled modest redundant array inexpensive disk  based magnetic disk technology developed personal computer offer attractive alternative sled promising improvement order magnitude performance reliability power consumption scalability paper introduces five level raid giving relative cost/performance compare raid ibm  fujitsu super eagle
1988,design xprs,paper present overview technique using build dbms berkeley simultaneously provide high performance high availability transaction processing environment application complex ad-hoc query application large object image cad layout plan achieve goal using general purpose dbms operating system shared memory multiprocessor hardware software tactic using accomplish goal described paper include novel fast path feature special purpose concurrency control scheme two-dimensional file system exploitation parallelism novel method efficiently mirror disk
1987,price smalltalk,anticipation promise tremendous hardware advance software researcher fashioned expansive programming environment improve programmer productivity even march technology exploratory programming environment smalltalk- require expensive computer programmer afford hope increasing community research project university california created reduced instruction set computer smalltalk called soar stand smalltalk risc author able estimate performance implication smalltalk- programming environment next section author list demand smalltalk- place traditional computer system present software hardware idea answer demand
1987,fast multiply divide vlsi floating-point unit,paper present design fast area-efficient multiply-divide unit used building vlsi floating-point processor  conforming ieee standard  detail algorithm implementation technique design tradeoff presented multiplier divider implemented  micron cmos technology two layer metal occupy  square mm  expect perform extended-precision multiplication division   microsecond respectively
1986,in-cache address translation mechanism,design spur high-performance multiprocessor workstation use large cache hardware-supported cache consistency suggests new approach virtual address translation performing translation processor virtually-tagged cache need separate translation lookaside buffer  eliminated eliminating tlb substantially reduces hardware cost complexity translation mechanism eliminates translation consistency problem trace-driven simulation show normal cache behavior minimally affected caching page table entry many case using separate device would actually reduce system performance
1986,evaluation spur lisp architecture,spur microprocessor -bit tagged architecture designed improve performance lisp program although spur includes small set enhancement berkeley risc-ii architecture simulation  show -ns cycle time spur run common lisp program least fast symbolies  dec vax  paper explains spur instruction set architecture provides measurement certain component architecture perform 
1985,reduced instruction set computer,reduced instruction set computer aim simplicity hardware synergy architecture compiler optimizing compiler used compile programming language instruction unencumbered microinstructions large virtual address space make instruction cycle time fast possible 
1984,architecture soar smalltalk risc,smalltalk risc  simple von neumann computer designed execute smalltalk- system much faster existing vlsi microcomputer smalltalk- system highly productive programming environment pose tough challenge implementors dynamic data typing high level instruction set frequent expensive procedure call object-oriented storage management soar compiles program low level efficient instruction set parallel tag check permit high performance simple common case cause trap software routine complex case parallel register initialization multiple on-chip register window speed procedure call sophisticated software technique relieve hardware burden managing object initial evaluation effectiveness soar architecture compiling simulating benchmark prove soar feasibility fabricating -transistor soar chip early  suggest reduced instruction set computer provide high performance exploratory programming environment
1983,architecture vlsi instruction cache risc,cache first used commercial computer  researcher spent last  year analyzing cache suggesting improvement designing vlsi instruction cache risc microprocessor uncovered four idea potentially applicable vlsi machine idea provide expansible cache memory increased cache speed reduced program code size decreased manufacturing cost improvement blur habitual distinction instruction cache instruction fetch unitthe next four section present four architectural idea followed section performance evaluation idea describe implementation cache finally summarize 
1982,vlsi risc,n/a
1982,assessing rjscs high-level language support,reduced instruction set computer risc compared five traditional machine provided highest performance smallest penalty using high-level language
1982,riscy approach computer design,n/a
1982,risc assessment high-level language experiment,present result informal experiment comparing performance one reduced instruction set computer risc five traditional computer vax-/ pdp-/ bbn c/ mc z high-level language environment measuring either absolute performance penalty using high-level language best computer risc
1981,experiment high level language microprogramming verification,strum system created apply software engineering technique microprogramming provides tool allow microprogrammer use high level language structured programming formal program verification create emulation horizontally microprogrammed computer system evaluated two part  high level microprogramming language design use structured microprogramming  verification large microprogram part evaluation include experimental  part includes comparison emulation created using traditional technique emulation created using strum system part ii describes formal verification  line program immediately subjected extensive testing work provides new  efficiency high level microprogramming language effectiveness peephole optimization microcode practicality formal microprogram verification 
1981,v-compiler next-generation tool microprogramming,microprogramming always difficult task related hardware software seems inherited difficulty microprogramming classic reliability maintainability problem software hardware inherited size speed efficiency practically measure success legacy made microprogramming difficult task falk summarized state microprogramming todayat present microprogramming elite activity performed effectively small number expert practitioner work detailed precise time-consuming considerably expensive present-day software programming
1981,vax hardware proposed ieee floating-point standard,proposed ieee floating-point standard implemented substitute floating-point accelerator vax  / explain feature proposed standard influenced design new processor comparing original vax accelerator illustrate difference hardware proposed standard hardware traditional floating-point architecture
1980,design consideration single-chip computer future,mid possible put million device  onto single silicon chip general trend evolution silicon integrated circuit reviewed design constraint emerging vlsi circuit analyzed desirable architectural feature modern computer discussed consequence implementation large-scale integrated circuit investigated resulting recommended processor design includes feature on-chip memory hierarchy multiple homogeneous cache enhanced execution parallelism support complex data structure high-level language flexible instruction set communication hardware concluded viable modular building block next generation computing system self-contained computer single chip tentative allocation one milion transistor various functional block given result memory intensive design
1979,design consideration vlsi processor x-tree,x-node single-chip vlsi processor realized mid used building block tree-structured multiprocessor system  three major trend influence design processor continuing evolution vlsi technology requirement parallelism communication multiprocessor system need better support software high level language construct influence trend processor architecture discussed current state design x-node outlined x-node introduce several new feature exploiting full potential vlsi technology processor hierarchical memory multiple device type combined single chip provide powerful processor basically memory-to-memory architecture on-chip caching scheme provides performance register based architecture on-chip memory hierarchy contains program data well microcode instruction set processor thus dynamically changed tailored specific problem executed planned support high level language construct directly hardware mechanism bound checking
1979,towards efficient machine-independent language microprogramming,machine independent low level language yalll presented language produce microcode two different machine hewlett packard hp  digital equipment corporation vax / efficiency language tested comparing two example machine microassembly coded version best knowledge first time program compiled executed two different microarchitectures example also let u compare efficiency microarchitectures macroarchitectures machine re-examine benefit microprogramming versus macroprogramming conclude paper comment upon transportability high level microprogramming language
1978,communication x-tree modular multiprocessor system,communication network tree-structured assembly  single-chip processor described consideration selecting particular approach discussed communication link processor high-speed byte-parallel connection asynchronous handshaking protocol node x-tree consists powerful processor switching network dedicated communication controller latter check availability link terminating node supervises creation elimination message channel control routing time multiplexing concurrent message link switching network inside x-node connects external link internal processor via fast multiplexed bus interfaced input/output port fifo message buffer network topology routing algorithm addressing scheme message format communication hardware discussed
1978,approach firmware engineering,n/a
1978,x-tree tree structured multi-processor computer architecture,problem organizing multiple monolithic microprocessor effective general purpose computer structure examined tree structure extra interconnection found especially attractive provides structured hierarchy control addressing message routing important appears provide mechanism automatically migrate data abstraction process network processor network expanded desired size global control routine mechanism neededthe potential advantage disadvantage x-tree structure discussed  static simulation presented
1976,strum structured microprogram development system correct firmware,approach development correct microprograms use methodology beneficial generation correct user program e structured programming high-level language  formal program verification using floyds inductive assertion method paper present system combine technique simplify design implementation correct microprograms real microprogrammable computer give statistic support emphasis generation well correctness preliminary  use system
