2018,On Revenue Monotonicity in Combinatorial Auctions.,"Abstract
Along with substantial progress made recently in designing near-optimal mechanisms for multi-item auctions, interesting structural questions have also been raised and studied. In particular, is it true that the seller can always extract more revenue from a market where the buyers value the items higher than another market? In this paper we obtain such a revenue monotonicity result in a general setting. Precisely, consider the revenue-maximizing combinatorial auction for m items and n buyers in the Bayesian setting, specified by a valuation function v and a set F of nm independent item-type distributions. Let REV(v, F) denote the maximum revenue achievable under F by any incentive compatible mechanism. Intuitively, one would expect that
REV(v,G)≥REV(v,F)
R
if distribution G stochastically dominates F. Surprisingly, Hart and Reny (2012) showed that this is not always true even for the simple case when v is additive. A natural question arises: Are these deviations contained within bounds? To what extent may the monotonicity intuition still be valid? We present an approximate monotonicity theorem for the class of fractionally subadditive (XOS) valuation functions v, showing that
REV(v,G)≥cREV(v,F)
R
if G stochastically dominates F under v where
c>0
c
is a universal constant. Previously, approximate monotonicity was known only for the case
n=1
n
: Babaioff et al. (2014) for the class of additive valuations, and Rubinstein and Weinberg (2015) for all subaddtive valuation functions."
2017,Dominant-Strategy versus Bayesian Multi-item Auctions: Maximum Revenue Determination and Comparison.,"We address two related unanswered questions in maximum revenue multi-item auctions. Is dominant-strategy implementation equivalent to the semantically less stringent Bayesian one (as in the case of Myerson's 1-item auction)? Can one find explicit solutions for non-trivial families of multi-item auctions (as in the 1-item case)? In this paper, we present such natural families whose explicit solutions exhibit a revenue gap between the two implementations. More precisely, consider the k-item n-buyer maximum revenue auction where k, n >1 with additive valuation in the independent setting (i.e., the buyers i have independent private distributions Fij on items j). We derive exact formulas for the maximum revenue when k=2 and Fij are any IID distributions on support of size 2, for both the dominant-strategy (DIC) and the Bayesian (BIC) implementations. The formulas lead to the simple characterization that, the two models have identical maximum revenue if and only if selling-separately is optimal for the distribution. Our results also give the first demonstration, in this setting, of revenue gaps between the two models. For instance, if k=n=2 and Pr{X{F = 1} = Pr{XF =2 } = 1/2, then the maximum revenue in the Bayesian implementation exceeds that in the dominant-strategy by exactly 2%; the same gap exists for the continuous uniform distribution XF over [a, a+1] ∪ [2a, 2a+1] for all large a."
2016,Concurrent Knowledge Extraction in Public-Key Models.,"Abstract
Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent, say over the Internet, with players possessing public keys (as is common in cryptography), assuring that entities “know” what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. In such settings, mixing the public-key structure as part of the language and statements is a natural adversarial strategy. Here, we investigate how to formally treat knowledge possession by parties interacting concurrently in the public-key model. More technically, we look into the relative power of the notion of “concurrent knowledge extraction” (CKE) for concurrent zero knowledge (CZK) in the bare public-key (BPK) model, where the language and statements being proved can be dynamically and adaptively chosen by the prover and may be possibly based on verifiers’ public keys. By concrete attacks against some existing natural protocols, we first show that concurrent soundness and normal arguments of knowledge do not guarantee concurrent verifier security in the public-key setting. Here, roughly speaking, concurrent verifier security says that the malicious concurrent prover should “know"" all the witnesses to all the possibly public-key-related statements adaptively chosen and successfully proved in the concurrent sessions. These concrete attacks serve as a good motivation for understanding “possession of knowledge” for concurrent transactions with registered public keys, i.e., the subtleties of concurrent knowledge extraction in the public-key model. This motivates us to introduce and formalize the notion of CKE, along with clarifications of various subtleties. Two implementations are then presented for constant-round concurrently knowledge extractable concurrent zero-knowledge (CZK–CKE) argument for
NP
N
in the BPK model: One protocol is generic and based on standard polynomial-time assumptions, whereas the other protocol is computationally efficient and employs complexity leveraging in a novel way. Both protocols can be practically instantiated for some specific number-theoretic languages without going through general
NP
N
-reductions. Of independent interest are the discussions about the subtleties surrounding the fundamental structure of Feige–Shamir zero knowledge in the BPK model."
2015,Interdisciplinarity: A View from Theory of Computation.,"Increasingly, the concepts and methods of computer science are being recognized as a source of great intellectual interest, injecting fresh ideas into other scientific disciplines. Through discourses and collaborations, exciting multidisciplinary areas are blossoming. We illustrate this phenomenon from the viewpoint of Theory of Computation."
2015,An n-to-1 Bidder Reduction for Multi-item Auctions and its Applications.,n/a
2014,Privacy-Preserving Authenticated Key-Exchange Over Internet.,"Abstract:
Key-exchange, in particular Diffie-Hellman key-exchange (DHKE), is among the core cryptographic mechanisms for ensuring network security. For key-exchange over the Internet, both security and privacy are desired. In this paper, we develop a family of privacy-preserving authenticated DHKE protocols named deniable Internet key-exchange (DIKE), both in the traditional PKI setting and in the identity-based setting. The newly developed DIKE protocols are of conceptual clarity and practical (online) efficiency. They provide useful privacy protection to both protocol participants, and add novelty and new value to the IKE standard. To the best of our knowledge, our protocols are the first provably secure DHKE protocols that additionally enjoy all the following privacy protection advantages: 1) forward deniability, actually concurrent non-malleable statistical zero-knowledge, for both protocol participants simultaneously; 2) the session transcript and session-key can be generated merely from DH-exponents (together with some public values), which thus cannot be traced to the pair of protocol participants; and 3) exchanged messages do not bear peer's identity, and do not explicitly bear player role information."
2013,On revenue maximization for selling multiple independently distributed items.,n/a
2013,Online/Offline Signatures for Low-Power Devices.,"Abstract:
When digital signature is applied on low-power devices, like smart cards, wireless sensors and RFID tags, some specific properties, e.g., better offline storage, more modular and flexible deployment, are desired. To meet these needs, a new variant of the Fiat-Shamir transformation for digital signatures, referred to as Γ -transformation, is introduced and formalized in this work. Following this new transformation approach, some new signature schemes (referred to as Γ-signatures) are presented and discussed. In particular, it is shown that the Γ-signatures for discrete logarithm problem (DLP) developed in this work combine, in essence, the advantages of both Schnorr's signature and the digital signature standard (DSS), while saving from the disadvantages of them both."
2013,OAKE: a new family of implicitly authenticated diffie-hellman protocols.,"Cryptographic algorithm standards play an important role both to the practice of information security and to cryptography theory research. Among them, the KEA and OPACITY (KEA/OPACITY, in short) protocols, and the MQV and HMQV ((H)MQV, in short) protocols, are a family of implicitly authenticated Diffie-Hellman key-exchange (IA-DHKE) protocols that are among the most efficient authenticated key-exchange protocols known and are widely standardized. In this work, from some new design insights, we develop a new family of practical IA-DHKE protocols, referred to as OAKE (standing for ""optimal authenticated key-exchange"" in brief). We show that the OAKE protocol family combines, in essence, the advantages of both (H)MQV and KEA/OPACITY, while saving from or alleviating the disadvantages of them both."
2012,Graph Coloring Applied to Secure Computation in Non-Abelian Groups.,"Abstract
We study the natural problem of secure n-party computation (in the computationally unbounded attack model) of circuits over an arbitrary finite non-Abelian group (G,⋅), which we call G-circuits. Besides its intrinsic interest, this problem is also motivating by a completeness result of Barrington, stating that such protocols can be applied for general secure computation of arbitrary functions. For flexibility, we are interested in protocols which only require black-box access to the group G (i.e. the only computations performed by players in the protocol are a group operation, a group inverse, or sampling a uniformly random group element). Our investigations focus on the passive adversarial model, where up to t of the n participating parties are corrupted.
Our results are as follows. We initiate a novel approach for the construction of black-box protocols for G-circuits based on k-of-k threshold secret-sharing schemes, which are efficiently implementable over any black-box (non-Abelian) group G. We reduce the problem of constructing such protocols to a combinatorial coloring problem in planar graphs. We then give three constructions for such colorings. Our first approach leads to a protocol with optimal resilience t<n/2, but it requires exponential communication complexity
O(
(
2t+1
t
)
2
⋅
N
g
)
group elements and round complexity
O((
2t+1
t
)⋅
N
g
)
, for a G-circuit of size N g . Nonetheless, using this coloring recursively, we obtain another protocol to t-privately compute G-circuits with communication complexity
Poly(n)⋅
N
g
for any t∈O(n 1−ϵ ) where ϵ is any positive constant. For our third protocol, there is a probability δ (which can be made arbitrarily small) for the coloring to be flawed in term of security, in contrast to the first two techniques, where the colorings are always secure (we call this protocol probabilistic, and those earlier protocols deterministic). This third protocol achieves optimal resilience t<n/2. It has communication complexity O(n 5.056(n+log δ −1)2⋅N g ) and the number of rounds is O(n 2.528⋅(n+log δ −1)⋅N g )."
2012,The Turing Computational Model.,"The panel presentations will discuss the beauty and simplicity of the Turing machine formulation of the previously elusive concept of computability and the intuitively satisfying explanation of the power and limitations of computability. They will also review how the Turing machine model provided simple proofs of deep results in logic, including Gödel’s incompleteness theorem. The panel will also examine specifi c results in computer science infl uenced by the Turing machine model as well as how it shaped the development of computational complexity theory. Quantum computing will be discussed and its relationship to the classic Turing machine model. The panel will also discuss what Alan Turing might say about the Inevitable Fallibility of Software."
2012,Quantum Computing: A Great Science in the Making.,"Abstract
In recent years, the scientific world has seen much excitement over the development of quantum computing, and the ever increasing possibility of building real quantum computers. What’s the advantage of quantum computing? What are the secrets in the atoms that could potentially unleash such enormous power, to be used for computing and information processing? In this talk, we will take a look at quantum computing, and make the case that we are witnessing a great science in the making."
2012,Computationally-Fair Group and Identity-Based Key-Exchange.,"Abstract
In this work, we re-examine some fundamental group key-exchange and identity-based key-exchange protocols, specifically the Burmester-Desmedet group key-exchange protocol [7] (referred to as the BD-protocol) and the Chen-Kudla identity-based key-exchange protocol [9] (referred to as the CK-protocol). We identify some new attacks on these protocols, showing in particular that these protocols are not computationally fair. Specifically, with our attacks, an adversary can do the following damages:
It can compute the session-key output with much lesser computational complexity than that of the victim honest player, and can maliciously nullify the contributions from the victim honest players.
It can set the session-key output to be some pre-determined value, which can be efficiently and publicly computed without knowing any secrecy supposed to be held by the attacker.
We remark these attacks are beyond the traditional security models for group key-exchange and identity-based key-exchange, which yet bring some new perspectives to the literature of group and identity-based key-exchange. We then present some fixing approaches, and prove that the fixed protocols are computationally fair."
2011,Tight Approximation Ratio of a General Greedy Splitting Algorithm for the Minimum k-Way Cut Problem.,n/a
2010,Deniable Internet Key Exchange.,"Abstract
In this work, we develop a family of non-malleable and deniable Diffie-Hellman key-exchange (DHKE) protocols, named deniable Internet key-exchange (DIKE). The newly developed DIKE protocols are of conceptual clarity, provide much remarkable privacy protection to protocol participants, and are of highly practical (online) efficiency.
For the security of the DIKE protocols, we formulate the notion of tag-based robust non-malleability (TBRNM) for DHKE protocols, which ensures robust non-malleability for DHKE protocols against concurrent man-in-the-middle (CMIM) adversaries and particularly implies concurrent forward deniability for both protocol participants. We show that the TBRNM security and the session-key security (SK-security) in accordance with the Canetti-Krawczyk framework are mutually complementary, thus much desirable to have DHKE protocols that enjoy both of them simultaneously. We prove our DIKE protocol indeed satisfies both (privacy preserving) TBRNM security and SK-security (with post-specified peers). The TBRNM analysis is based on a variant of the knowledge-of-exponent assumption (KEA), called concurrent KEA assumption introduced and clarified in this work, which might be of independent interest."
2010,Concurrent Knowledge Extraction in the Public-Key Model.,"Abstract
Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent (e.g., over the Internet) with players possessing public-keys (as is common in cryptography), assuring that entities “know” what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. Here, we investigate how to formally treat knowledge possession by parties (with registered public-keys) interacting over the Internet. Stated more technically, we look into the relative power of the notion of “concurrent knowledge-extraction” (CKE) in the concurrent zero-knowledge (CZK) bare public-key (BPK) model where statements being proven can be dynamically and adaptively chosen by the prover.
We show the potential vulnerability of man-in-the-middle (MIM) attacks turn out to be a real security threat to existing natural protocols running concurrently in the public-key model, which motivates us to introduce and formalize the notion of CKE, alone with clarifications of various subtleties. Then, both generic (based on standard polynomial assumptions), and efficient (employing complexity leveraging in a novel way) implementations for
NP
N
are presented for constant-round (in particular, round-optimal) concurrently knowledge-extractable concurrent zero-knowledge (CZK-CKE) arguments in the BPK model. The efficient implementation can be further practically instantiated for specific number-theoretic language."
2009,On the Quantum Query Complexity of Local Search in Two and Three Dimensions.,"Abstract
The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the d-dimensional grid graphs, the complexity has been determined asymptotically for all fixed d≥5, but the lower dimensional cases present special difficulties, and considerable gaps exist in our knowledge. In the present paper we present near-optimal lower bounds, showing that the quantum query complexity for the 2-dimensional grid [n]2 is Ω(n 1/2−δ ), and that for the 3-dimensional grid [n]3 is Ω(n 1−δ ), for any fixed δ>0.
A general lower bound approach for this problem, initiated by Aaronson (based on Ambainis’ adversary method for quantum lower bounds), uses random walks with low collision probabilities. This approach encounters obstacles in deriving tight lower bounds in low dimensions due to the lack of degrees of freedom in such spaces. We solve this problem by the novel construction and analysis of random walks with non-uniform step lengths. The proof employs in a nontrivial way sophisticated results of Sárközy and Szemerédi, Bose and Chowla, and Halász from combinatorial number theory, as well as less familiar probability tools like Esseen’s Inequality."
2009,A note on the feasibility of generalised universal composability.,n/a
2009,A note on universal composable zero-knowledge in the common reference string model.,n/a
2009,Communication Complexity and Its Applications.,"Abstract
For any function f(x, y), its communication complexity is the minimum number of bits needed to be exchanged between two parties holding integers x and y respectively. Invented thirty years ago, communication complexity has been a central research area in theoretical computer science with rich applications to algorithmic problems. In this talk, we give an overview of computational complexity, high-lighting several notable recent results and the diverse mathematical techniques needed for deriving such results."
2008,Graph Design for Secure Multiparty Computation over Non-Abelian Groups.,"Abstract
Recently, Desmedt et al. studied the problem of achieving secure n-party computation over non-Abelian groups. They considered the passive adversary model and they assumed that the parties were only allowed to perform black-box operations over the finite group G. They showed three results for the n-product function f G (x 1,...,x n ) : = x 1 ·x 2 ·...·x n , where the input of party P i is x i  ∈ G for i ∈ {1,...,n}. First, if
t≥⌈
n
2
⌉
then it is impossible to have a t-private protocol computing f G . Second, they demonstrated that one could t-privately compute f G for any
t≤⌈
n
2
⌉−1
in exponential communication cost. Third, they constructed a randomized algorithm with O(n t 2) communication complexity for any
t<
n
2.948
t
.
In this paper, we extend these results in two directions. First, we use percolation theory to show that for any fixed ε> 0, one can design a randomized algorithm for any
t≤
n
2+ϵ
t
using O(n 3) communication complexity, thus nearly matching the known upper bound
⌈
n
2
⌉−1
. This is the first time that percolation theory is used for multiparty computation. Second, we exhibit a deterministic construction having polynomial communication cost for any t = O(n 1 − ε ) (again for any fixed ε> 0). Our results extend to the more general function
f
˜
G
(
x
1
,…,
x
m
):=
x
1
⋅
x
2
⋅…⋅
x
m
where m ≥ n and each of the n parties holds one or more input values."
2008,Some Perspectives on Complexity-Based Cryptography.,"Abstract
In the 1940’s, Shannon applied his information theory to build a mathematical foundation for classical cryptography which studies how information can be securely encrypted and communicated. In the internet age, Turing’s theory of computation has been summoned to augment Shannon’s model and create new frameworks, under which numerous cryptographic applications have blossomed. Fundamental concepts, such as ‘‘information” and ‘‘knowledge transfer”, often need to be re-examined and reformulated. The amalgamation process is still on-going in view of the many unsolved security issues. In this talk we give a brief overview of the background, and discuss some of the recent developments in complexity-based cryptography. We also raise some open questions and explore directions for future work."
2008,"Generalized Tsirelson Inequalities, Commuting-Operator Provers, and Multi-prover Interactive Proof Systems.","Abstract:
A central question in quantum information theory and computational complexity is how powerful nonlocal strategies are in cooperative games with imperfect information, such as multi-prover interactive proof systems. This paper develops a new method for proving limits of nonlocal strategies that make use of prior entanglement among players (or, provers, in the terminology of multi-prover interactive proofs). Instead of proving the limits for usual isolated provers who initially share entanglement, this paper proves the limits for ""commuting-operator provers"", who share private space, but can apply only such operators that are commutative with any operator applied by other provers. Obviously, these commuting-operator provers are at least as powerful as usual isolated but prior-entangled provers, and thus, limits in the model with commuting-operator provers immediately give limits in the usual model with prior-entangled provers. Using this method, we obtain an n-party generalization of the Tsirelson bound for the Clauser-Horne-Shimony-Holt inequality, for every n. Our bounds are tight in the sense that, in every n-party case, the equality is achievable by a usual nonlocal strategy with prior entanglement. We also apply our method to a three-prover one-round binary interactive proof system for NEXP. Combined with the technique developed by Kempe, Kobayashi, Matsumoto, Toner and Vidick to analyze the soundness of the proof system, it is proved to be NP-hard to distinguish whether the entangled value of a three-prover one-round binary-answer game is equal to one or at most 1-1/p(n) for some polynomial p, where n is the number of questions. This is in contrast to the two-prover one-round binary-answer case, where the corresponding problem is efficiently decidable. Alternatively, NEXP has a three-prover one-round binary interactive proof system with perfect completeness and soundness 1 middot 2 -poly ."
2007,Oblivious and Adaptive Strategies for the Majority and Plurality Problems.,n/a
2007,A Note on Universal Composable Zero Knowledge in Common Reference String Model.,"Abstract
Pass observed that universal composable zero-knowledge (UCZK) protocols in the common reference string (CRS) model, where a common reference string is selected trustily by a trusted third party and is known to all players, lose deniability that is a natural property of any ZK protocol in the plain model [33]. An open problem (or, natural query) raised in the literature is: are there any other essential security properties, other than the well-known deniability property, that could be lost by universal composable zero-knowledge in the common reference string model, in comparison with UC security in the plain model? In this work, we answer this open question (or, natural query), by showing that UCZK protocols in the CRS model could lose concurrent general composability (CGC) and proof of knowledge (POK) properties that are very important and essential security implications of UCZK in the plain model. This is demonstrated by concrete attacks."
2007,A Note on the Feasibility of Generalized Universal Composability.,"Abstract
We clarify the potential limitation of the general feasibility for generalized universal composability (GUC) proposed in the recent work [8], and discuss a general principle for fully realizing universal composability. This in particular demonstrates the hardness of achieving generalized universal composability, and prevents potential misinterpretation in applications. We also propose some fixing approaches, which involve a source/session-authentic ID-based trapdoor commitment scheme via the hash-then-commit paradigm that could possibly be of independent interest."
2006,Discrete and continuous min-energy schedules for variable voltage processors.,n/a
2006,On the Quantum Query Complexity of Local Search in Two and Three Dimensions.,"Abstract:
The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the d-dimensional grid graphs, the complexity has been determined asymptotically for all fixed d ges 5, but the lower dimensional cases present special difficulties, and considerable gaps exist in our knowledge. In the present paper we present near-optimal lower bounds, showing that the quantum query complexity for the 2-dimensional grid [n] 2 is Omega(n frac12 - delta ), and that for the 3-dimensional grid [n] 3 is Omega(n 1 - delta ), for any fixed delta > 0. A general lower bound approach for this problem, initiated by Aaronson (2004) (based on Ambainis' adversary method (2003) for quantum lower bounds), uses random walks with low collision probabilities. This approach encounters obstacles in deriving tight lower bounds in low dimensions due to the lack of degrees of freedom in such spaces. We solve this problem by the novel construction and analysis of random walks with non-uniform step lengths. The proof employs in a nontrivial way sophisticated results of Sarkozy and Szemeridi (1965), Bose and Chowla (1962-63), and Halasz (1977) from combinatorial number theory, as well as less familiar probability tools like Esseen's inequality"
2006,Some perspectives on computational and communication complexity.,"Abstract:
Summary form only given,as follows. In past decades, the theory of computational complexity has fl ourished in terms of both the revelation of its internal structures and the unfolding of its numerous applications. In this talk we discuss several persistent and interwoven themes underlying many of these accomplishments. In particular we shall focus on the interplay between communication and computation which has a key role in these developments. We also speculate on promising future directions in the study of computational and communication complexity."
2006,Recent Progress in Quantum Computational Complexity.,"Abstract
With rapid advances in technology, it appears that computing and communication devices based on quantum principles may become available in the not too distant future. A central question addressed by the emerging research field quantum computational complexity is: how much can quantum devices speed up computation and communication over classical devices? In this talk we discuss recent developments in quantum computational complexity regarding communication complexity, query complexity and interactive proofs. We also examine directions for future research."
2005,Oblivious and Adaptive Strategies for the Majority and Plurality Problems.,"Abstract
In the well-studied Majority problem, we are given a set of n balls colored with two or more colors, and the goal is to use the minimum number of color comparisons to find a ball of the majority color (i.e., a color that occurs for more than ⌈ n/2 ⌉ times). The Plurality problem has exactly the same setting while the goal is to find a ball of the dominant color (i.e., a color that occurs most often). Previous literature regarding this topic dealt mainly with adaptive strategies, whereas in this paper we focus more on the oblivious (i.e., non-adaptive) strategies. Given that our strategies are oblivious, we establish a linear upper bound for the Majority problem with arbitrarily many different colors. We then show that the Plurality problem is significantly more difficult by establishing quadratic lower and upper bounds. In the end, we also discuss some generalized upper bounds for adaptive strategies in the k-color Plurality problem."
2005,On the Communication Complexity of Co-linearity Problems.,"Abstract
In the k-party simultaneous message model, k–1 parties holding respectively x 1,x 2, ⋯, x k − − 1 wish to compute the value of some boolean function f(x 1,x 2,..., x k − − 1), by each sending a stochastically chosen message to a k-th party, the referee, who then decides on the value of f with probability at least 2/3 of being correct. Let R ||(f) be the minimum number of total communication bits needed to compute f by any such algorithm.
The (k,n)-Co-Linearity Problem is defined by CL k,n (x 1,x 2,...,x k − − 1) = 1, if and only if ⊕1 ≤ i ≤ k− − 1 x i =0 n (where x i are n-bit strings). It is well known that, for any fixed k ≥ 3,
R
||
(C
L
k,n
)=O(
n
(k−2)/(k−1)
)
R
, and that the bound is tight for k=3. It is an interesting open question whether the bound is tight for k>3. In this talk we present some new results on this question. Specifically, we prove that the above bound is tight in the linear model, in which all the transmitted message bits are linear functions of the input bits. We also discuss CL k,n ’s quantum communication complexity, which also has received considerable attention in recent years."
2004,Self testing quantum apparatus.,"We study, in the context of quantum information and quantum communication, a configuration of devices that includes (1) a source of some unknown bipartite quantum state that is claimed to be the Bell state Φ+ and (2) two spatially separated but otherwise unknown measurement apparatus one on each side, that are each claimed to execute an orthogonal measurement at an angle θ ∈ {-π/8, 0, π/8} that is chosen by the user. We show that, if the nine distinct probability distributions that are generated by the self checking configuration, one for each pair of angles, are consistent with the specifications, the source and the two measurement apparatus are guaranteed to be identical to the claimed specifications up to a local change of basis on each side. We discuss the connection with quantum cryptography."
2004,Graph Properties and Circular Functions: How Low Can Quantum Query Complexity Go?,"Abstract:
In decision tree models, considerable attention has been paid on the effect of symmetry on computational complexity. That is, for a permutation group /spl Gamma/, how low can the complexity be for any Boolean function invariant under /spl Gamma/? In this paper, we investigate this question for quantum decision trees for graph properties, directed graph properties, and circular functions. In particular, we prove that the n-vertex Scorpion graph property has quantum query complexity /spl Theta//sup /spl tilde// (n/sup 1/2/), which implies that the minimum quantum complexity for graph properties is strictly less than that for monotone graph properties (known to be /spl Omega/(n/sup 2/3/)). A directed graph property, SINK, is also shown to have the /spl Theta//sup /spl tilde//(n/sup 1/2/) quantum query complexity. Furthermore, we give an N-ary circular function which has the quantum query complexity /spl Theta/ /sup /spl tilde//(N/sup 1/4/). Finally, we show that for any permutation group /spl Gamma/, as long as /spl Gamma/ is transitive, the quantum query complexity of any function invariant to /spl Gamma/ is at least /spl Omega/(N/sup 1/4/), which implies that our examples are (almost) the best ones in the sense of pinning down the complexity for the corresponding permutation group."
2004,Fisher Equilibrium Price with a Class of Concave Utility Functions.,"Abstract
In this paper we study efficient algorithms for computing equilibrium price in the Fisher model for a class of nonlinear concave utility functions, the logarithmic utility functions. We derive a duality relation between buyers and sellers under such utility functions, and use it to design a polynomial time algorithm for calculating equilibrium price, for the special case when either the number of sellers or the number of buyers is bounded by a constant."
2004,Dynamic Price Sequence and Incentive Compatibility (Extended Abstract).,"Abstract
We introduce and study a new auction model in which a certain type of goods is offered over a period of time, and buyers arrive at different times and stay until a common deadline (unless their purchase requests have been fulfilled). We examine in this model incentive compatible auction protocols (i.e., those that induce participants to bid their true valuations).
We establish an interesting connection between incentive compatibility and price sequence: incentive compatibility forces a non-decreasing price sequence under some assumptions on market pricing schemes. We should point out that negation of our assumptions would require market distortions to some extent.
Our protocol may not ensure that one item must be sold everyday. Imposing such a market intervention, we show an impossibility result that deterministic incentive compatible auction protocols do not exist. With randomized relaxation, we give such an incentive compatible auction protocol. We also discuss incentive compatible protocols under other market conditions."
2004,Graph entropy and quantum sorting problems.,"Let P = (X, < P) be a partial order on a set of n elements X = x1, x2,..., xn. Define the quantum sorting problem QSORTP as: given n distinct numbers x1, x2,..., xn consistent with P, sort them by a quantum decision tree using comparisons of the form ""xi: xj"". Let Qε(P) be the minimum number of queries used by any quantum decision tree for solving QSORTP with error less than ε (where 0 < ε < 1/10 is fixed). It was proved by Hoyer, Neerbek and Shi (Algorithmica 34 (2002), 429--448) that, when P0 is the empty partial order, Qε(P0) ≥ Ω (n log n), i. e., the classical information lower bound holds for quantum decision trees when the input permutations are unrestricted.In this paper we show that the classical information lower bound holds, up to an additive linear term, for quantum decision trees for any partial order P. Precisely, we prove Qε(P) ≥ c log2 e(P)-c'n where c,c' > 0 are constants and e(P) is the number of linear orderings consistent with P. Our proof builds on an interesting connection between sorting and Korner's graph entropy that was first noted and developed by Kahn and Kim (JCSS 51(1995), 390--399)."
2003,Classical physics and the Church-Turing Thesis.,"Would physical laws permit the construction of computing machines that are capable of solving some problems much faster than the standard computational model? Recent evidence suggests that this might be the case in the quantum world. But the question is of great interest even in the realm of classical physics. In this article, we observe that there is fundamental tension between the Extended Church--Turing Thesis and the existence of numerous seemingly intractable computational problems arising from classical physics. Efforts to resolve this incompatibility could both advance our knowledge of the theory of computation, as well as serve the needs of scientific computing."
2003,Interactive Proofs for Quantum Computation.,"Abstract
It is by now well established that quantum machines can solve certain computational problems much faster than the best algorithms known in the standard Turing machine model. The complexity question of which problems can be feasibly computed by quantum machines has also been extensively investigated in recent years, both in the context of one machine models (quantum polynomial classes) and various flavors of multi-machine models (single and multiple prover quantum interactive proofs). In this talk we examine the more general (but less theoretically investigated) question of which quantum states can be feasibly computed. Specifically, we will focus on the question of what quantum states can be generated by quantum interactive proofs. We will show that several classical interactive proof theorems have analogs in such models. For example, we show that any quantum state computable in quantum polynomial space has a 2-prover quantum interactive proof. Open questions will be discussed."
2003,On the power of quantum fingerprinting.,"In the simultaneous message model, two parties holding n-bit integers x,y send messages to a third party, the referee, enabling him to compute a boolean function f(x,y). Buhrman et al [3] proved the remarkable result that, when f is the equality function, the referee can solve this problem by comparing short ""quantum fingerprints"" sent by the two parties, i.e., there exists a quantum protocol using only O(log n) bits. This is in contrast to the well-known classical case for which Ω(n1/2) bits are provably necessary for the same problem even with randomization. In this paper we show that short quantum fingerprints can be used to solve the problem for a much larger class of functions. Let R<??par line>,pub(f) denote the number of bits needed in the classical case, assuming in addition a common sequence of random bits is known to all parties (the public coin model). We prove that, if R<??par line>,pub(f)=O(1), then there exists a quantum protocol for f using only O(log n) bits. As an application we show that O(log n) quantum bits suffice for the bounded Hamming distance function, defined by f(x,y)=1 if and only if x and y have a constant Hamming distance d or less."
2002,"Read-Once Branching Programs, Rectangular Proofs of the Pigeonhole Principle and the Transversal Calculus.","We investigate read-once branching programs for the following search problem: given a Boolean m × n matrix with m > n, ﬁnd either an all-zero row, or two 1’s in some column. Our primary motivation is that this models regular resolution proofs of the pigeonhole principle
PH
P
m
n
P
, and that for m > n 2 no lower bounds are known for the length of such proofs. We prove exponential lower bounds (for arbitrarily large m!) if we further restrict this model by requiring the branching program either to finish one row of queries before asking queries about another row (the row model) or put the dual column restriction (the column model).
Then we investigate a special class of resolution proofs for
PH
P
m
n
P
that operate with positive clauses of rectangular shape; we call this fragment the rectangular calculus. We show that all known upper bounds on the size of resolution proofs of
PH
P
m
n
P
actually give rise to proofs in this calculus and, inspired by this fact, also give a remarkably simple “rectangular” reformulation of the Haken–Buss–Turán lower bound for the case m ≪ n 2. Finally we show that the rectangular calculus is equivalent to the column model on the one hand, and to transversal calculus on the other hand, where the latter is a natural proof system for estimating from below the transversal size of set families. In particular, our exponential lower bound for the column model translates both to the rectangular and transversal calculi."
2001,Informational Complexity and the Direct Sum Problem for Simultaneous Message Complexity.,"Abstract:
Given m copies of the same problem, does it take m times the amount of resources to solve these m problems? This is the direct sum problem, a fundamental question that has been studied in many computational models. We study this question in the simultaneous message (SM) model of communication introduced by A.C. Yao (1979). The equality problem for n-bit strings is well known to have SM complexity /spl Theta/(/spl radic/n). We prove that solving m copies of the problem has complexity /spl Omega/(m/spl radic/n); the best lower bound provable using previously known techniques is /spl Omega/(/spl radic/(mn)). We also prove similar lower bounds on certain Boolean combinations of multiple copies of the equality function. These results can be generalized to a broader class of functions. We introduce a new notion of informational complexity which is related to SM complexity and has nice direct sum properties. This notion is used as a tool to prove the above results; it appears to be quite powerful and may be of independent interest."
2001,Some perspective on computational complexity (abstract).,"In past decades, the theory of computational complexity has flourished in terms of both the revelation of its internal structures and the unfolding of its numerous applications. In this paper we discuss several persistent and interwoven themes underlying many of these accomplishments. Chief among them are the interplay between communication and computation, the power of problem reduction, and the increasingly prominent role played by classical mathematics. We will also speculate on a few promising directions for future development of computational complexity."
2000,Quantum bit escrow.,
1999,NQPC = co-C=P.,n/a
1998,An exponential lower bound on the size of algebraic decision trees for Max.,n/a
1998,RAPID: Randomized pharmacophore identification for drug design.,n/a
1998,Quantum Cryptography with Imperfect Apparatus.,"Abstract:
Quantum key distribution, first proposed by C.H. Bennett and G. Brassard (1984), provides a possible key distribution scheme whose security depends only on the quantum laws of physics. So far the protocol has been proved secure even under channel noise and detector faults of the receiver but is vulnerable if the photon source used is imperfect. In this paper we propose and give a concrete design for a new concept, self-checking source, which requires the manufacturer of the photon source to provide certain tests; these tests are designed such that, if passed, the source is guaranteed to be adequate for the security of the quantum key distribution protocol, even though the testing devices may not be built to the original specification. The main mathematical result is a structural theorem which states that, for any state in a Hilbert space, if certain EPR-type equations are satisfied, the state must be essentially the orthogonal sum of EPR pairs."
1997,Dictionary Look-Up with One Error.,n/a
1997,Decision Tree Complexity and Betti Numbers.,n/a
1997,RAPID: Randomized Pharmacophore Identification for Drug Design.,
1997,"Read-Once Branching Programs, Rectangular Proofs of the Pigeonhole Principle and the Transversal Calculus.",
1996,Hypergraphs and Decision Trees (Abstract).,"Abstract
We survey some recent results on a space decomposition problem that has a close relationship to the size of algebraic decision trees. These results are obtained by establishing connections between the decomposition problem and some extremal questions in hypergraphs.
Let d, n ≥ 1 be integers. A d-elementary cell is a set D
⊆
R n defined by a finite set of constraints f i (x)=0, g j (x) > 0 where f i , g j are polynomials of degrees not exceeding d. For any set S
⊆
R n , let κ d (S) be the smallest number of disjoint d-elementary cells that S can be decomposed into. It is easy to see that any degree-d (ternary) algebraic decision tree for solving the membership question of S must have size no less than κ d (S). Thus, any lower bound to κ d (S) yields also a lower bound the size complexity for the corresponding membership problem.
Let A n ={(x1,x2,...,xn) ¦ x i ≥ 0}. A well-known result of Rabin states that any algebraic decision tree for the membership question of A n must have height at least n. In this talk we discuss a recent result by Grigoriev, Karpinski and Yao [GKY], which gives an exponential lower bound to κ d (A n ) for any fixed d, and hence to the size of any fixed degree (ternary) algebraic decision tree for solving this problem. The proof utilizes a new connection between κ d (A n ) and the maximum number of minimal cutsets for any rank-d hypergraph on n vertices. We also discuss an improved lower bound by Wigderson and Yao [WY]. Open questions are presented."
1995,Minimean Optimal Key Arrangements in Hash Tables.,"Abstract
For an open-addressing hash functionh and a setA ofn keys, letCh(A) be the expected retrieval cost when the keys are arranged to minimize the expected retrieval cost in a full table. It is shown that, asymptotically for largen, whenh satisfies a certain doubly dispersive property, as is the case for double hashing,C h (A)=0(1) with probability 1 − 0(1) for a randomA."
1995,On Computing Algebraic Functions Using Logarithms and Exponentials.,n/a
1995,Algebraic Decision Trees and Euler Characteristics.,n/a
1995,On the Shrinkage Exponent for Read-Once Formulae.,n/a
1995,Dictionary Loop-Up with Small Errors.,"Abstract
Let W be a set of n binary strings of length m each. We are interested in designing data structures for W that can answer d-queries quickly, that is, given a binary string α, decide whether there is any member of W within Hamming distance d of α. This problem, originally raised by Minsky and Papert [MP], remains a challenge in data structure design. In this paper, we make an initial effort towards a theoretical study of the small d case. Our main result is a data structure that achieves O(m log log n) query time with O(nm log m) space for the d = 1 case."
1995,Security of quantum protocols against coherent measurements.,
1994,A Randomized Algorithm for Finding Maximum with O((log n)²) Polynomial Tests.,n/a
1994,Near-Optimal Time-Space Tradeoff for Element Distinctness.,n/a
1994,A Lower Bound for the Monotone Depth of Connectivity.,"Abstract:
We show that any monotone circuit for computing graph connectivity must have a depth greater than /spl Omega/((log n)/sup 3/2// log log n). This proves that UCONN/sub n/ is not in monotone NC/sup 1/. The proof technique, which is an adaptation of Razborov's approximation method, is also used to derive lower bounds for a general class of graph problems.< >"
1994,Decision tree complexity and Betti numbers.,
1993,A Circuit-Based Proof of Toda's Theorem.,n/a
1993,Towards Uncheatable benchmarks.,"Abstract:
The problem of how to make benchmarks resistant to tampering and hence more trustworthy is studied. Some schemes that are based on modern cryptography and complexity theory are proposed to make benchmarks uncheatable. The philosophy is the same as that of encryption-decryption schemes, namely, that trust in individuals and organizations is replaced by trust in the impossibility of breaking certain computational problems.< >"
1993,Quantum Circuit Complexity.,"Abstract:
We propose a complexity model of quantum circuits analogous to the standard (acyclic) Boolean circuit model. It is shown that any function computable in polynomial time by a quantum Turing machine has a polynomial-size quantum circuit. This result also enables us to construct a universal quantum computer which can simulate, with a polynomial factor slowdown, a broader class of quantum machines than that considered by E. Bernstein and U. Vazirani (1993), thus answering an open question raised by them. We also develop a theory of quantum communication complexity, and use it as a tool to prove that the majority function does not have a linear-size quantum formula.< >"
1993,Groups and Algebraic Complexity (Abstract).,"Abstract
In recent years, concepts from group theory have played an important role in the derivation of lower bounds for computational complexity. In this talk we present two new results in algebraic complexity obtained with group-theoretical arguments. We show that any algebraic computation tree for the membership question of a compact set S in Rn must have height Ω(log(βi(S)))−cn for all i, where βi are the Betti numbers. We also show that, to compute the sum of n independent radicals using logarithms, exponentiations and root-takings, at least n operations are required. (The second result was obtained jointly with Dima Grigoriev and Mike Singer.) This talk will be self-contained."
1992,Algebraic Decision Trees and Euler Characteristics.,"Abstract:
For any set S contained in R/sup n/, let chi (S) denote its Euler characteristic. The author shows that any algebraic computation tree or fixed-degree algebraic decision tree must have height Omega (log mod chi (S) mod )for deciding the membership question of a compact semi-algebraic set S. This extends a result by A. Bjorner, L. Lovasz and A. Yao where it was shown that any linear decision tree for deciding the membership question of a closed polyhedron S must have height greater than or equal to log/sub 3/ mod chi (S) mod .< >"
1992,Linear Decision Trees: Volume Estimates and Topological Bounds.,
1991,Lower Bounds to Randomized Algorithms for Graph Properties.,n/a
1991,Lower Bounds for Algebraic Computation Trees with Integer Inputs.,n/a
1991,Recent Progress in Circuit and Communication Complexity (Abstract).,n/a
1991,Program Checkers for Probability Generation.,n/a
1991,Weighted Random Assignments with Application to Hashing.,"Abstract
In this talk we will study the optimal solution to a class of random assignment problems with dependent weights. The result is then used to show that, in double hashing, the expected retrieval cost with respect to an optimal static hash table is O(1) even if the table is full. This confirms a conjecture of Gonnet and Munro (SIAM J. on Computing 8 (1979), 463–478)."
1990,On Evaluating Boolean Functions with Unreliable Tests.,n/a
1990,On ACC and Threshold Circuits.,"Abstract:
It is proved that any language in ACC can be approximately computed by two-level circuits of size 2 raised to the (log n)/sup k/ power, with a symmetric-function gate at the top and only AND gates on the first level. This implies that any language in ACC can be recognized by depth-3 threshold circuits of that size. This result gives the first nontrivial upper bound on the computing power of ACC circuits.<>"
1990,Coherent Functions and Program Checkers (Extended Abstract).,
1989,On Selecting the k Largest with Median Tests.,n/a
1989,On the Complexity of Partial Order Productions.,n/a
1989,Lower Bounds for Algebraic Computation Trees with Integer Inputs.,"Abstract:
A proof is given of a general theorem showing that for certain sets W a certain topological lower bound is valid in the algebraic computation tree model, even if the inputs are restricted to be integers. The theorem can be used to prove tight lower bounds for the integral-constrained form of many basic problems, such as element distinctness, set disjointness, and finding the convex hull. Through further transformations it leads to lower bounds for problems such as the integer max gap and closest pair of a simple polygon. The proof involves a nontrivial extension of the Milnor-Thom techniques for finding upper bounds on the Betti numbers of algebraic varieties.< >"
1989,Circuits and Local Computation.,"This paper contains two parts. In Part I, we show that polynomial-size monotone threshold circuits of depth k form a proper hierarchy in parameter k. This implies in particular that monotone TC0 is properly contained in NC1. In Part II, we introduce a new concept, called local function, which tries to characterize when a function can be efficiently computed using only localized processing elements. It serves as a unifying framework for viewing related and sometimes apparently unrelated results. In particular, it will be demonstrated that the recent results on lower bounds for monotone circuits by Razborov [Ra1] and Karchmer and Wigderson [KW], as well as a main theorem in Part I of this paper, can be regarded as proving certain functions to be nonlocal. We will also suggest an approach based on locality for attacking the conjecture that (nonmonotone) TC0 is properly contained in NC1."
1989,On the Improbability of Reaching Byzantine Agreements (Preliminary Version).,"It is well known that for the Byzantine Generals Problem, no deterministic protocol can exist for an n-processor system if the number t of faulty processors is allowed to be as large as n/3. In this paper we investigate the maximum achievable agreement probability &Bgr;n,t in a model in which the faulty processors can be as devious and powerful as possible. We also discuss a restricted model with &Bgr;n,t denoting the corresponding maximum achievable probability. We will prove that: (i) for n = 3, t = 1 (the first nontrivial case), &Bgr;3,1 = (√5 - 1)/2 (the reciprocal of the golden ratio); (ii) for all &egr; with 0 < &egr; < 1, if t/n > 1 - log (1 -&egr;)1/2/ log (1 - (1 -&egr;)1/2) then &Bgr;tn,t < &egr;"
1988,Monotone Bipartite Graph Properties are Evasive.,n/a
1988,Near-Optimal Time-Space Tradeoff for Element Distinctness.,"Abstract:
It was conjectured by A. Borodin et al. that to solve the element distinctness problem requires TS= Omega (n/sup 2/) on a comparison-based branching program using space S and time T, which, if true, would be close to optimal since TS=O(n/sup 2/ log n) is achievable. They showed recently (1987) that TS= Omega (n/sup 3/2/(log n)/sup 1/2/). The author shows a near-optimal tradeoff TS= Omega (n/sup 2- epsilon (n)/), where epsilon (n)=O(1/(log n)/sup 1/2/).< >"
1987,Lower Bounds to Randomized Algorithms for Graph Properties (Extended Abstract).,"Abstract:
For any property P on n-vertex graphs, let C(P) be the minimum number of edges that need to be examined by any decision tree algorithm for determining P. In 1975 Rivest and Vuillemin settled the Aanderra-Rosenberg Conjecture, proving that C(P) = Ω(n2) for every nontrivial monotone graph property P. An intriguing open question is whether the theorem remains true when randomized algorithms are allowed. In this paper we report progress on this problem, showing that Ω(n(log n)1/12) edges must be examined by a randomized algorithm for determining any nontrivial monotone graph property."
1986,How to Generate and Exchange Secrets (Extended Abstract).,"Abstract:
In this paper we introduce a new tool for controlling the knowledge transfer process in cryptographic protocol design. It is applied to solve a general class of problems which include most of the two-party cryptographic problems in the literature. Specifically, we show how two parties A and B can interactively generate a random integer N = p·q such that its secret, i.e., the prime factors (p, q), is hidden from either party individually but is recoverable jointly if desired. This can be utilized to give a protocol for two parties with private values i and j to compute any polynomially computable functions f(i,j) and g(i,j) with minimal knowledge transfer and a strong fairness property. As a special case, A and B can exchange a pair of secrets sA, sB, e.g. the factorization of an integer and a Hamiltonian circuit in a graph, in such a way that sA becomes computable by B when and only when sB becomes computable by A. All these results are proved assuming only that the problem of factoring large intergers is computationally intractable."
1985,Uniform Hashing Is Optimal.,"It was conjectured by J. Ullman that uniform hashing is optimal in its expected retrieval cost among all open-address hashing schemes [4]. In this paper, we show that, for any open-address hashing scheme, the expected cost of retrieving a record from a large table that is &agr;-fraction full is at least (1/&agr;) log (1/(1 - &agr;)) + o(1). This proves Ullman's conjecture to be true in the asymptotic sense."
1985,On Optimal Arrangements of Keys with Double Hashing.,n/a
1985,On Fault-Tolerant Networks for Sorting.,n/a
1985,On the Expected Performance of Path Compression Algorithms.,n/a
1985,On the Complexity of Maintaining Partial Sums.,n/a
1985,Separating the Polynomial-Time Hierarchy by Oracles (Preliminary Version).,"Abstract:
We present exponential lower bounds on the size of depth-k Boolean circuits for computing certain functions. These results imply that there exists an oracle set A such that, relative to A, all the levels in the polynomial-time hierarchy are distinct, i.e., ΣkP,A is properly contained in Σk+1P,A for all k."
1985,A General Approach to d-Dimensional Geometric Queries (Extended Abstract).,"It is shown that any bounded region in Ed can be divided into 2d subregions of equal volume in such a way that no hyperplane in Ed can intersect all 2d of the subregions. This theorem provides the basis of a data structure scheme for organizing n points in d dimensions. Under this scheme, a broad class of geometric queries in d dimensions, including many common problems in range search and optimization, can be solved in linear storage space and sublinear time."
1983,On the security of public key protocols.,"Abstract:
Recently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characterizations that can be used to determine protocol security in these models are given."
1983,Lower Bounds by Probabilistic Arguments (Extended Abstract).,"Abstract:
The purpose of this paper is to resolve several open problems in the current literature on Boolean circuits, communication complexity, and hashing functions. These lower bound results share the common feature that their proofs utilize probabilistic arguments in an essential way. Specifically, we prove that, to compute the majority function of n Boolean variables, the size of any depth-3 monotone circuit must be greater than 2nε, and the size of any width-2 branching program must have super-polynomial growth. We also show that, for the problem of deciding whether i ≤ j for two n-bit integers i and j, the probabilistic ε-error one-way communication complexity is of order θ(n), while the two-way ε-error complexity is O((log n)2). We will also prove that, to compute i · j mod p for an n-bit prime p, the probabilistic ε-error two-way communication complexity is of order θ(n). Finally, we prove a conjecture of Ullman that uniform hashing is asymptotically optimal in its expected retrieval cost among open address hashing schemes."
1983,Strong Signature Schemes.,"The notion of digital signature based on trapdoor functions has been introduced by Diffie and Hellman[3]. Rivest, Shamir and Adleman[8] gave the first number theoretic implementation of a signature scheme based on a trapdoor function. If f is a trapdoor function and m a message, f−1(m) is the signature of m. The signature can be verified by computing f(f−1(m)) = m. This approach presents the following problems even when f is hard to invert: 1) there may be special message spaces (or subsets of them) that are easy to sign without knowing the trapdoor information 2) it is possible to forge the signature of random numbers; this violates the requirements of many protocols 3) given a polynomial number of signed messages, it may be possible to sign a new one without knowing the trapdoor information. We solve the above problems by exhibiting two signature schemes for which any strategy of an adversary, who has seen all previously signed messages, that has a moderate success in forging even a single additional signature, is transformable to a fast algorithm for factoring or inverting the RSA function. This provably holds for all message spaces with all possible Probability distributions. Thus, in particular, given the signature of m, forging the signature of m+1 or 2m or 2sm is as hard as factoring. The two signature schemes"
1982,On Parallel Computation for the Knapsack Problem.,
1982,Lower Bounds for Algebraic Decision Trees.,n/a
1982,The Complexity of Finding Cycles in Periodic Functions.,n/a
1982,On the Average-Case Complexity of Selecting the kth Best.,n/a
1982,On Constructing Minimum Spanning Trees in k-Dimensional Spaces and Related Problems.,n/a
1982,On the Time-Space Tradeoff for Sorting with Linear Queries.,n/a
1982,On Signatures and Authentication.,"Abstract
The design of cryptographic protocols using trapdoor and one-way functions has received considerable attention in the past few years [1–8]. More recently, attention has been paid to provide rigorous correctness proofs based on simple mathematical assumptions, for example, in coin flipping (Blum [1]), mental poker (Goldwasser and Micali [4]). It is perhaps reasonable to speculate at this time that all cryptographic protocols can eventually be designed to be provably secure under simple assumptions, such as factoring large numbers or inverting RSA functions are computationally intractable in the appropriate sense."
1982,Theory and Applications of Trapdoor Functions (Extended Abstract).,"Abstract:
The purpose of this paper is to introduce a new information theory and explore its appplications. Using modern computational complexity, we study the notion of information that can be accessed through a feasible computation. In Part 1 of this paper, we lay the foundation of the theory and set up a framework for cryptography and pseudorandom number generation. In Part 2, we study the concept of trapdoor functions and examine applications of such functions in cryptography, pseudorandom number generation, and abstract complexity theory."
1982,Protocols for Secure Computations (Extended Abstract).,"Abstract:
The author investigates the following problem: Suppose m people wish to compute the value of a function f(x 1 , x 2 , x 3 , ..., x m ), which is an integer-valued function of m integer variables xi of bounded range. Assume initially person Pi knows the value of xi and no other x's. Is it possible for them to compute the value of f, by communicating among themselves, without unduly giving away any information about the values of their own variables? The author gives a precise formulation of this general problem and describe three ways of solving it by use of one-way functions (i.e., functions which are easy to evaluate but hard to invert). These results have applications to secret voting, private querying of database, oblivious negotiation, playing mental poker, etc.. He also discusses the complexity question ""How many bits need to be exchanged for the computation,"" and describes methods to prevent participants from cheating. Finally, he studies the question ""What cannot be accomplished with one-way functions."""
1982,Space-Time Tradeoff for Answering Range Queries (Extended Abstract).,n/a
1981,Efficient Searching Using Partial Ordering.,n/a
1981,Should Tables Be Sorted?,
1981,A Lower Bound to Finding Convex Hulls.,
1981,An Analysis of a Memory Allocation Scheme for Implementing Stacks.,n/a
1981,On the Security of Public Key Protocols (Extended Abstract).,
1981,On the Parallel Computation for the Knapsack Problem.,"We are interested in the complexity of solving the knapsack problem with n input real numbers on a parallel computer with real arithmetic and branching operations. A processor-time tradeoff constraint is derived; in particular, it is shown that an exponential number of processors have to be used if the problem is to be solved in time t ≤ @@@@n/2."
1981,The Entropic Limitations on VLSI Computations (Extended Abstract).,"In this paper we will explore the limitations imposed by entropic constraints, both in generality and for specific problems. We list below the main questions that we will address. (1) In the binary number system, addition is easy while multiplication is hard for VLSI. Is there an “ideal” number representation, in which all arithmetic operations have efficient VLSI implementations? (2) Can one build multipliers for binary numbers, which achieve both small area and fast average computation time? (3) Thompson's technique applies only to multiple output functions. How can one prove area-time bounds for single output functions? (4) What other ways are there for deriving entropic constraints from consideration of data movement? Answers to these questions will be discussed in the ensuing sections."
1980,A Stochastic Model of Bin-Packing.,n/a
1980,A Note on the Analysis of Extendible Hashing.,n/a
1980,External Hashing Schemes for Collections of Data Structures.,n/a
1980,New Algorithms for Bin Packing.,"In the bin-packing problem a list L of n numbers are to be packed into unit-capacity bins. For any algorithm S, let r(S) be the maximum ratio S(L)/L* for large L*, where S(L) denotes the number of bins used by S and L* denotes the minimum number needed. An on-line &Ogr;(n log n)-time algorithm RFF with r(RFF) = 5/3 and an off-line polynomial-time algorithm RFFD with r(RFFD) ≤ 11/9 - &egr; for some fixed &egr; > 0, are given. These are strictly better, respectively, than two prominent algorithms: the First-Fit (FF), which is on-line with r(FF) = 17/10, and the First-Fit-Decreasing (FFD) with r(FFD) = 11/9. Furthermore, it is shown that any on-line algorithm S must have r(S) ≥ 3/2. The question, “How well can an &ogr;(n log n)-time algorithm perform?” is also discussed. It is shown that in the generalized d-dimensional bin packing, any &ogr;(n log n)-time algorithm S must have r(S) ≥ d."
1980,Information Bounds Are Weak in the Shortest Distance Problem.,
1980,"An Analysis of (h, k, 1)-Shellsort.",n/a
1980,On the Polyhedral Decision Problem.,n/a
1980,Bounds on Selection Networks.,n/a
1980,Some Monotonicity Properties of Partial Orders.,n/a
1980,Optimal Expected-Time Algorithms for Closest Point Problems.,
1979,Storing a Sparse Table.,"The problem of storing and searching large sparse tables is ubiquitous in computer science. The standard technique for storing such tables is hashing, but hashing has poor worst-case performance. We propose a good worst-case method for storing a static table of n entries, each an integer between 0 and N - 1. The method requires O(n) words of storage and allows O(logn N) access time. Although our method is a little complicated to use in practice, our analysis shows why a simpler algorithm used for compressing LR parsing tables works so well."
1979,A Note on a Conjecture of Kam and Ullman Concerning Statistical Databases.,n/a
1979,The Complexity of Pattern Matching for a Random String.,n/a
1979,Some Complexity Questions Related to Distributive Computing (Preliminary Report).,"Let M &equil; {0, 1, 2, ..., m—1} , N &equil; {0, 1, 2,..., n—1} , and f:M × N → {0, 1} a Boolean-valued function. We will be interested in the following problem and its related questions. Let i &egr; M, j &egr; N be integers known only to two persons P1 and P2, respectively. For P1 and P2 to determine cooperatively the value f(i, j), they send information to each other alternately, one bit at a time, according to some algorithm. The quantity of interest, which measures the information exchange necessary for computing f, is the minimum number of bits exchanged in any algorithm. For example, if f(i, j) &equil; (i + j) mod 2. then 1 bit of information (conveying whether i is odd) sent from P1 to P2 will enable P2 to determine f(i, j), and this is clearly the best possible. The above problem is a variation of a model of Abelson [1] concerning information transfer in distributive computions."
1978,On Random 2-3 Trees.,"Summary
It is shown that ¯n (N), the average number of nodes in an N-key random 2–3 tree, satisfies the inequality 0.70 N < ¯n(N) <0.79 N for large N. A similar analysis is done for general B-trees. It is shown that storage utilization is essentially ln 2≈69% for B-tree of high orders."
1978,Addition chains with multiplicative cost.,n/a
1978,k+1 Heads Are Better than k.,
1978,On the Loop Switching Addressing Problem.,n/a
1978,Should Tables Be Sorted? (Extended Abstract).,
1978,On the Average-case Complexity of Selecting k-th Best.,"Abstract:
Let Vk (n) be the minimum average number of pairwise comparisons needed to find the k-th largest of n numbers (k≥2), assuming that all n! orderings are equally likely. D. W. Matula proved that, for some absolute constant c, Vk(n)- n ≤ ck log log n as n → ∞. In the present paper, we show that there exists an absolute constant c′ ≫ 0 such that Vk(n) - n ≥ c′k log log n as n → ∞, proving a conjecture by Matula."
1977,Probabilistic Computations: Toward a Unified Measure of Complexity (Extended Abstract).,
1977,An Omega(n^2 log n) Lower Bound to the Shortest Paths Problem.,Let P be a polyhedron with fs s-dimensional faces. We show that Ω(log fs) linear comparisons are needed to determine if a point lies in P. This is used to establish an Ω(n2 log n) lower bound to the all-pairs shortest path problem between n points.
1976,Analysis of the subtractive algorithm for greatest common divisors.,"The sum of all partial quotients in the regular continued fraction expansions of m/n, for 1 ≤m≤n, is shown to be 6Π-2 n(ln n)2+ O(n log n(log log n)2). This result is applied to the analysis of what is perhaps the oldest nontrivial algorithm for number-theoretic computations."
1976,On a problem of Katona on minimal separating systems.,n/a
1976,An Almost Optimal Algorithm for Unbounded Searching.,n/a
1976,Lower Bounds on Merging Networks.,"Let M(m, n) be the minimum number or comparators needed in an (m, n)-merging network. It is shown that M(m, n) ≥ n(lg(m + 1))/2, which implies that Batcher's merging networks are optimal up to a factor of 2 + &egr; for almost all values of m and n. The limit rm = limn→∞ M(m, n)/n is determined to within 1. It is also proved that M(2, n) = [3n/2]."
1976,Resource Constrained Scheduling as Generalized Bin Packing.,n/a
1976,On the Evaluation of Powers.,n/a
1976,k+1 Heads Are Better than k.,"Abstract:
There are languages which can be recognized by a deterministic (k + 1)-headed oneway finite automaton but which cannot be recognized by a k-headed one-way (deterministic or non-deterministic) finite automaton. Furthermore, there is a language accepted by a 2-headed nondeterministic finite automaton which is accepted by no k-headed deterministic finite automaton."
1976,The Complexity of Searching an Ordered Random Table (Extended Abstract).,
1976,On the Average Behavior of Set Merging Algorithms (Extended Abstract).,"In this paper we study the expected running time of a variety of algorithms that perform set merging. The set merging problem (for example, see AHU [1]) is concerned with using suitable data structures to represent partition of a set S &equil; { 1,2, .... ,n} so that a sequence of instructions of the form “x &Xgr; y”, meaning “Find the subset containing x; Find the subset containing y; Merge the two subsets if they are different.” may be carried out efficiently. Several alternative data structures for solving this problem are known, and their worse-case complexity fairly well understood [3], [4], [5], [8]. In contrast, the average behavior of even the most basic of these schemes remains an open problem [6]. It is the purpose of the present paper to determine the average behavior for several of the set merging algorithms commonly known."
1975,An O(|E| log log |V|) Algorithm for Finding Minimum Spanning Trees.,n/a
1975,On the Complexity of Comparison Problems using Linear Functions (Preliminary Report).,
1975,On Computing the Minima of Quadratic Forms (Preliminary Report).,"The following problem was recently raised by C. William Gear [1]: Let F(x1,x2,...,xn) &equil; &Sgr;i≤j a'ijxixj + &Sgr;i bixi +c be a quadratic form in n variables. We wish to compute the point x→(0) &equil; (x1(0),...,xn(0)), at which F achieves its minimum, by a series of adaptive functional evaluations. It is clear that, by evaluating F(x→) at 1/2(n+1)(n+2)+1 points, we can determine the coefficients a'ij,bi,c and thereby find the point x→(0). Gear's question is, “How many evaluations are necessary?” In this paper, we shall prove that O(n2) evaluations are necessary in the worst case for any such algorithm."
1974,Bounds on Selection Networks.,"Abstract:
We investigate the complexity of network selection by measuring it in terms of U(t,N), the minimum number of comparators needed, and T(t,N), the minimum delay time possible, for networks selecting the smallest t elements from a set of N inputs. New bounds on U(t,N) and T(t,N) are presented. In particular, U(3,N) is determined to within a constant of 2, and asymptotic formulae for U(t,N) and T(t,N) are given for fixed t."
1974,Scheduling Unit-Time Tasks with Limited Resources.,"Abstract
A set of tasks are to be scheduled on a multiprocessing system with s resources. Each task takes one unit time to complete, and requires certain amounts of resources. The schedule is to be consistent with a prescribed partial order relation on the task, and the total demand for each resource must not exceed a fixed amount at any instant. In this paper we analyze the worst-case behavior of several heuristic scheduling algorithms.
Let ω be the time taken for executing all the tasks according to a priority list, and ω0 be the time required when scheduled in an optimal way. It is shown that, independent of the number of processors, ω/ω0 ≦ sω0/2 + 0(s) for any list. When certain heuristic algorithms are used to prepare the list, a significantly improved upper bound can be derived: ω/ω0 ≦ const. × s + 0(1). Some generalizations are possible to the case when the ""unit-time"" restriction is removed.
When the partial order relation is empty, the problem becomes a natural generalization of the bin-packing problem. Tighter bounds for this special situation are given."
