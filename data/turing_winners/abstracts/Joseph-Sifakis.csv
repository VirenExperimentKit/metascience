2019,Rigorous design of cyber-physical systems - Linking physicality and computation.,"Cyber-physical systems have developed into a very active research field, with a broad range of challenges and research directions going from requirements, to implementation and simulation, as well as validation and verification to guarantee essential properties. In this survey paper, we focus exclusively on the following fundamental issue: how to link physicality and computation, continuous time-space dynamics with discrete untimed ones? We consider that cyber-physical system design flow involves the following three main steps: (1) cyber-physical systems modeling; (2) discretization for executability; and (3) simulation and implementation. We reviewóand strive to provide insight into possible approaches for addressingóthe key issues, for each of these three steps.
"
2019,Can We Trust Autonomous Systems? Boundaries and Risks.,"Abstract
Can we trust autonomous systems? This question arises urgently with the perspective of massive use of AI-enabled techniques in autonomous systems, critical systems intended to replace humans in complex organizations.
We propose a framework for tackling this question and bringing reasoned and principled answers. First, we discuss a classification of different types of knowledge according to their truthfulness and generality. We show basic differences and similarities between knowledge produced and managed by humans and computers, respectively. In particular, we discuss how differences in the system development process of knowledge affect its truthfulness.
To determine whether we can trust a system to perform a given task, we study the interplay between two main factors: (1) the degree of trustworthiness achievable by a system performing the task; and (2) the degree of criticality of the task. Simple automated systems can be trusted if their trustworthiness can match the desired degree of criticality. Nonetheless, the acceptance of autonomous systems to perform complex critical tasks will additionally depend on their ability to exhibit symbiotic behavior and allow harmonious collaboration with human operators. We discuss how objective and subjective factors determine the balance in the division of work between autonomous systems and human operators.
We conclude emphasizing that the role of autonomous systems will depend on decisions about when we can trust them and when we cannot. Making these choices wisely goes hand in hand with compliance with principles promulgated by policy-makers and regulators rooted both in ethical and technical criteria."
2019,A Logic-Inspired Approach to Reconfigurable System Modelling.,"Abstract
Software systems have reached a level of complexity that demands new approaches to software design in order to support continuous adaptation to the changes in their internal and external environment. This implies the capability of capturing at design-time the dynamic features of systems that are composed of large numbers of interacting components in order to reduce the risks of undesirable interferences and unpredictable outcomes. The L-DReAM framework (‚ÄúLight Dynamic Reconfigurable Architecture Modelling‚Äù) relies on a logic-based modelling language that is expressive enough to capture different approaches to systems coordination, reconfiguration and dynamicity. L-DReAM components have a ‚Äúloose‚Äù structure that, combined with the flexibility of the adopted coordination language, results in a framework that can be used to model many different computational paradigms while offering a readable syntax easy to understand."
2019,Autonomous Systems - An Architectural Characterization.,"Abstract
The concept of autonomy is key to the IoT vision promising increasing integration of smart services and systems minimizing human intervention. This vision challenges our capability to build complex open trustworthy autonomous systems. We lack a rigorous common semantic framework for autonomous systems. It is remarkable that the debate about autonomous vehicles focuses almost exclusively on AI and learning techniques while it ignores many other equally important autonomous system design issues.
Autonomous systems involve agents and objects coordinated in some common environment so that their collective behavior meets a set of global goals. We propose a general computational model combining a system architecture model and an agent model. The architecture model allows expression of dynamic reconfigurable multi-mode coordination between components. The agent model consists of five interacting modules implementing each one a characteristic function: Perception, Reflection, Goal management, Planning and Self-adaptation. It determines a concept of autonomic complexity accounting for the specific difficulty to build autonomous systems.
We emphasize that the main characteristic of autonomous systems is their ability to handle knowledge and adaptively respond to environment changes. We advocate that autonomy should be associated with functionality and not with specific techniques. Machine learning is essential for autonomy although it can meet only a small portion of the needs implied by autonomous system design.
We conclude that autonomy is a kind of broad intelligence. Building trustworthy and optimal autonomous systems goes far beyond the AI challenge."
2019,Checking Deadlock-Freedom of Parametric Component-Based Systems.,"Abstract
We propose an automated method for computing inductive invariants used to proving deadlock freedom of parametric component-based systems. The method generalizes the approach for computing structural trap invariants from bounded to parametric systems with general architectures. It symbolically extracts trap invariants from interaction formulae defining the system architecture. The paper presents the theoretical foundations of the method, including new results for the first order monadic logic and proves its soundness. It also reports on a preliminary experimental evaluation on several textbook examples."
2018,Early validation of system requirements and design through correctness-by-construction.,"Highlights
‚Ä¢
We provide templates and a conceptual model for requirement specification.
‚Ä¢
We give interpretation of the templates using formal property patterns.
‚Ä¢
We show how property patterns can be enforced through architecture styles.
‚Ä¢
All safety properties of the case study were enforced or verified by inspection.
‚Ä¢
The design model and the modeling/verification utilities are online.
Abstract
Early validation of requirements aims to reduce the need for the high-cost validation testing and corrective measures at late development stages. This work introduces a systematic process for the unambiguous specification of system requirements and the guided derivation of formal properties, which should be implied by the system ‚Äôs structure and behavior in conjunction with its external stimuli. This rigorous design takes place through the incremental construction of a model using the BIP (Behavior-Interaction-Priorities) component framework. It allows building complex designs by composing simpler reusable designs enforcing given properties. If some properties are neither enforced nor verified, the model is refined or certain requirements are revised. A validated model provides evidence of requirements‚Äô consistency and design correctness. The process is semi-automated through a new tool and existing verification tools. Its effectiveness was evaluated on a set of requirements for the control software of the CubETH nanosatellite and an extract of software requirements for a Low Earth Orbit observation satellite. Our experience and obtained results helped in identifying open challenges for applying the method in industrial context. These challenges concern with the domain knowledge representation, the expressiveness of used specification languages, the library of reusable designs and scalability."
2018,Global and Local Deadlock Freedom in BIP.,"We present a criterion for checking local and global deadlock freedom of finite state systems expressed in BIP: a component-based framework for constructing complex distributed systems. Our criterion is evaluated by model-checking a set of subsystems of the overall large system. If satisfied in small subsystems, it implies deadlock-freedom of the overall system. If not satisfied, then we re-evaluate over larger subsystems, which improves the accuracy of the check. When the subsystem being checked becomes the entire system, our criterion becomes complete for deadlock-freedom. Hence our criterion only fails to decide deadlock freedom because of computational limitations: state-space explosion sets in when the subsystems become too large. Our method thus combines the possibility of fast response together with theoretical completeness. Other criteria for deadlock freedom, in contrast, are incomplete in principle, and so may fail to decide deadlock freedom even if unlimited computational resources are available. Also, our criterion certifies freedom from local deadlock, in which a subsystem is deadlocked while the rest of the system executes. Other criteria only certify freedom from global deadlock. We present experimental results for dining philosophers and for a multi-token-based resource allocation system, which subsumes several data arbiters and schedulers, including Milner‚Äôs token-based scheduler."
2018,Programming Dynamic Reconfigurable Systems.,"Abstract
DR-BIP is an extension of the BIP component framework intended for programming reconfigurable systems encompassing various aspects of dynamism. It relies on architectural motifs to structure the architecture of a system and to coordinate its reconfiguration at runtime. An architectural motif defines a set of interacting components that evolve according to reconfiguration rules. With DR-BIP, the dynamism can be captured as the interplay of dynamic changes in three independent directions (1) the organization of interactions between instances of components in a given configuration; (2) the reconfiguration mechanisms allowing creation/deletion of components and management of their interaction according to a given architectural motif; (3) the migration of components between predefined architectural motifs which characterizes dynamic execution environments. The paper lays down the formal foundation of DR-BIP, illustrates its expressiveness on few examples and discusses avenues for dynamic reconfigurable system design."
2018,DReAM: Dynamic Reconfigurable Architecture Modeling.,"Abstract
Modern systems evolve in unpredictable environments and have to continuously adapt their behavior to changing conditions. The ‚ÄúDReAM‚Äù (Dynamic Reconfigurable Architecture Modeling) framework, has been designed for modeling reconfigurable dynamic systems. It provides a rule-based language, inspired from Interaction Logic, expressive and easy to use, and encompassing all aspects of dynamicity including parametric multi-modal coordination with creation/deletion of components as well as mobility. Additionally, it allows the description of both endogenous/modular and exogenous/centralized coordination styles and sound transformations from one style to the other. The DReAM framework is implemented in the form of a Java API bundled with an execution engine. It allows to develop runnable systems combining the expressiveness of the rule-based notation together with the flexibility of this widespread programming language."
2018,Four Exercises in Programming Dynamic Reconfigurable Systems: Methodology and Solution in DR-BIP.,"Abstract
DR-BIP is an extension of the BIP component framework intended for programming reconfigurable systems encompassing various aspects of dynamism. A system is built from instances of types of components characterized by their interfaces. The latter consist of sets of ports through which data can be exchanged when interactions take place. DR-BIP allows the description of parametric exogenous interactions and reconfiguration operations. To naturally model self-organization and mobility of components, a system is composed of several architecture motifs, each motif consisting of a set of component instances and coordination rules. The use of motifs allows a disciplined management of dynamically changing coordination rules. The paper illustrates the basic concepts of DR-BIP through a collection of four non-trivial exercises from different application areas: fault-tolerant systems, mobile systems and autonomous systems. The presented solutions show that DR-BIP is both minimal and expressive allowing concise and natural description of non-trivial systems."
2018,System Design in the Era of IoT - Meeting the Autonomy Challenge.,"The advent of IoT is a great opportunity to reinvigorate Computing by focusing on autonomous system design. This certainly raises technology questions but, more importantly, it requires building new foundation that will systematically integrate the innovative results needed to face increasing environment and mission complexity.
A key idea is to compensate the lack of human intervention by adaptive control. This is instrumental for system resilience: it allows both coping with uncertainty and managing mixed criticality services. Our proposal for knowledge-based design seeks a compromise: preserving rigorousness despite the fact that essential properties cannot be guaranteed at design time. It makes knowledge generation and application a primary concern and aims to fully and seamlessly incorporate the adaptive control paradigm in system architecture."
2017,Configuration logics: Modeling architecture styles.,"Highlights
‚Ä¢
We introduce and study the Propositional Configuration Logic (PCL), as well as its First- and Second-Order extensions.
‚Ä¢
We study three classes of PCL formulas: the downward-closed, upward-closed and union-closed formulas.
‚Ä¢
We define a full normal form, which is unique for any PCL formula.
‚Ä¢
We describe two methods for checking satisfaction of PCL formulas.
‚Ä¢
We provide full proofs of all results and examples illustrating the specification of architecture styles.
Abstract
We study a framework for the specification of architecture styles as families of architectures involving a common set of types of components and coordination mechanisms. The framework combines two logics: 1) interaction logics for the specification of architectures as generic coordination schemes involving a configuration of interactions between typed components; and 2) configuration logics for the specification of architecture styles as sets of interaction configurations. The presented results build on previous work on architecture modeling in BIP. We show how propositional interaction logic can be extended into a corresponding configuration logic by adding new operators on sets of interaction configurations. In addition to the usual set-theoretic operators, configuration logic is equipped with a coalescing operator + to express combination of configuration sets. We provide a complete axiomatization of propositional configuration logic as well as decision procedures for checking that an architecture satisfies given logical specifications. To allow genericity of specifications, we study first-order and second-order extensions of the propositional configuration logic. First-order logic formulas involve quantification over component variables. Second-order logic formulas involve additional quantification over sets of components. We provide several examples illustrating the application of the results to the characterization of various architecture styles. We also provide an experimental evaluation using the Maude rewriting system to implement the decision procedure for the propositional flavor of the logic."
2017,Functional BIP: Embedding connectors in functional programming languages.,"Abstract
This paper presents a theoretical foundation for functional language implementations of Behaviour‚ÄìInteraction‚ÄìPriority (BIP). We introduce a set of connector combinators describing synchronisation, data transfer, priorities and dynamicity in a principled way. A static type system ensures the soundness of connector semantics.
Based on this foundation, we implemented BIP as an embedded domain specific language (DSL) in Haskell and Scala. The DSL embedding allows programmers to benefit from the full expressive power of high-level languages. The clear separation of behaviour and coordination inherited from BIP leads to systems that are arguably simpler to maintain and reason about, compared to other approaches."
2016,A general framework for architecture composability.,"Abstract
Architectures depict design principles: paradigms that can be understood by all, allow thinking on a higher plane and avoiding low-level mistakes. They provide means for ensuring correctness by construction by enforcing global properties characterizing the coordination between components. An architecture can be considered as an operator A that, applied to a set of components
B
B
, builds a composite component
A(B)
A
meeting a characteristic property
Œ¶
Œ¶
. Architecture composability is a basic and common problem faced by system designers. In this paper, we propose a formal and general framework for architecture composability based on an associative, commutative and idempotent architecture composition operator
‚äï
. The main result is that if two architectures A 1 and A 2 enforce respectively safety properties
Œ¶
1
Œ¶
and
Œ¶
2
Œ¶
, the architecture
A
1
‚äï
A
2
enforces the property
Œ¶
1
‚àß
Œ¶
2
, that is both properties are preserved by architecture composition. We also establish preservation of liveness properties by architecture composition. The presented results are illustrated by a running example and a case study."
2016,Component-based verification using incremental design and invariants.,"Abstract
We propose invariant-based techniques for the efficient verification of safety and deadlock-freedom properties of component-based systems. Components and their interactions are described in the BIP language. Global invariants of composite components are obtained by combining local invariants of their constituent components with interaction invariants that take interactions into account. We study new techniques for computing interaction invariants. Some of these techniques are incremental, i.e., interaction invariants of a composite hierarchically structured component are computed by reusing invariants of its constituents. We formalize incremental construction of components in the BIP language as the process of building progressively complex components by adding interactions (synchronization constraints) to atomic components. We provide sufficient conditions ensuring preservation of invariants when new interactions are added. When these conditions are not satisfied, we propose methods for generating new invariants in an incremental manner by reusing existing invariants from the constituents in the incremental construction. The reuse of existing invariants reduces considerably the overall verification effort. The techniques have been implemented in the D-Finder toolset. Among the experiments conducted, we have been capable of verifying safety properties and deadlock-freedom of sub-systems of the functional level of the DALA autonomous robot. This work goes far beyond the capacity of existing monolithic verification tools."
2016,Parameterized Systems in BIP: Design and Model Checking.,"BIP is a component-based framework for system design that has important industrial applications. BIP is built on three pillars: behavior, interaction, and priority. In this paper, we introduce first-order interaction logic (FOIL) that extends BIP to systems parameterized in the number of components. We show that FOIL captures classical parameterized architectures such as token-passing rings, cliques of identical components communicating with rendezvous or broadcast, and client-server systems. Although the BIP framework includes efficient verification tools for statically-defined systems, none are available for parameterized systems with an unbounded number of components. The parameterized model checking literature contains a wealth of techniques for systems of classical architectures. However, application of these results requires a deep understanding of parameterized model checking techniques and their underlying mathematical models. To overcome these difficulties, we introduce a framework that automatically identifies parameterized model checking techniques applicable to a BIP design. To our knowledge, it is the first framework that allows one to apply prominent parameterized model checking results in a systematic way."
2016,Architecture-Based Design: A Satellite On-Board Software Case Study.,"Abstract
In this case study, we apply the architecture-based design approach to the control software of the CubETH satellite. Architectures are a means for ensuring global coordination properties and thus, achieving correctness of complex systems by construction. We illustrate the following three steps of the design approach: (1) definition of a domain-specific taxonomy of architecture styles; (2) design of the software model by applying architectures to enforce the required properties; (3) deadlock-freedom analysis of the resulting model. We provide a taxonomy of architecture styles for satellite on-board software, formally defined by architecture diagrams in the BIP component-based framework. We show how architectures are instantiated from the diagrams and applied to a set of atomic components. Deadlock-freedom of the resulting model is verified using DFinder from the BIP tool-set. We provide additional validation of our approach by using the nuXmv model checker to verify that the properties enforced by the architectures are, indeed, satisfied by the model."
2016,Architecture Diagrams: A Graphical Language for Architecture Style Specification.,"Architecture styles characterise families of architectures sharing common characteristics. We have recently proposed configuration logics for architecture style specification. In this paper, we study a graphical notation to enhance readability and easiness of expression. We study simple architecture diagrams and a more expressive extension, interval architecture diagrams. For each type of diagrams, we present its semantics, a set of necessary and sufficient consistency conditions and a method that allows to characterise compositionally the specified architectures. We provide several examples illustrating the application of the results. We also present a polynomial-time algorithm for checking that a given architecture conforms to the architecture style specified by a diagram."
2015,System Design Automation: Challenges and Limitations.,"Abstract:
Electronic design automation (EDA) has enabled the integrated circuit industry to sustain exponentially increasing product complexity growth until today, while maintaining consistent product development timeline and costs. We argue that the success of EDA-based design relies on the application of four interrelated principles: 1) separation of concerns implying a decomposition of a design flow into steps, each step dealing with specific aspects, namely user requirements, functional design, and implementation; 2) component-based design enabling the reasoned construction of complex systems as the composition of components; 3) semantic coherency meaning that descriptions used in successive design steps are semantically related through adequate semantic mappings; this implies, in particular, that the formalisms used at each design step are rooted in well-defined semantics; and 4) correctness by construction meaning that it is possible to guarantee essential properties of the designed system incrementally and compositionally along the design process. The paper discusses to what extent the EDA paradigm can be adapted to general mixed hardware/software (HW/SW) systems design through the application of these principles. It presents an overview of the problems raised by the rigorous system design of mixed HW/SW systems. Then, it presents a unified abstract framework for addressing these problems by identifying main research avenues."
2015,Optimized distributed implementation of multiparty interactions with Restriction.,"Abstract
Using high level coordination primitives allows enhanced expressiveness of component-based frameworks to cope with the inherent complexity of present-day systems designs. Nonetheless, their distributed implementation raises multiple issues, regarding both the correctness and the runtime performance of the final implementation. We propose a novel approach for distributed implementation of multiparty interactions subject to scheduling constraints expressed by priorities. We rely on a new composition operator named Restriction, whose semantics dynamically restricts the set of interactions allowed for execution, depending on the current state. We show that this operator provides a natural encoding for priorities. We provide a knowledge-based optimization that modifies the Restriction operator to avoid superfluous communication in the final implementation. We complete our framework through an enhanced conflict resolution protocol that natively implements Restriction. A prototype implementation allows us to compare performances of different optimizations."
2015,A Theory Agenda for Component-Based Design.,"Abstract
The aim of the paper is to present a theory agenda for component-based design based on results that motivated the development of the BIP component framework, to identify open problems and discuss further research directions. The focus is on proposing a semantically sound theoretical and general framework for modelling component-based systems and their properties both behavioural and architectural as well for achieving correctness by using scalable specific techniques.
We discuss the problem of composing components by proposing the concept of glue as a set of stateless composition operators defined by a certain type of operational semantics rules. We provide an overview of results about glue expressiveness and minimality. We show how interactions and associated transfer of data can be described by using connectors and in particular, how dynamic connectors can be defined as an extension of static connectors. We present two approaches for achieving correctness for component-based systems. One is by compositional inference of global properties of a composite component from properties of its constituents and interaction constraints implied by composition operators. The other is by using and composing architectures that enforce specific coordination properties. Finally, we discuss recent results on architecture specification by studying two types of logics: 1) interaction logics for the specification of sets of allowed interactions; 2) configuration logics for the characterisation of architecture styles."
2015,Configuration Logics: Modelling Architecture Styles.,"Abstract
We study a framework for the specification of architecture styles as families of architectures involving a common set of types of components and coordination mechanisms. The framework combines two logics: (1) interaction logics for the specification of architectures as generic coordination schemes involving a configuration of interactions between typed components; (2) configuration logics for the specification of architecture styles as sets of interaction configurations. The presented results build on previous work on architecture modelling in BIP. We show how propositional interaction logic can be extended into a corresponding configuration logic by adding new operators on sets of interaction configurations. We provide a complete axiomatisation of the propositional configuration logic, as well as a decision procedure for checking that an architecture satisfies given logical specifications. To allow genericity of specifications, we study first-order and second-order extensions of the propositional logic. We provide examples illustrating the application of the results to the characterization of architecture styles. Finally, we provide an experimental evaluation using the Maude rewriting system to implement the decision procedure for the propositional logic."
2014,Architecture internalisation in BIP.,"We consider two approaches for building component-based systems, which we call respectively architecture-based and architecture-agnostic. The former consists in describing coordination constraints in a purely declarative manner through parametrizable glue operators; it provides higher abstraction level and, consequently, stronger correctness by construction. The latter uses simple fixed coordination primitives, which are spread across component behaviour; it is more error-prone, but allows performance optimisation. We study architecture internalisation leading from an architecture-based system to an equivalent architecture-agnostic one, focusing, in particular, on component-based systems described in BIP. BIP uses connectors for hierarchical composition of components. We study connector internalisation in three steps. 1) We introduce and study the properties of interaction expressions, which represent the combined information about all the effects of an interaction. We show that they are a very powerful tool for specifying and analysing structured interaction. 2) We formalize the connector semantics of BIP by using interaction expressions. The formalization proves to be mathematically rigorous and concise. 3) We introduce the T/B component model and provide a semantics preserving translation of BIP into this model. The translation is compositional that is, it preserves the structure of the source models. The results are illustrated by simple examples. A Java implementation is evaluated on two case studies."
2014,Toward a System Design Science.,"Abstract
Design is a universal concept. It links the immaterial world of concepts to the physical world. It is an essential area of human experience, expertise, and knowledge, which deals with our ability to mold our environment to satisfy material and spiritual needs.
Design has two different connotations. One is simply a plan or a pattern for assembling objects constituting a given artifact. The other is the creative process for devising plans or patterns and carrying them out to produce an artifact. For this paper we focus on the second interpretation. We are ultimately interested in putting design on a more scientific basis. Toward this end, we focus here on articulating a new structure for the design process, which we believe will support this goal."
2014,Keynote talk III: A framework for modeling architectures and their properties.,"Abstract:
Architectures are common means for organizing coordination between components in order to build complex systems and to make them manageable. Despite the progress of the state of the art over the past decades, there are still a lot of foundational issues that remain unsolved. In this talk we present a general framework for modeling architectures and their properties."
2014,Rigorous system design.,"We advocate rigorous system design as a coherent and accountable model-based process leading from requirements to implementations. We present the state of the art in system design, discuss its current limitations, and identify possible avenues for overcoming them. A rigorous system design flow [3] is defined as a formal accountable and iterative process composed of steps, and based on four principles: (1) separation of concerns; (2) component-based construction; (3) semantic coherency; and (4) correctness-by-construction. We show that the combined application of these principles allows the definition of rigorous design flows clearly identifying where human intervention and ingenuity are needed to resolve design choices, as well as activities that can be supported by tools to automate tedious and error-prone tasks. An implementable system model is progressively derived by source-to-source automated transformations in a single host component-based language rooted in well-defined semantics. Using a single modeling language throughout the design flow enforces semantic coherency. Correct-by-construction techniques allow well-known limitations of a posteriori verification to be overcome and ensure accountability. It is possible to explain, at each design step, which among the requirements are satisfied and which may not be satisfied.
The presented view has been amply implemented in the BIP (Behavior, Interaction, Priority) component framework and substantiated by numerous experimental results showing both its relevance and feasibility [1]. We show in particular, how distributed implementations can be generated from BIP models with multiparty interactions by application of correct-by-construction transformations [2]. We conclude with a discussion advocating a system-centric vision for computing, identifying possible links with other disciplines, and emphasizing centrality of system design."
2014,A General Framework for Architecture Composability.,"Abstract
Architectures depict design principles: paradigms that can be understood by all, allow thinking on a higher plane and avoiding low-level mistakes. They provide means for ensuring correctness by construction by enforcing global properties characterizing the coordination between components. An architecture can be considered as an operator A that, applied to a set of components
B
B
, builds a composite component
A(B)
A
meeting a characteristic property Œ¶. Architecture composability is a basic and common problem faced by system designers. In this paper, we propose a formal and general framework for architecture composability based on an associative, commutative and idempotent architecture composition operator ‚Äò‚äï‚Äô. The main result is that if two architectures A 1 and A 2 enforce respectively safety properties Œ¶1 and Œ¶2, the architecture A 1‚Äâ‚äï‚ÄâA 2 enforces the property
Œ¶
1
‚àß
Œ¶
2
, that is both properties are preserved by architecture composition. We also establish preservation of liveness properties by architecture composition. The presented results are illustrated by a running example and a case study."
2013,Rigorous System Design.,"We advocate rigorous system design as a coherent and accountable model-based process leading from requirements to implementations. We present the state of the art in system design, discuss its current limitations, and identify possible avenues for overcoming them. A rigorous system design flow [3] is defined as a formal accountable and iterative process composed of steps, and based on four principles: (1) separation of concerns; (2) component-based construction; (3) semantic coherency; and (4) correctness-by-construction. We show that the combined application of these principles allows the definition of rigorous design flows clearly identifying where human intervention and ingenuity are needed to resolve design choices, as well as activities that can be supported by tools to automate tedious and error-prone tasks. An implementable system model is progressively derived by source-to-source automated transformations in a single host component-based language rooted in well-defined semantics. Using a single modeling language throughout the design flow enforces semantic coherency. Correct-by-construction techniques allow well-known limitations of a posteriori verification to be overcome and ensure accountability. It is possible to explain, at each design step, which among the requirements are satisfied and which may not be satisfied.

The presented view has been amply implemented in the BIP (Behavior, Interaction, Priority) component framework and substantiated by numerous experimental results showing both its relevance and feasibility [1]. We show in particular, how distributed implementations can be generated from BIP models with multiparty interactions by application of correct-by-construction transformations [2]. We conclude with a discussion advocating a system-centric vision for computing, identifying possible links with other disciplines, and emphasizing centrality of system design."
2013,Rigorous implementation of real-time systems - from theory to application.,"The correct and efficient implementation of general real-time applications remains very much an open problem. A key issue is meeting timing constraints whose satisfaction depends on features of the execution platform, in particular its speed. Existing rigorous implementation techniques are applicable to specific classes of systems, for example, with periodic tasks or time-deterministic systems.

We present a general model-based implementation method for real-time systems based on the use of two models:

ïAn abstract model representing the behaviour of real-time software as a timed automaton, which describes user-defined platform-independent timing constraints. Its transitions are timeless and correspond to the execution of statements of the real-time software.
ïA physical model representing the behaviour of the real-time software running on a given platform. It is obtained by assigning execution times to the transitions of the abstract model.
A necessary condition for implementability is time-safety, that is, any (timed) execution sequence of the physical model is also an execution sequence of the abstract model. Time-safety simply means that the platform is fast enough to meet the timing requirements. As execution times of actions are not known exactly, time-safety is checked for the worst-case execution times of actions by making an assumption of time-robustness: time-safety is preserved when the speed of the execution platform increases.
We show that, as a rule, physical models are not time-robust, and that time-determinism is a sufficient condition for time-robustness. For a given piece of real-time software and an execution platform corresponding to a time-robust model, we define an execution engine that coordinates the execution of the application software so that it meets its timing constraints. Furthermore, in the case of non-robustness, the execution engine can detect violations of time-safety and stop execution.

We have implemented the execution engine for BIP programs with real-time constraints and validated the implementation method for two case studies. The experimental results for a module of a robotic application show that the CPU utilisation and the size of the model are reduced compared with existing implementations. The experimental results for an adaptive video encoder also show that a lack of time-robustness may seriously degrade the performance for increasing platform execution speed."
2013,Introduction to the special section on rigorous embedded systems design.,n/a
2013,Model-Based Implementation of Parallel Real-Time Systems.,"Abstract
One of the main challenges in the design of real-time systems is how to derive correct and efficient implementations from platform-independent specifications.
We present a general implementation method in which the application is represented by an abstract model consisting of a set of interacting components. The abstract model executes sequentially components interactions atomically and instantaneously. We transform abstract models into physical models representing their execution on a platform. Physical models take into account execution times of interactions and allow their parallel execution. They are obtained by breaking atomicity of interactions using a notion of partial state. We provide safety conditions guaranteeing that the semantics of abstract models is preserved by physical models. These provide bases for implementing a parallel execution engine coordinating the execution of the components. The implementation has been validated on a real robotic application. Benchmarks show net improvement of its performance compared to a sequential implementation."
2013,An Abstract Framework for Deadlock Prevention in BIP.,"Abstract
We present a sound but incomplete criterion for checking deadlock freedom of finite state systems expressed in BIP: a component-based framework for the construction of complex distributed systems. Since deciding deadlock-freedom for finite-state concurrent systems is PSPACE-complete, our criterion gives up completeness in return for tractability of evaluation. Our criterion can be evaluated by model-checking subsystems of the overall large system. The size of these subsystems depends only on the local topology of direct interaction between components, and not on the number of components in the overall system.
We present two experiments, in which our method compares favorably with existing approaches. For example, in verifying deadlock freedom of dining philosphers, our method shows linear increase in computation time with the number of philosophers, whereas other methods (even those that use abstraction) show super-linear increase, due to state-explosion."
2012,A framework for automated distributed implementation of component-based models.,"Although distributed systems are widely used nowadays, their implementation and deployment are still time-consuming, error-prone, and hardly predictable tasks. In this paper, we propose a method for producing automatically efficient and correct-by-construction distributed implementations from a model of the application software in Behavior, Interaction, Priority (BIP). BIP is a well-founded component-based framework encompassing high-level multi-party interactions for synchronizing components (e.g., rendezvous and broadcast) and dynamic priorities for scheduling between interactions. Our method transforms an arbitrary BIP model into a Send/Receive BIP model that is directly implementable on distributed execution platforms. The transformation consists in (1) breaking the atomicity of actions in components by replacing synchronous multiparty interactions with asynchronous Send/Receive interactions; (2) inserting distributed controllers that coordinate the execution of interactions according to a user-defined partition of interactions, and (3) adding a distributed algorithm for handling conflicts between controllers. The obtained Send/Receive BIP model is proven observationally equivalent to its corresponding initial model. Hence, all functional properties of the initial BIP model are preserved by construction in the implementation. Moreover, the obtained Send/Receive BIP model can be used to automatically derive distributed executable code. The proposed method is fully implemented. Currently, it is possible to generate C++ implementations for (1) TCP sockets for conventional distributed communication, (2) MPI for multi-processor platforms, and (3) POSIX threads for deployment on multi-core platforms. We present four case studies and report experimental results for different design choices including partition of interactions and choice of algorithm for distributed conflict resolution.
"
2012,2010 CAV award announcement.,"Abstract
The 2010 CAV (Computer-Aided Verification) award was awarded to Kenneth L. McMillan of Cadence Research Laboratories for a series of fundamental contributions resulting in significant advances in scalability of model checking tools. The annual award recognizes a specific fundamental contribution or a series of outstanding contributions to the CAV field."
2012,"Systems Architecture, Design, Engineering, and Verification - The Practice in Research and Research in Practice.","More than any other area in computer science, the interaction and boundary between science and engineering is blurred in the systems area, with cross fertilization from both directions. The systems panel will explore the past, present and future relationship between systems research and engineering practice.
They will discuss the relationship between systems research and engineering practices: when does systems innovation emanating from industry become an invention and when does academic research stop being science and become engineering? How does practice-driven research impact the real world and how does the real world reflect back on foundations? In what forms does technology create research challenges, and in what manner does applied research give solid base for development?
They will surmise about the future of systems research: What are the fundamental challenges posed by the scale of today's cloud computing systems and mega-size data centers? How to organize software of large-scale distributed executions or mega-ton lines of code? What new opportunities are enabled by novel technologies like flash memory and transactional memory? How to integrate hand-in-hand design of software and architecture?"
2012,Optimized distributed implementation of multiparty interactions with observation.,"Using high level coordination primitives allows enhanced expressiveness of component-based frameworks to cope with the inherent complexity of present-day systems designs. Nonetheless, their distributed implementation raises multiple issues, regarding both the correctness and the runtime performance of the final implementation. We propose a novel approach for distributed implementation of multiparty interactions subject to scheduling constraints expressed by priorities. We rely on new composition operators and semantics that combine multiparty interactions with observation. We show that this model provides a natural encoding for priorities and moreover, can be used as an intermediate step towards provably correct and optimized distributed implementations."
2012,Knowledge-Based Distributed Conflict Resolution for Multiparty Interactions and Priorities.,"Abstract
Distributed decentralized implementation of systems of communicating processes raises non-trivial problems. Correct execution of multiparty interactions, subject to priority rules, requires sophisticated mechanisms for runtime conflict detection and resolution. We propose a method for detection of false conflicts which combines partial observation of the system‚Äôs state and apriori knowledge extracted from invariants. We propose heuristics for determining optimal sets of observations leading to implementations with particular guarantees. We provide preliminary experimental results on an implementation of the method in the BIP framework."
2012,Trustworthy Computing Systems.,n/a
2012,Rigorous design of cyber-physical systems.,"Abstract:
Cyber-physical systems (CPS) break with traditional systems such as desktop computers and servers, in various ways: (1) they are instrumented in order to interact with physical environments; (2) they are interconnected to allow interaction between people and objects in entirely new modes; (3) they must be smart to ensure predictability of events and optimal use of resources. Currently, we lack theory methods and tools for building cost-effectively trustworthy CPS. In this talk, I will show how and why CPS challenge our capabilities for ensuring their trustworthiness. I will advocate for a coherent scientific foundation of CPS design and will discuss three main scientific challenges: (1) Marrying physicality and computation; (2) Correctness-by-construction; (3) Adaptivity. Meeting these challenges is a prerequisite for moving from empirical to rigorous design. This can be formalized as a sound, scalable and accountable process leading to trustworthy and optimized implementations from: (1) an application software; (2) models of its execution infrastructure; and (3) models of its physical environment. Soundness is achieved through translation of the languages used along the design process into a single and expressive host language rooted in clean operational semantics. Scalability and accountability can be ensured by using correct-by-construction source-to-source transformations in the host language. The talk will conclude with an overview of the BIP rigorous design flow developed at Verimag and EPFL."
2012,Trustworthy Computing Systems.,n/a
2012,Modeling Dynamic Architectures Using Dy-BIP.,"Abstract
Dynamic architectures in which interactions between components can evolve during execution, are essential for modern computing systems such as web-based systems, reconfigurable middleware, wireless sensor networks and fault-tolerant systems. Currently, we lack rigorous frameworks for their modeling, development and implementation. We propose Dy-BIP a dynamic extension of the BIP component framework rooted in rigorous operational semantics and supporting a powerful and high-level set of primitives for describing dynamic interactions. These are expressed as symbolic constraints offered by interacting components and computed efficiently by an execution Engine. We present experimental results which validate the effectiveness of Dy-BIP and show significant advantages over using static architecture models."
2012,Rigorous Component-Based System Design - (Invited Paper).,"Abstract
Rigorous system design requires the use of a single powerful component framework allowing the representation of the designed system at different levels of detail, from application software to its implementation. This is essential for ensuring the overall coherency and correctness. The paper introduces a rigorous design flow based on the BIP (Behavior, Interaction, Priority) component framework [1]. This design flow relies on several, tool-supported, source-to-source transformations allowing to progressively and correctly transform high level application software towards efficient implementations for specific platforms."
2011,A vision for computer science - the system perspective.,n/a
2011,Priority scheduling of distributed systems based on model checking.,"Priorities are used to control the execution of systems to meet given requirements for optimal use of resources, e.g., by using scheduling policies. For distributed systems it is hard to find efficient implementations for priorities; because they express constraints on global states, their implementation may incur considerable overhead.

Our method is based on performing model checking for knowledge properties. It allows identifying where the local information of a process is sufficient to schedule the execution of a high priority transition. As a result of the model checking, the program is transformed to react upon the knowledge it has at each point. The transformed version has no priorities, and uses the gathered information and its knowledge to limit the enabledness of transitions so that it matches or approximates the original specification of priorities."
2011,Rigorous Component-Based System Design Using the BIP Framework.,"Abstract:
An autonomous robot case study illustrates the use of the behavior, interaction, priority (BIP) component framework as a unifying semantic model to ensure correctness of essential system design properties."
2011,Methods and tools for component-based system design.,"Abstract:
Traditional engineering disciplines such as civil or mechanical engineering are based on solid theory for building artefacts with predictable behavior over their lifetime. In contrast, we lack similar constructivity results for computing systems engineering: computer science provides only partial answers to particular system design problems. With few exceptions, predictability is impossible to guarantee at design time and therefore, a posteriori verification remains the only means for ensuring their correct operation."
2011,Time-predictable and composable architectures for dependable embedded systems.,"Embedded systems must interact with their real-time environment in a timely and dependable fashion. Most embedded-systems architectures and design processes consider ""non-functional"" properties such as time, energy, and reliability as an afterthought, when functional correctness has (hopefully) been achieved. As a result, embedded systems are often fragile in their real-time behaviour, and take longer to design and test than planned. Several techniques have been proposed to make real-time embedded systems more robust, and to ease the process of designing embedded systems:
Precision-timed and time-triggered architectures, to make time a first-class citizen of system design.
Deterministic architectures for repeatable timing behaviour.
Composability, which guarantees that the (non)-functional behaviour of components is unchanged on integration in a larger system.
The tutorial presents the state of the art and major approaches to time-predictability and composability, such as BIP, TTA, PRET, PTIDES, Giotto, and CompSOC."
2011,Component Assemblies in the Context of Manycore.,"Abstract
We present a component-based software design flow for building parallel applications running on top of manycore platforms. The flow is based on the BIP - Behaviour, Interaction, Priority - component framework and its associated toolbox. It provides full support for modeling of application software, validation of its functional correctness, modeling and performance analysis on system-level models, code generation and deployment on target manycore platforms. The paper details some of the steps of the design flow. The design flow is illustrated through the modeling and deployment of two applications, the Cholesky factorization and the MJPEG decoding on MPARM, an ARM-based manycore platform. We emphasize the merits of the design flow, notably fast performance analysis as well as code generation and efficient deployment on manycore platforms."
2011,Rigorous System Design: The BIP Approach.,"Abstract
Rigorous system design requires the use of a single powerful component framework allowing the representation of the designed system at different levels of detail, from application software to its implementation. This is essential for ensuring the overall coherency and correctness. The paper introduces a rigorous design flow based on the BIP (Behavior, Interaction, Priority) component framework [1]. This design flow relies on several, tool-supported, source-to-source transformations allowing to progressively and correctly transform high level application software towards efficient implementations for specific platforms."
2011,Rigorous system level modeling and analysis of mixed HW/SW systems.,"Abstract:
A grand challenge in complex embedded systems design is developing methods and tools for modeling and analyzing the behavior of an application software running on multicore or distributed platforms. We propose a rigorous method and a tool chain that allows to obtain a faithful model representing the behavior of a mixed hardware/software system from a model of its application software and a model of its underlying hardware architecture. The system model can be simulated and analyzed for validation of both functional and extra-functional properties. The tool chain uses DOL (Distributed Operation Layer [1]) as the frontend for specifying the application software and hardware architecture, and BIP (Behavior Interaction Priority [2]) as the modeling and analysis framework. It is illustrated through the construction of system models of MJPEG and MPEG2 decoder applications running on MPARM, a multicore architecture."
2011,D-Finder 2: Towards Efficient Correctness of Incremental Design.,"Abstract
D-Finder 2 is a new tool for deadlock detection in concurrent systems based on effective invariant computation to approximate the effects of interactions among modules. It is part of the BIP framework, which provides various tools centered on a component-based language for incremental design. The presented tool shares its theoretical roots with a previous implementation, but was completely rewritten to take advantage of a new version of BIP and various new results on the theory of invariant computation. The improvements are demonstrated by comparison with previous work and reports on new results on a practical case study."
2011,Synthesizing Glue Operators from Glue Constraints for the Construction of Component-Based Systems.,"Abstract
We study glue operators used in component-based frameworks to obtain systems as the composition of atomic components described as labeled transition systems (LTS). Glue operators map tuples of LTS into LTS. They restrict the behavior of their arguments by performing memoryless coordination. In a previous paper, we have proposed a simple format for SOS rules that captures, in particular, glue operators from known frameworks such as CCS, SCCS, CSP, and BIP.
This paper studies a new way for characterizing glue operators: as boolean glue constraints between interactions (sets of ports) and the state of the coordinated components. We provide an SOS format for glue, which allows a natural correspondence between glue operators and glue constraints. This correspondence is used for automated synthesis of glue operators implementing given glue constraints. By focusing on the properties that do not bear computation, we reduce a very hard (and, in general, undecidable) problem of synthesizing controllers to a tractable one. The examples in the paper show that such properties are natural and can be expressed as glue constraints in a straightforward manner. Finally, we compare expressiveness of the proposed formalisms with the glue used in the BIP framework and discuss possible applications."
2010,Causal semantics for the algebra of connectors.,"The Algebra of Connectors AC(P) is used to model structured interactions in the BIP component framework. Its terms are connectors, relations describing synchronization constraints between the ports of component-based systems. Connectors are structured combinations of two basic synchronization protocols between ports: rendezvous and broadcast.

In a previous paper, we have studied interaction semantics for AC(P) which defines the meaning of connectors as sets of interactions. This semantics reduces broadcasts into the set of their possible interactions and thus blurs the distinction between rendezvous and broadcast. It leads to exponentially complex models that cannot be a basis for efficient implementation. Furthermore, the induced semantic equivalence is not a congruence.

For a subset of AC(P), we propose a new causal semantics that does not reduce broadcast into a set of rendezvous and explicitly models the causal dependency relation between ports. The Algebra of Causal Interaction Trees T(P) formalizes this subset. It is the set of the terms generated from interactions on the set of ports P, by using two operators: a causality operator and a parallel composition operator. Terms are sets of trees where the successor relation represents causal dependency between interactions: an interaction can participate in a global interaction only if its father participates too. We show that causal semantics is consistent with interaction semantics; the semantic equivalence on T(P) is a congruence. Furthermore, it defines an isomorphism between T(P) and a subset of AC(P).

Finally, we define for causal interaction trees a boolean representation in terms of causal rules. This representation is used for their manipulation and simplification as well as for synthesizing connectors."
2010,2009 CAV award announcement.,"Abstract
The 2009 CAV (Computer-Aided Verification) award was presented to seven individuals who made major advances in creating high-performance Boolean satisfiability solvers. This annual award recognizes a specific fundamental contribution or series of outstanding contributions to the CAV field."
2010,Compositional verification for component-based systems and application.,The authors present a compositional method for the verification of component-based systems described in a subset of the behaviour-interaction-priority language encompassing multi-party interaction without data transfer. The method is based on the use of two kinds of invariants. Component invariants are over-approximations of components' reachability sets. Interaction invariants are global constraints on the states of components involved in interactions. The method has been implemented in the D-Finder tool and has been applied for checking deadlock-freedom. The experimental results on non-trivial examples show that this method allows either to prove deadlock-freedom or to identify very few deadlock configurations that can be analysed by using state-space exploration.
2010,Source-to-Source Architecture Transformation for Performance Optimization in BIP.,"Abstract:
Behavior, Interaction, Priorities (BIP) is a component framework for constructing systems from a set of atomic components by using two kinds of composition operators: interactions and priorities. In this paper, we present a method that transforms the interactions of a component-based program in BIP and generates a functionally equivalent program. The method is based on the successive application of three types of source-to-source transformations: flattening of components, flattening of connectors, and composition of atomic components. We show that the system of the transformations is confluent and terminates. By exhaustive application of the transformations, any BIP component can be transformed into an equivalent monolithic component. From this component, efficient standalone C++ code can be generated. The method combines advantages of component-based description such as clarity, incremental construction, and reasoning with the possibility to generate efficient monolithic code. It has been integrated in the design methodology for BIP and it has been successfully applied to two non trivial examples described in this paper."
2010,Knowledge Based Scheduling of Distributed Systems.,"Abstract
Priorities are used to control the execution of systems to meet given requirements for optimal use of resources, e.g., by using scheduling policies. For distributed systems it is hard to find efficient implementations for priorities; because they express constraints on global states, their implementation may incur considerable overhead.
Our method is based on performing model checking for knowledge properties. It allows identifying where the local information of a process is sufficient to schedule the execution of a high priority transition. As a result of the model checking, the program is transformed to react upon the knowledge it has at each point. The transformed version has no priorities, and uses the gathered information and its knowledge to limit the enabledness of transitions so that it matches or approximates the original specification of priorities."
2010,Component-based Construction of Heterogeneous Real-time Systems in BIP.,"Abstract
We present a framework for the component-based construction of real-time systems. The framework is based on the BIP (Behaviour, Interaction, Priority) semantic model, characterized by a layered representation of components. Compound components are obtained as the composition of atomic components specified by their behaviour and interface, by using connectors and dynamic priorities. Connectors describe structured interactions between atomic components, in terms of two basic protocols: rendezvous and broadcast. Dynamic priorities are used to select amongst possible interactions ‚Äì in particular, to express scheduling policies."
2010,From high-level component-based models to distributed implementations.,"Although distributed systems are widely used nowadays, their implementation and deployment is still a time-consuming, error-prone, and hardly predictive task. In this paper, we propose a methodology for producing automatically efficient and correct-by-construction distributed implementations by starting from a high-level model of the application software in BIP. BIP (Behavior, Interaction, Priority) is a component-based framework with formal semantics that rely on multi-party interactions for synchronizing components. Our methodology transforms arbitrary BIP models into Send/Receive BIP models, directly implementable on distributed execution platforms. The transformation consists of (1) breaking atomicity of actions in atomic components by replacing strong synchronizations with asynchronous Send/Receive interactions; (2) inserting several distributed controllers that coordinate execution of interactions according to a user-defined partition, and (3) augmenting the model with a distributed algorithm for handling conflicts between controllers preserving observational equivalence to the initial models. Currently, it is possible to generate from Send/Receive models stand-alone C++ implementations using either TCP sockets for conventional communication, or MPI implementation, for deployment on multi-core platforms. This method is fully implemented. We report concrete results obtained under different scenarios."
2010,Model-based implementation of real-time applications.,"Correct and efficient implementation of general real-time applications remains by far an open problem. A key issue is meeting timing constraints whose satisfaction depends on features of the execution platform, in particular its speed. Existing rigorous implementation techniques are applicable to specific classes of systems e.g. with periodic tasks, time deterministic systems.
We present a general model-based implementation method for real-time systems based on the use of two models.
An abstract model representing the behavior of real-time software as a timed automaton. The latter describes user-defined platform-independent timing constraints. Its transitions are timeless and correspond to the execution of statements of the real-time software.
A physical model representing the behavior of the real-time software running on a given platform. It is obtained by assigning execution times to the transitions of the abstract model.
A necessary condition for implementability is time-safety, that is, any (timed) execution sequence of the physical model is also an execution sequence of the abstract model. Time-safety simply means that the platform is fast enough to meet the timing requirements. As execution times of actions are not known exactly, time-safety is checked for worst-case execution times of actions by making an assumption of time-robustness: time-safety is preserved when speed of the execution platform increases.
We show that as a rule, physical models are not time-robust and show that time-determinism is a sufficient condition for time-robustness.
For given real-time software and execution platform corresponding to a time-robust model, we define an Execution Engine that coordinates the execution of the application software so as to meet its timing constraints. Furthermore, in case of non-robustness, the Execution Engine can detect violations of time-safety and stop execution.
We have implemented the Execution Engine for BIP programs with real-time constraints. We have validated the implementation method for an adaptive MPEG video encoder. Experimental results reveal the existence of timing anomalies seriously degrading performance for increasing platform execution speed."
2010,Embedded systems design - Scientific challenges and work directions.,"Abstract:
Summary form only given. The development of a satisfactory Embedded Systems Design Science provides a timely challenge and opportunity for reinvigorating Computer Science. Embedded systems are components integrating software and hardware jointly and specifically designed to provide given functionalities, which are often critical. They are used in many applications areas including transport, consumer electronics and electrical appliances, energy distribution, manufacturing systems, etc. Embedded systems design requires techniques taking into account extra-functional requirements regarding optimal use of resources such as time, memory and energy while ensuring autonomy, reactivity and robustness. Jointly taking into account these requirements raises a grand scientific and technical challenge: extending Computer Science with paradigms and methods from Control Theory and Electrical Engineering. Computer Science is based on discrete computation models not encompassing physical time and resources which are by their nature very different from analytic models used by other engineering disciplines. We summarize some current trends in embedded systems design and point out some of their characteristics, such as the chasm between analytical and computational models, and the gap between safety critical and best-effort engineering practices. We call for a coherent scientific foundation for embedded systems design, and we discuss a few key demands on such a foundation: the need for encompassing several manifestations of heterogeneity, and the need for design paradigms ensuring constructivity and adaptivity. We discuss main aspects of this challenge and associated research directions for different areas such as modelling, programming, compilers, operating systems and networks."
2010,Incremental component-based construction and verification using invariants.,"Abstract:
We propose invariant-based techniques for the efficient verification of safety and deadlock properties of concurrent systems. We assume that components and component interactions are described within the BIP framework, a tool for component-based design. We build on a compositional methodology in which the invariant is obtained by combining the invariants of the individual components with an interaction invariant that takes concurrency and interaction between components into account. In this paper, we propose new efficient techniques for computing interaction invariants. This is achieved in several steps. First, we propose a formalization of incremental component-based design. Then we suggest sufficient conditions that ensure the preservation of invariants through the introduction of new interactions. For cases in which these conditions are not satisfied, we propose methods for generation of new invariants in an incremental manner. The reuse of existing invariants reduces considerably the verification effort. Our techniques have been implemented in the D-Finder toolset. Among the experiments conducted, we have been capable of verifying properties and deadlock-freedom of DALA, an autonomous robot whose behaviors in the functional level are described with 500000 lines of C Code. This experiment, which is conducted with industrial partners, is far beyond the scope of existing academic tools such as NuSMV or SPIN."
2010,Automated Conflict-free distributed implementation of component-based models.,"Abstract:
We propose a method for generating distributed implementations from high-level models expressed in terms of a set of components glued by rendezvous interactions. The method is a 2-phase transformation preserving all functional properties. The first phase is a source-to-source transformation from global state to a partial state model (to relax atomicity). This transformation replaces multi-party rendezvous interactions by send/receive primitives managed by a set of automatically generated distributed schedulers. These schedulers are conflict-free by construction in the sense that they do not require communication in order to safely execute interactions of the highlevel model. In the second phase, from the transformed model in phase one, we generate C++ distributed code using either TCP sockets or MPI to implement send/receive primitives. Our method is fully implemented in a tool for automatic generation of distributed applications. We present experimental results using different case studies."
2010,Compositional Translation of Simulink Models into Synchronous BIP.,"Abstract:
We present a method for the translation of a discrete-time fragment of Simulink into the synchronous subset of the BIP language. The translation is fully compositional, that is, it preserves completely the original structure and reveals the minimal control coordination structure needed to perform the correct computation within Simulink models. Additionally, this translation can be seen as providing an alternative operational semantics of Simulink models using BIP. The advantages are twofold. It allows for integration of Simulink models within heterogeneous BIP designs. It enables the use of validation and automatic implementation techniques already available for BIP on Simulink models. The translation is currently implemented in the Simulink2BIP tool. We report several experiments, in particular, we show that the executable code generated from BIP models has comparable runtime performances as the code produced by the Real-Time Workshop on several Simulink models."
2010,Systematic Correct Construction of Self-stabilizing Systems: A Case Study.,"Abstract
Design and implementation of distributed algorithms often involve many subtleties due to their complex structure, non-determinism, and low atomicity as well as occurrence of unanticipated physical events such as faults. Thus, constructing correct distributed systems has always been a challenge and often subject to serious errors. We present a methodology for component-based modeling, verification, and performance evaluation of self-stabilizing systems based on the BIP framework. In BIP, a system is modeled as the composition of a set of atomic components by using two types of operators: interactions describing synchronization constraints between components, and priorities to specify scheduling constraints. The methodology involves three steps illustrated using the distributed reset algorithm due to Arora and Gouda. First, a high-level model of the algorithm is built in BIP from the set of its processes by using powerful primitives for multi-party interactions and scheduling. Then, we use this model for verification of properties of a self-stabilizing algorithm. Finally, a distributed model which is observationally equivalent to the high-level model is generated."
2010,Embedded Systems Design - Scientific Challenges and Work Directions.,"Abstract
The development of a satisfactory Embedded Systems Design Science provides a timely challenge and opportunity for reinvigorating Computer Science.
Embedded systems are components integrating software and hardware jointly and specifically designed to provide given functionalities, which are often critical. They are used in many applications areas including transport, consumer electronics and electrical appliances, energy distribution, manufacturing systems, etc."
2010,Incremental Invariant Generation for Compositional Design.,"Abstract:
We consider a compositional method for the verification of component-based systems described in a subset of the BIP language encompassing multi-party interactions. The method is based on the use of two kinds of invariants. Component invariants are over-approximations of components' reach ability sets. Interaction invariants are constraints on the states of components involved in interactions. In this paper we propose fixed point characterization for computing interaction invariants. We also propose a new technique that takes the incremental design of the system into account. In many situations, the technique will help to avoid redoing all the verification process each time an interaction is added in the design. Our two techniques have been implemented as extension of the D-Finder toolset. The result has been applied to check deadlock-freedom on several case studies. Our experiments show that our new methodology is generally much faster than existing ones."
2009,Component-Based Construction of Heterogeneous Real-Time Systems in Bip.,"Abstract
We present a framework for the component-based construction of real-time systems. The framework is based on the BIP (Behaviour, Interaction, Priority) semantic model, characterized by a layered representation of components. Compound components are obtained as the composition of atomic components specified by their behaviour and interface, by using connectors and dynamic priorities. Connectors describe structured interactions between atomic components, in terms of two basic protocols: rendezvous and broadcast. Dynamic priorities are used to select amongst possible interactions - in particular, to express scheduling policies.
The BIP framework has been implemented in a language and a toolset. The BIP language offers primitives and constructs for modelling and composing atomic components described as state machines, extended with data and functions in C. The BIP toolset includes an editor and a compiler for generating from BIP programs, C++ code executable on a dedicated platform. It also allows simulation and verification of BIP programs by using model checking techniques.
BIP supports a model-based design methodology involving three steps:
1
The construction of a system model from a set of atomic components composed by progressively adding interactions and priorities.
 1
The application of incremental verification techniques. These techniques use the fact that the designed system model can be obtained by successive application of property-preserving transformations in a three-dimensional space: Behavior √ó Interaction √ó Priority.
 1
The generation of correct-by-construction distributed implementations from the designed model. This is achieved by source-to-source transformations which preserve global state semantics.
 We provide two examples illustrating the methodology.
Further information is available at:
http://www-verimag.imag.fr/~async/bip.php"
2009,Component-Based Construction of Real-Time Systems in BIP.,"Abstract
BIP is a framework for the component-based construction of real-time systems. It considers that systems can be obtained as the composition of 3-layer components. For a component,
The lower layer describes its behavior, a set of transitions with triggers and actions (atomic state transformations). A trigger consists of an enabling condition on data and a port through which synchronization is sought.
The intermediate level is the set of interactions between transitions of the behavior level. An interaction is a set of synchronizing ports and associated actions. Interactions are specified by using connectors expressing synchronization constraints on ports.
The upper level is a set of priority rules implementing scheduling policies for interactions.
The framework supports a system construction methodology which is based on a parameterized binary composition operator on components. The product of two components consists in composing their corresponding layers, separately. Parameters are used to define new interactions as well as new priorities between the composed components."
2009,Priority Scheduling of Distributed Systems Based on Model Checking.,"Abstract
Priorities are used to control the execution of systems to meet given requirements for optimal use of resources, e.g., by using scheduling policies. For distributed systems, it is hard to find efficient implementations for priorities; because they express constraints on global states, their implementation may incur considerable overhead.
Our method is based on performing model checking for knowledge properties. It allows identifying where the local information of a process is sufficient to schedule the execution of a high priority transition. As a result of the model checking, the program is transformed to react upon the knowledge it has at each point. The transformed version has no priorities, and uses the gathered information and its knowledge to limit the enabledness of transitions so that it matches or approximates the original specification of priorities."
2009,D-Finder: A Tool for Compositional Deadlock Detection and Verification.,"Abstract
D-Finder tool implements a compositional method for the verification of component-based systems described in BIP language encompassing multi-party interaction. For deadlock detection, D-Finder applies proof strategies to eliminate potential deadlocks by computing increasingly stronger invariants."
2009,Embedded systems design - Scientific challenges and work directions.,"Abstract:
Summary form only given. The development of a satisfactory Embedded Systems Design Science provides a timely challenge and opportunity for reinvigorating Computer Science. Embedded systems are components integrating software and hardware jointly and specifically designed to provide given functionalities, which are often critical. They are used in many applications areas including transport, consumer electronics and electrical appliances, energy distribution, manufacturing systems etc. Embedded systems design requires techniques taking into account extra-functional requirements regarding optimal use of resources such as time, memory and energy while ensuring autonomy, reactivity and robustness. Jointly taking into account these requirements raises a grand scientific and technical challenge extending Computer Science with paradigms and methods from Control Theory and Electrical Engineering. Computer Science is based on discrete computation models not encompassing physical time and resources which are by their nature very different from analytic models used by other engineering disciplines. We summarise some current trends in embedded systems design and point out some of their characteristics, such as the chasm between analytical and computational models and the gap between safety critical and best-effort engineering practices. We call for a coherent scientific foundation for embedded systems design, and we discuss a few key demands on such a foundation: the need for encompassing several manifestations of heterogeneity, and the need for design paradigms ensuring constructivity and adaptivity. We discuss main aspects of this challenge and associated research directions for different areas such as modelling, programming, compilers, operating systems and networks."
2009,Modeling synchronous systems in BIP.,"We present a general approach for modeling synchronous component-based systems. These are systems of synchronous components strongly synchronized by a common action that initiates steps of each component. We propose a general model for synchronous systems. Steps are described by acyclic Petri nets equipped with data and priorities. Petri nets are used to model concurrent flow of computation. Priorities are instrumental for enforcing run-to-completion in the execution of a step.
We study a class of well-triggered synchronous systems which are by construction deadlock-free and their computation within a step is confluent. For this class, the behavior of components is modeled by modal flow graphs. These are acyclic graphs representing three different types of dependency between two events p and q: strong dependency (p must follow q), weak dependency (p may follow q), conditional dependency (if both p and q occur then p must follow q).
We propose a translation of Lustre into well-triggered synchronous systems. This translation is modular and exhibits not only data-flow connections between nodes but also their synchronization by using clocks."
2009,Source-to-source architecture transformation for performance optimization in BIP.,"Abstract:
BIP (behavior, interaction, priorities) is a component framework for constructing systems from a set of atomic components by using two kinds of composition operators: interactions and priorities. In this paper we present a method that transforms the interactions of a component-based program in BIP and generates a functionally equivalent program. The method is based on the successive application of three types of source-to-source transformations: flattening of components, flattening of connectors and composition of atomic components. We show that the system of the transformations is confluent and terminates. By exhaustive application of the transformations, any BIP component can be transformed into an equivalent monolithic component. From this component, efficient C code can be generated. The method combines advantages of component-based description such as clarity, incremental construction and reasoning with the possibility to generate efficient monolithic code. It has been integrated in the design methodology for BIP and it has been successfully applied to two non trivial examples described in the paper."
2009,The Quest for Correctness-Beyond a Posteriori Verification.,"Abstract
In this presentation, I discuss the main achievements in the area of formal verification, in particular regarding their impact thus far on the development of Computer Science as a discipline and on future research directions.
The presentation starts with a short overview of formal verification techniques and their main characteristics, followed by an analysis of their current status with respect to: 1) requirements specification; 2) faithfulness of modeling; 3) scalability of verification methods. Compositional modeling and verification is the main challenge to tackling complexity. System verification should be tightly integrated into the design process, making use of knowledge about the system‚Äôs structure and its properties.
I identify two complementary research directions for overcoming some of the current difficulties in compositional techniques: 1) Moving away from low-level automata-based composition to component-based composition, by developing frameworks encompassing heterogeneous components; 2) Using such frameworks to study compositionality techniques for particular architectures and/or specific properties.
I illustrate these ideas through the BIP (Behavior, Interaction, Priority) component framework which encompasses high-level composition of heterogeneous components.
BIP supports a design methodology for building systems in a three-dimensional design space by using property-preserving transformations. This allows efficient compositional verification techniques for proving invariants, and deadlock-freedom in particular."
2009,"Brief Announcement: Incremental Component-Based Modeling, Verification, and Performance Evaluation of Distributed Reset.","Abstract
Design and implementation of distributed algorithms often involve many subtleties due to their complex structure, nondeterminism, and low atomicity as well as occurrence of unanticipated physical events such as faults. Thus, constructing correct distributed systems has always been a challenge and often subjects to serious errors. This is essentially due to the fact that we currently lack disciplined methods for the rigorous design and correct implementation of distributed systems, mainly for two reasons: (1) formal methods are not easy to use by designers and developers; and (2) there is a wide gap between modeling formalisms and automated verification tools on one side, and practical development and deployment tools on the other side."
2008,Symbolic quality control for multimedia applications.,"We present a fine grain quality control method for multimedia applications. The method takes as input an application software composed of actions. The execution times of actions are unknown increasing functions of quality level parameters. The method allows the construction of a Controller which computes adequate action schedules and corresponding quality levels, so as to meet QoS requirements for a given platform. These include requirements for safety (action deadlines are met) as well optimality (maximization and smoothness of quality levels).

The Controller consists of a Quality Manager and a Scheduler. For each action, the Controller uses a quality management policy for choosing a schedule and quality levels meeting the QoS requirements. The schedule is selected amongst a set of optimal schedules computed by the Scheduler.

We extend and improve results of previous papers providing a solid theoretical basis for designing and implementing the Controller.

We propose a symbolic quality management method using speed diagrams, a representation of the controlled systemís dynamics. Instead of numerically computing a quality level for each action, the Quality Manager changes action quality levels based on the knowledge of constraints characterizing control relaxation regions. These are sets of states in which quality management for a given number of computation steps can be relaxed without degrading quality.

We study techniques for efficient computation of optimal schedules.

We present experimental results including the implementation of the method and benchmarks for an MPEG4 video encoder. The benchmarks show drastic performance improvement for controlled quality with respect to constant quality. They also show that symbolic quality management allows significant reduction of the overhead with respect to numeric quality management. Finally, using optimal schedules can lead to considerable performance gains."
2008,The Algebra of Connectors - Structuring Interaction in BIP.,"Abstract:
We provide an algebraic formalization of connectors in the BIP component framework. A connector relates a set of typed ports. Types are used to describe different modes of synchronization, in particular, rendezvous and broadcast. Connectors on a set of ports P are modeled as terms of the algebra AC(P), generated from P by using a binary fusion operator and a unary typing operator. Typing associates with terms (ports or connectors) synchronization types - trigger or synchron - that determine modes of synchronization. Broadcast interactions are initiated by triggers. Rendezvous is a maximal interaction of a connector that includes only synchrons. The semantics of AC(P) associates with a connector the set of its interactions. It induces on connectors an equivalence relation which is not a congruence as it is not stable for fusion. We provide a number of properties of AC(P) used to symbolically simplify and handle connectors. We provide examples illustrating applications of AC(P), including a general component model encompassing methods for incremental model decomposition and efficient implementation by using symbolic techniques."
2008,Compositional Verification for Component-Based Systems and Application.,"Abstract
We present a compositional method for the verification of component-based systems described in a subset of the BIP language encompassing multi-party interaction without data transfer. The method is based on the use of two kinds of invariants. Component invariants which are over-approximations of components‚Äô reachability sets. Interaction invariants which are constraints on the states of components involved in interactions. Interaction invariants are obtained by computing traps of finite-state abstractions of the verified system. The method is applied for deadlock verification in the D-Finder tool. D-Finder is an interactive tool that takes as input BIP programs and applies proof strategies to eliminate potential deadlocks by computing increasingly stronger invariants. The experimental results on non-trivial examples allow either to prove deadlock-freedom or to identify very few deadlock configurations that can be analyzed by using state space exploration."
2008,A Notion of Glue Expressiveness for Component-Based Systems.,"Abstract
Comparison between different formalisms and models is often by flattening structure and reducing them to behaviorally equivalent models e.g. automaton and Turing machine. This leads to a notion of expressiveness which is not adequate for component-based systems where separation between behavior and coordination mechanisms is essential. The paper proposes a notion of glue expressiveness for component-based frameworks characterizing their ability to coordinate components.
Glue is a closed under composition set of operators mapping tuples of behavior into behavior. Glue operators preserve behavioral equivalence. They only restrict the behavior of their arguments by performing memoryless coordination.
Behavioral equivalence induces an equivalence on glue operators. We compare expressiveness of two glues G 1 and G 2 by considering whether glue operators of G 1 have equivalent ones in G 2 (strong expressiveness). Weak expressiveness is defined by allowing a finite number of additional behaviors in the arguments of operators of G 2.
We propose an SOS-style definition of glues, where operators are characterized as sets of SOS-rules specifying the transition relation of composite components from the transition relations of their constituents. We provide expressiveness results for the glues of BIP and of process algebras such as CCS, CSP and SCCS. We show that for the considered expressiveness criteria, glues of the considered process calculi are less expressive than general SOS glue. Furthermore, glue of BIP has exactly the same strong expressiveness as glue definable by the SOS characterization."
2008,Incremental Component-Based Construction and Verification of a Robotic System.,"We propose invariant-based techniques for the efficient verification of safety and deadlock properties of concurrent systems. We assume that components and component interactions are described within the BIP framework, a tool for component-based design. We build on a compositional methodology in which the invariant is obtained by combining the invariants of the individual components with an interaction invariant that takes concurrency and interaction between components into account. In this paper, we propose new efficient techniques for computing interaction invariants. This is achieved in several steps. First, we propose a formalization of incremental component-based design. Then we suggest sufficient conditions that ensure the preservation of invariants through the introduction of new interactions. For cases in which these conditions are not satisfied, we propose methods for generation of new invariants in an incremental manner. The reuse of existing invariants reduces considerably the verification effort. Our techniques have been implemented in the D-Finder toolset. Among the experiments conducted, we have been capable of verifying properties and deadlock-freedom of DALA, an autonomous robot whose behaviors in the functional level are described with 500000 lines of C Code. This experiment, which is conducted with industrial partners, is far beyond the scope of existing academic tools such as NuSMV or SPIN."
2008,Distributed Semantics and Implementation for Systems with Interaction and Priority.,"Abstract
The paper studies a distributed implementation method for the BIP (Behavior, Interaction, Priority) component framework for modeling heterogeneous systems.
BIP offers two powerful mechanisms for describing composition of components by combining interactions and priorities. A system model is layered. The lowest layer contains atomic components; the second layer, describes possible interactions between atomic components; the third layer includes priorities between the interactions. The current implementation of BIP is based on global state operational semantics. An Engine directly interprets the operational semantics rules and computes the possible interactions between atomic components from global states.
The implementation method is a translation from BIP models into distributed models involving two steps. The first translates BIP models into partial state models where are known only the states of the components which are ready to communicate. The second implements interactions in the partial state model by using message passing primitives.
The main results of the paper are conditions for which the three models are observationally equivalent. We show that in general, the translation from global state to partial state models does not preserve observational equivalence. Preservation can be achieved by strengthening the premises of the operational semantics rules by an oracle. This is a predicate depending on the priorities of the BIP model. We show that there are many possible choices for oracles. Maximal parallelism is achieved for dynamic oracles allowing interaction as soon as possible. Nonetheless, these oracles may entail considerable computational overhead. We study performance trade-offs for different types of oracles. Finally, we provide experimental results illustrating the application of the theory on a prototype implementation."
2008,Translating AADL into BIP - Application to the Verification of Real-Time Systems.,"Abstract
This paper studies a general methodology and an associated tool for translating AADL (Architecture Analysis and Design Language) and annex behavior specification into the BIP (Behavior Interaction Priority) language. This allows simulation of systems specified in AADL and application to these systems of formal verification techniques developed for BIP, e.g. deadlock detection. We present a concise description of AADL and BIP followed by the presentation of the translation methodology illustrated by a Flight Computer example."
2008,Specification and Verification of Conurrent Systems in Cesar.,"Abstract
The aim of this paper is to illustrate by an example, the alternating bit protocol, the use of CESAR, an interactive system for aiding the design of distributed applications.
CESAR allows the progressive validation of the algorithmic description of a system of communicating sequential processes with respect to a given set of specifications. The algorithmic description is done in a high level language inspired from CSP and specifications are a set of formulas of a branching time logic, the temporal operators of which can be computed iteratively as fixed points of monotonic predicate transformers. The verification of a system consists in obtaining by automatic translation of its description program an Interpreted Petri Net representing it and evaluating each formula of the specifications."
2007,The Discipline of Embedded Systems Design.,"Abstract:
The wall between computer science and electrical engineering has kept the potential of embedded systems at bay. It is time to build a new scientific foundation with embedded systems design as the cornerstone, which will ensure a systematic and even-handed integration of the two fields. The embedded systems design problem certainly raises technology questions, but more important, it requires building a new scientific foundation that will systematically and even-handedly integrate computation and physicality from the bottom up. Support for this foundation will require enriching computer science paradigms to encompass models and methods traditionally found in electrical engineering."
2007,The algebra of connectors: structuring interaction in BIP.,"We provide an algebraic formalisation of connectors in BIP. These are used to structure interactions in a component-based system. A connector relates a set of typed ports. Types are used to describe different modes of synchronisation: rendezvous and broadcast, in particular.
Connectors on a set of ports P are modelled as terms of the algebra AC(P), generated from P by using a binary fusion operator and a unary typing operator. Typing associates with terms (ports or connectors) synchronisation types - trigger or synchron - , which determine modes of synchronisation. Broadcast interactions are initiated by triggers. Rendezvous is a maximal interaction of a connector including only synchrons.
The semantics of AC(P) associates with a connector the set of its interactions. It induces on connectors an equivalence relation which is not a congruence as it is not stable for fusion. We provide a number of properties of AC(P) used to symbolically simplify and handle connectors. We provide examples illustrating applications of AC(P), including a general component model encompassing synchrony, methods for incremental model decomposition, and efficient implementation by using symbolic techniques."
2007,Causal Semantics for the Algebra of Connectors.,"Abstract
The Algebra of Connectors
is used to model structured interactions in the BIP component framework. Its terms are connectors, i.e. relations describing synchronization constraints between the ports of component-based systems. Connectors are structured combinations of two basic synchronization protocols between ports: rendezvous and broadcast. They are generated from the ports of P by using a binary fusion operator and a unary typing operator. Typing associates with terms (ports or connectors) synchronization types: trigger or synchron.
In a previous paper, we studied interaction semantics for
which defines the meaning of connectors as sets of interactions. This semantics reduces broadcasts into the set of their possible interactions and thus blurs the distinction between rendezvous and broadcast. It leads to exponentially complex models that cannot be a basis for efficient implementation. Furthermore, the induced semantic equivalence is not a congruence.
For a subset of
, we propose a new causal semantics that does not reduce broadcast into a set of rendezvous and explicitly models the causal dependency relation between triggers and synchrons. The Algebra of Causal Trees
formalizes this subset. It is the set of the terms generated from interactions on the set of ports P, by using two operators: a causality operator and a parallel composition operator. Terms are sets of trees where the successor relation represents causal dependency between interactions: an interaction can participate in a global interaction only if its parent participates too. We show that causal semantics is consistent with interaction semantics. Furthermore, it defines an isomorphism between
and the set of the terms of
involving triggers.
Finally, we define for causal trees a boolean representation in terms of causal rules."
2007,Using Speed Diagrams for Symbolic Quality Management.,"Abstract:
We present a quality management method for multimedia applications. The method takes as input an application software composed of actions. The execution times of actions are unknown increasing junctions of quality level parameters. The method allows the construction of a quality manager which computes adequate action quality levels so as to meet QoS requirements for a given platform. These include deadlines for the actions as well as quality maximization and smoothness. We extend and improve results of a previous paper by focusing on the reduction of overhead due to quality management. We propose a symbolic quality management method using speed diagrams, a representation of the system's dynamics. Instead of numerically computing a quality level for each action, the quality manager changes action quality levels based on the knowledge of constraints characterizing control relaxation regions. These are sets of states in which quality management for a given number of steps can be relaxed without degrading quality. We provide experimental results for quality management of an MPEG encoder, in particular performance benchmarks for both numeric and symbolic quality management."
2007,Using BIP for Modeling and Verification of Networked Systems -- A Case Study on TinyOS-based Networks.,"Abstract:
We apply a model construction methodology to TinyOS- based networks, using the behavior-interaction-priority (BIP) component framework. The methodology consists in building the model of a node as the composition of a model extracted from a nesC program describing the application, and models of TinyOS components. Models for networks are obtained by composition of models for nodes by using BIP connectors implementing different types of radio chan- nels. This opens the way for enhanced analysis and early error detection by using verification techniques."
2007,An Approach to Modelling and Verification of Component Based Systems.,"Abstract
We build on a framework for modelling and investigating component-based systems that strictly separates the description of behavior of components from the way they interact. We discuss various properties of system behavior as liveness, local progress, local and global deadlock, and robustness. We present a criterion that ensures liveness and can be tested in polynomial time."
2006,Ensuring Properties of Interaction Systems.,"Abstract
We propose results ensuring properties of a component-based system from properties of its interaction model and of its components. We consider here deadlock-freedom and local progress of subsystems. This is done in the framework of interaction systems, a model for component based modelling described in [9]. An interaction system is the superposition of two models: a behavior model and an interaction model. The behavior model describes the behavior of individual components. The interaction model describes the way the components may interact by introducing connectors that relate actions from different components. We illustrate our concepts and results with examples."
2006,The Embedded Systems Design Challenge.,"Abstract
We summarize some current trends in embedded systems design and point out some of their characteristics, such as the chasm between analytical and computational models, and the gap between safety-critical and best-effort engineering practices. We call for a coherent scientific foundation for embedded systems design, and we discuss a few key demands on such a foundation: the need for encompassing several manifestations of heterogeneity, and the need for constructivity in design. We believe that the development of a satisfactory Embedded Systems Design Science provides a timely challenge and opportunity for reinvigorating computer science."
2006,WPDRTS keynote: component-based construction of embedded systems.,"Abstract:
Summary form only given. We present a framework for the component-based construction of embedded systems. The framework is based on a general semantic model, encompassing various models of computation for real-time systems. It is characterized by the combined use of models for behavior, interaction and dynamic priorities. Interaction models describe interactions between components by using connectors with synchronization types. Dynamic priorities are used to specify controllers and schedulers in particular. We also present a methodology for model-based composition of real-time systems using this semantic model. The methodology enables correct-by-construction development for properties such as deadlock-freedom and progress, as well as incremental construction and associativity of composition operators. We present two implementations of the framework in system modeling and validation tools developed at Verimag: 1) A partial implementation in the state exploration platform of the IF tool suite dedicated to the validation of asynchronous system modeling languages such as UML and SDL; 2) A more recent full implementation in a platform for the execution of both synchronous and asynchronous components. The methodology is illustrated by the use of these tools on case studies for real-time systems modeling and validation"
2006,A Methodology and Supporting Tools for the Development of Component-Based Embedded Systems.,"Abstract
The paper presents a methodology and supporting tools for developing component-based embedded systems running on resource-limited hardware platforms. The methodology combines two complementary component frameworks in an integrated tool chain: BIP and Think. BIP is a framework for model-based development including a language for the description of heterogeneous systems, as well as associated simulation and verification tools. Think is a software component framework for the generation of small-footprint embedded systems. The tool chain allows generation, from system models described in BIP, of a set of functionally equivalent Think components. From these and libraries including OS services for a given hardware platform, a minimal system can be generated. We illustrate the results by modeling and implementing a software MPEG encoder on an iPod."
2006,Modeling Heterogeneous Real-time Components in BIP.,"Abstract:
We present a methodology for modeling heterogeneous real-time components. Components are obtained as the superposition of three layers: behavior, specified as a set of transitions; Interactions between transitions of the behavior; Priorities, used to choose amongst possible interactions. A parameterized binary composition operator is used to compose components layer by layer. We present the BIP language for the description and composition of layered components as well as associated tools for executing and analyzing components on a dedicated platform. The language provides a powerful mechanism for structuring interactions involving rendezvous and broadcast. We show that synchronous and timed systems are particular classes of components. Finally, we provide examples and compare the BIP framework to existing ones for heterogeneous component-based modeling"
2005,Composition for component-based modeling.,"Abstract
We propose a framework for component-based modeling using an abstract layered model for components. A component is the superposition of two models: a behavior model and an interaction model. Interaction models describe architectural constraints induced by connectors between components.
We propose and analyze general requirements for component composition that motivated and guided the development of the framework. We define an associative and commutative composition operator on components encompassing heterogeneous interaction. As a particular instance of the proposed framework, we consider components where behavior models are transition systems and interaction models are described by priority relations on interactions. This leads to a concept of ‚Äúflexible‚Äù composition different from usual composition in that it preserves deadlock-freedom and is appropriate for correctness by construction. Nevertheless, flexible composition is a partial operation. Product systems should be interaction safe in the sense that they do not violate constraints of the interaction model.
We propose results ensuring correctness by construction of a system from properties of its interaction model and of its components. The properties considered include global deadlock-freedom, individual deadlock-freedom of components, and interaction safety."
2005,Guidelines for a graduate curriculum on embedded software and systems.,"The design of embedded real-time systems requires skills from multiple specific disciplines, including, but not limited to, control, computer science, and electronics. This often involves experts from differing backgrounds, who do not recognize that they address similar, if not identical, issues from complementary angles. Design methodologies are lacking in rigor and discipline so that demonstrating correctness of an embedded design, if at all possible, is a very expensive proposition that may delay significantly the introduction of a critical product. While the economic importance of embedded systems is widely acknowledged, academia has not paid enough attention to the education of a community of high-quality embedded system designers, an obvious difficulty being the need of interdisciplinarity in a period where specialization has been the target of most education systems. This paper presents the reflections that took place in the European Network of Excellence Artist leading us to propose principles and structured contents for building curricula on embedded software and systems."
2005,Fine Grain QoS Control for Multimedia Application Software.,"Abstract:
We propose a method for fine grain QoS control of dataflow applications. We assume that the application software is described as the composition of actions (C-functions) with quality level parameters. The method allows a QoS controller to be computed from this description, and also average execution times, worst case execution times and deadlines for its actions. The controller computes dynamically feasible schedules and quality assignments for their actions. Furthermore, the control policy ensures optimal time budget utilization. A prototype tool implementing the method is shown, as well as experimental results for a non trivial example. The results show the interest of fine grain QoS control for video encoders."
2005,QoS control for optimality and safety.,"We propose a method for fine grain QoS control of real-time applications. The method allows adapting the overall system behavior by adequately setting the quality level parameters of its actions. The objective of the control policy is to meet QoS requirements including three types of properties: 1) safety that is, no deadline is missed; 2) optimality that is, maximization of the available time budget; 3) smoothness of quality levels. The method takes as input a model of the application software, QoS requirements and platform-dependent timing information, and produces a controlled application software meeting the QoS requirements on the target platform. This paper provides a complete formalization of the quality control problem. It proposes a new control management policy ensuring safety, near-optimality and smoothness. It also describes a prototype tool implementing the quality control algorithm and experimental results about its application to a video encoder."
2005,A Framework for Component-based Construction Extended Abstract.,"Abstract:
We present an overview of results developed mainly at Verimag, by the author and his colleagues, on a framework for component-based construction, characterized by the following: the behavior of atomic components is represented by transition systems; components are built from a set of atomic components by using ""glue"" operators; for each component, it is possible to separate its behavior from its structure, due to specific properties of glue operators. We show an instance of this framework, which combines two independent classes of glue operators, interaction models and priorities. The combination of interaction models and priorities is expressive enough to encompass heterogeneous interaction and execution. We show that separation between behavior and structure is instrumental for correctness-by-construction. Finally, we discuss new research problems related to a structure-dependent notion of expressiveness."
2004,Embedded Systems - Challenges and Work Directions.,"Abstract
Embedded Systems are components integrating software and hardware jointly and specifically designed to provide given functionalities. These components may be used in many different types of applications, including transport (avionics, space, automotive, trains), electrical and electronic appliances (cameras, toys, television, washers, dryers, audio systems, cellular phones), power distribution, factory automation systems, etc.
Their extensive use and integration in everyday products marks a significant evolution in information science and technology. A main trend is the proliferation of embedded systems, that should work in seamless interaction while respecting real-world constraints.
Embedded systems have a number of specific characteristics, which play a role in structuring the technical domain including criticality, reactivity and autonomy.
The coming generations of embedded systems ‚Äì primarily used in mass-market products ‚Äì need development methods and tools allowing to jointly consider functionality, quality, physical implementation, and market constraints: The need to jointly consider functional and extra-functional constraints leads to a system-centric approach to development. Here, the main focus is the end result: a system as the combination of hardware and software, in interaction with its physical environment.
Current methods and tools do not allow system-centric approaches. These approaches raise difficult, fundamental research problems, which are the basis of an emerging theory that should bring together information and physical sciences. Information sciences consider models of computation based on abstract notions of machines (e.g., automata, complexity and computability theory, algorithms, etc.), that do not take into account physical properties of computation (e.g., execution times, delays, latency, etc.). There is no unified theory allowing to predict the behavior of an application software on a given execution platform which determines execution speed and other dynamic properties of the application.
System-centric approaches raise two grand challenges common to all the activities of system development. The first is theory and tools for rigorous component-based engineering. This determines our ability to build complex systems from simpler ones by mastering their complexity. The second is intelligence, a long term vision for systems that are able to analyze and adapt their behavior according to changes of their environment.
We discuss specific work directions in system development activities to meet these challenges, including modeling, programming and compilation, operating systems design, controller synthesis, testing and verification."
2004,Modeling Real-Time Systems.,"Modeling real-time systems raises non trivial problems for the definition of usable modeling languages and the application of model-based development approaches.

We identify key problems and present corresponding research directions for the incremental construction of timed models for real-time systems. We present a framework that may provide some solutions and an associated methodology for model construction. Timed models of real-time systems are obtained by adding timing constraints to their application software. These constraints take into account execution times of atomic statements, the dynamics of the external environment, as well as quality of service requirements. The framework combines two kinds of composition operators for timed components:

Restriction operators which are unary operators parameterized by a safety property. Their application on a component restricts its behavior so as to meet the associated property. Dynamic priorities correspond to a class of restriction operators which preserve deadlock-freedom of their arguments.

Parallel composition operators, parameterized by interaction models. These models describe interactions between actions offered by the composed components and their associated synchronization requirements.

We show that the combination of parallel composition and restriction operators allows compositional modeling of real-time systems, in particular of aspects related to heterogeneous interaction and execution, resource sharing and scheduling. Scheduling policies are modeled by dynamic priorities. The framework supports composition of scheduling policies and provides compositionality and composability results for deadlock-freedom of scheduled systems.

We show applications of these results, including model-based development of applications in Esterel and real-time Java, as well as a partial implementation of the framework in Verimag's IF toolset."
2004,The IF Toolset.,"Abstract
This paper presents an overview on the IF toolset which is an environment for modelling and validation of heterogeneous real-time systems. The toolset is built upon a rich formalism, the IF notation, allowing structured automata-based system representations. Moreover, the IF notation is expressive enough to support real-time primitives and extensions of high-level modelling languages such as SDL and UML by means of structure preserving mappings.
The core part of the IF toolset consists of a syntactic transformation component and an open exploration platform. The syntactic transformation component provides language level access to IF descriptions and has been used to implement static analysis and optimisation techniques. The exploration platform gives access to the graph of possible executions. It has been connected to different state-of-the-art model-checking and test-case generation tools.
A methodology for the use of the toolset is presented at hand of a case study concerning the Ariane-5 Flight Program for which both an SDL and a UML model have been validated."
2003,Building models of real-time systems from application software.,"We present a methodology for building timed models of real-time systems by adding time constraints to their application software. The applied constraints take into account execution times of atomic statements, the behavior of the system's external environment, and scheduling policies. The timed models of the application obtained in this manner can be analyzed by using time analysis techniques to check relevant real-time properties. We show an instance of the methodology developed in the TAXYS project for the modeling and analysis of real-time systems programmed in the Esterel language. This language has been extended to describe, by using pragmas, time constraints characterizing the execution platform and the external environment. An analyzable timed model of the real-time system is produced by composing instrumented C-code generated by the compiler. The latter has been re-engineered in order to take into account the pragmas. Finally, we report on applications of TAXYS to several nontrivial examples. "
2003,Priority Systems.,"Abstract
We present a framework for the incremental construction of deadlock-free systems meeting given safety properties. The framework borrows concepts and basic results from the controller synthesis paradigm by considering a step in the construction process as a controller synthesis problem.
We show that priorities are expressive enough to represent restrictions induced by deadlock-free controllers preserving safety properties. We define a correspondence between such restrictions and priorities and provide compositionality results about the preservation of this correspondence by operations on safety properties and priorities. Finally, we provide an example illustrating an application of the results."
2003,Component-Based Construction of Deadlock-Free Systems: Extended Abstract.,"Abstract
We propose a framework for building deadlock-free systems from deadlock-free components. The framework is based on a methodology for the layered construction of systems by superposing three layers. A layer of components, an interaction model and a restriction layer. The interaction model specifies the possible interactions between components. The restriction layer restricts the behavior of the two lower layers by a global constraint. Layered structuring allows separating three orthogonal aspects in system construction. Apart from its methodological interest it makes technically possible the definition of a unique and powerful associative composition operator.
We study sufficient deadlock-freedom conditions for systems built from deadlock-free components and given interaction model and restriction. We also provide a sufficient condition for individual deadlock-freedom of the components of such systems."
2002,Abstracts of Invited Talks.,"Abstract
Towards Adaptive Real-Time Systems
Giorgio Buttazzo
University of Pavia
Italy
Modern real-time applications, including multimedia systems, mobile robotics, and distributed monitoring architectures, often operate in highly dynamic environments where workload conditions are difficult to predict in advance. In addition, real-time activities may have variable computational requirements and are characterized by more flexible timing constraints than classical real-time theory usually permits. Handling such systems according to a hard real-time paradigm (based on worst-case assumptions) is inappropriate, because it would cause a waste of resources and would dramatically increase the cost. Recently, significant work has been devoted at increasing the flexibility and the efficiency of real-time systems, still providing a form of performance guarantee.
The goal of this talk is to introduce a set of new methodologies that can be adopted to develop adaptive real-time systems, that is, systems which can modify resource management policies based on the current workload conditions. In this framework, tasks are allowed to have less stringent timing constraints to achieve higher resource utilization. Moreover, the concept of yes-or-no guarantee is replaced with the notion of quality of service, which can be specified within a much larger grey-level scale.
Real Life Timing Analysis at Intel
Avi Efrati
Intel, Haifa
Israel
The current generation of VLSI CPU's include a huge number of devices and the complexity is continuously increasing as technology scaling allows the designers to put more and more functionality within same area. At the same time the more and more advanced processes with faster devices allow higher operating frequency which require considering inductance and other physical effects. Lower voltages and smaller devices require increased timing accuracy. We take a two-prong approach, by increasing accuracy at the local level and supporting hierarchical models which abstract internals of blocks while preserving timing accuracy and interface electrical behaviour.
This talk will give an overview of timing analysis at intel. Hierarchical timing models that enable full-chip timing will be described as well as interaction with academia in timing-related topics, such as false paths identification.
Scheduling by a Combination of Mathematical and Constraint Programming
John Hooker
Carnegie Mellon University
Pittsburgh, USA
I survey decomposition-methods that combine mathematical and constraint programming for solving scheduling problems.  Theidea is to generalize Benders decomposition so that the subproblem is a constraint programming problem in which Benders cuts are obtained by logical inference, and the master problem is a mixed integer programming problem.  I report results by Jain and Grossmann for a machine scheduling problem, and by Thorsteinsson for a branch-and-check approach to the same problem. I suggest how to generalize the approach using a continuous relaxation of the cumulative constraint (joint work with Yan).
Temporal and Resource Constraints in Constraint-Based Scheduling
Claude Le Pape
ILOG SA
Paris, France
Scheduling consists in assigning execution times and resources to activities so as to satisfy a variety of constraints (time bounds, precedence relations, resource capacity constraints, etc.) and optimize one or several conflicting performance criteria (total schedule duration, cost, schedule robustness, etc.). Two main issues have to be considered to evaluate the applicability of a model of time and resources to industrial scheduling applications: ""flexibility"" and ""efficiency"". Flexibility means that the specific constraints of a given application shall be easy to represent in the given model. Efficiency means that the algorithms that are applicable to this model must provide good solutions in limited CPU time. As scheduling applications tend to be different one from another, this led to the development of a variety of models of time and resources, with different characteristics in terms of flexibility and efficiency. The presentation will emphasize the most widely used models and compare them along these two dimensions.
Restricting the Behavior of Timed Systems
Joseph Sifakis
VERIMAG
Grenoble, France
Restriction is a central notion in system development. It appears to be a key concept for definition of parallel composition and refinement relations. It can be defined as a unary operation on systems whose effect is the restriction of the enabling conditions of actions.  For untimed systems,  restrictions S' of a system S both simulate S and preserve its invariants. For timed systems different notions of restriction can be defined depending on the effect of restriction operations on time progress. In this  talk we,
‚Ä¢
Discuss different technical choices involved in the definition of restriction for timed systems.
‚Ä¢
Give results about a notion of restriction which preserves both invariants and time progress.
‚Ä¢
Illustrate applications of these results to the definition of property preserving operations such as flexible parallel composition.
‚Ä¢
Discuss technical choices concerning the definition of time in systems and advocate for time models where waiting conditions are not specified or modified independently of the system's ability to perform actions."
2002,Scheduler Modeling Based on the Controller Synthesis Paradigm.,"Abstract
The controller synthesis paradigm provides a general framework for scheduling real-time applications. Schedulers can be considered as controllers of the applications; they restrict their behavior so that given scheduling requirements are met. We study a modeling methodology based on the controller synthesis paradigm. The methodology allows to get a correctly scheduled system from timed models of its processes in an incremental manner, by application of composability results which simplify schedulability analysis. It consists in restricting successively the system to be scheduled by application of constraints defined from scheduling requirements. The latter are a conjunction of schedulability requirements that express timing properties of the processes and policy requirements about resource management. The presented methodology allows a unified view of scheduling theory and approaches based on timing analysis of models of real-time applications."
2002,Composition for Component-Based Modeling.,"Abstract
Component-based engineering is of paramount importance for rigorous system design methodologies. It is founded on a paradigm which is common to all engineering disciplines: complex systems can be obtained by assembling components (building blocks). Components are usually characterized by abstractions that ignore implementation details and describe properties relevant to their composition e.g. transfer functions, interfaces. Composition is used to build complex components from simpler ones. It can be formalized as an operation that takes in components and their integration constraints. From these, it provides the description of a new, more complex component."
2002,Scheduler Modeling Based on the Controller Synthesis Paradigm.,"Abstract
The controller synthesis paradigm provides a general framework for scheduling real-time applications. Schedulers can be considered as controllers of the applications; they restrict their behavior so that given scheduling requirements are met.
We study a modeling methodology based on the controller synthesis paradigm. The methodology allows to get a correctly scheduled system from timed models of its processes, in an incremental manner, by application of composability results which simplify schedulability analysis. It consists in restricting successively the system to be scheduled by application of constraints defined from scheduling requirements. The latter are a conjunction of schedulability requirements that express timing properties of the processes and policy requirements about resource management.
The presented methodology allows a unified view of analytic approaches and model-based approaches to scheduling."
2001,TAXYS: A Tool for the Development and Verification of Real-Time Embedded Systems.,"Abstract
The correct behavior of real-time applications depends not only on the correctness of the results of computations but also on the times at which these results are produced. As a matter of fact, violations of real-time constraints in embedded systems are the most difficult errors to detect, because they are extremely sensitive both to the patterns of external events stimulating the system and to the timing behavior of the system itself. Clearly, the development of real-time systems requires rigorous methods and tools to reduce development costs and ‚Äútime-to-market‚Äù while guaranteeing the quality of the produced code (in particular, respect of the temporal constraints)."
2001,Modeling Real-Time Systems-Challenges and Work Directions.,"Abstract
The evolution of information sciences and technologies is characterized by the extensive integration of embedded components in systems used in various application areas, from telecommunications to automotive, manufacturing, medical applications, e-commerce etc. In most cases, embedded components are real-time systems that continuously interact with other systems and the physical world. Integration and continuous interaction of software and hardware components makes the assurance of global quality a major issue in system design. The failure of a component may have catastrophic consequences on systems performance, security, safety, availability etc."
2000,An Algebraic Framework for Urgency.,"A sub-class of timed automata known as timed automata with deadlines was presented. Parallel composition and other operators were defined according to 'orthogonality' principal, for timed process algebras and hybrid automata. The compositional description methods that are based on 'flexible' composition rules that relax urgency constraints to preserve time reactivity was also studied. "
2000,Towards validated real-time software.,"Abstract:
We present a tool for the design and validation of embedded real time applications. The tool integrates two approaches: the use of the synchronous programming language, ESTEREL for design, and the application of model checking techniques for validation of real time properties. Validation is carried out on a global formal model (timed automata) taking into account the effective implementation of the application on the target hardware architecture as well as its external environment behavior."
2000,A Methodology for the Construction of Scheduled Systems.,"Abstract
We study a methodology for constructing scheduled systems by restricting successively the behavior of the processes to be scheduled. Restriction is used to guarantee the satisfaction of two types of constraints: schedulability constraints characterizing timing properties of the processes, and constraints characterizing particular scheduling algorithms including process priorities, non-idling, and preemption.
The methodology is based on a controller synthesis paradigm. The main results deal with the characterization of scheduling policies as safety constraints and the simplification of the synthesis process by applying a composability principle."
2000,On the Construction of Live Timed Systems.,"Abstract
We present a method that allows to guarantee liveness by construction of a class of timed systems. The method is based on the use of a set of structural properties which can be checked locally at low cost. We provide sufficient conditions for liveness preservation by parallel composition and priority choice operators. The latter allow to restrict a system‚Äôs behavior according to a given priority order on its actions.
We present several examples illustrating the use of the results, in particular for the construction of live controllers."
1999,Decidable Integration Graphs.,"Abstract
Integration graphsare a computational model developed in the attempt to identify simple hybrid systems with decidable analysis problems. We start with the class ofconstant slope hybrid systems(CSHS), in which the right-hand side of all differential equations is an integer constant. We refer to continuous variables whose right-hand side constants are always 1 astimers. All other continuous variables are calledintegrators. The first result shown in the paper is that simple questions such as reachability of a given state are undecidable for even this simple class of systems. To restrict the model even further, we impose the requirement that no test that refers to integrators may appear within a loop in the graph. This restricted class of CSHS is calledintegration graphs. The main results of the paper are that the reachability problem of integration graphs is decidable for two special cases: the case of a single timer and the case of a single test involving integrators. The expressive power of the integration-graphs formalism is demonstrated by showing that some typical problems studied within the context of the calculus of durations and timed statecharts can be formulated as reachability problems for restricted integration graphs, and a high fraction of these fall into the subclasses of a single timer or a single test involving integrators."
1999,The Compositional Specification of Timed Systems - A Tutorial.,"The analysis of reactive systems requires models representing the system, its interaction with the environment, and taking into account features of the underlying execution structure. It is important that such models are timed if analysis concerns performance, action scheduling or in general, dynamic aspects of the behavior. In practice, timed models of systems are obtained by adding timing constraints to untimed descriptions. For instance, given the functional description of a circuit, the corresponding timed model can be obtained by adding timing constraints about propagation delays of the components; to build a timed model of a real-time software, quantitative timing information concerning execution times of the statements and significant changes of the environment must be added. The construction of timed models of reactive systems raises some important questions concerning their composition and in particular, the way some well-understood constructs for untimed systems can be extended to timed systems. We present an overview of existing executable timed formalisms with a global notion of time, by putting emphasis on problems of compositional description. The results on compositionality have been developed in collaboration with Bornot at Verimag"
1999,"Integration, the Price of Success.","Abstract
It is generally recognized that formal techniques have a limited impact on current industrial practice. Several reasons often had been advocated to explain this fact: youth of the discipline, intrinsic limitations due to complexity and undecidability, lack of trained practitioners and engineers. All these are factors limiting the application of formal techniques. How ever, a reason that is less frequently suggested is the relevance of our contribution to current industrial practice. Clearly, Informatics is a scientificc discipline with its own evolution laws and proper objectives. How ever,as an experimental discipline it should find inspiration and validation in applications whose development is also driven by external needs, technologic, economic and ultimately social. The recognition and the success of our discipline is intimately related to the capability to address problems raised by the fast evolving practice."
1999,A Framework for Scheduler Synthesis.,"Abstract:
We present a framework integrating specification and scheduler generation for real time systems. In a first step, the system, which can include arbitrarily designed tasks (cyclic or sporadic, with or without precedence constraints, any number of resources and CPUs) is specified as a timed Petri net. In a second step, our tool generates the most general non preemptive online scheduler for the specification, using a controller synthesis technique."
1999,IF: An intermediate representation for SDL and its applications.,"We present work of a project for the improvement of a specification/validation toolbox integrating a commercial toolset ObjectGEODE and different validation tools such as the verification tool CADP and the test sequence generator TGV. The intrinsic complexity of most protocol specifications lead us to study combinations of techniques such as static analysis and abstraction together with classical model-checking techniques. Experimentation and validation of our results in this context motivated the development of an intermediate representation for SDL called IF. In IF, a system is represented as a set of timed automata communicating asynchronously through a set of buffers or by rendez-vous through a set of synchronization gates. The advantage of the use of such a program level intermediate representation is that it is easier to interface with various existing tools, such as static analysis, abstraction and compositional state space generation. Moreover, it allows to define for SDL different, but mathematically sound, notions of time"
1998,A General Framework for the Composition of Timed Systems Extended Abstract.,"It is recognized that there is no general methodology for writing correct timed specifications. Timed systems differ from untimed systems in that their runs are composed of alternating discrete transitions and time steps. When describing systems as the parallel composition of independent timed components, it is not in general easy to preserve this property, given that time progress must be synchronous in all components. We propose here a high level algebraic framework for the composition of timed systems."
1998,On the Composition of Hybrid Systems.,n/a
1997,On the Composition of Timed Systems.,"Abstract
It is generally admitted that timed models can be obtained as extensions of untimed (discrete) models by adding constructs that allow to manipulate time explicitly or implicitly. For instance, timed automata are automata extended with continuous variables, called clocks, that can be tested and modified at transitions. Timed process algebras are languages obtained by adding constructs such as delays, timeouts and watchdogs to untmed process algebras. Finally, the different classes of timed Petri nets can be obtained by adding interval time constraints to Petri nets.
In timed models, a run can be considered as composed of alternating steps: time steps where time progresses synchronously in all the sequential components and transitions, timeless discrete state changes. This implies in particular, that discrete and continuous steps are mutually exclusive. Model behavior is represented by the language of the time divergent runs."
1997,Modeling Urgency in Timed Systems.,"Abstract
Timed systems can be modeled as automata (or, generally, discrete transition structures) extended with real-valued variables (clocks) measuring the time elapsed since their initialization. The following features are also common in the above models.
States are associated with time progress conditions specifying how time can advance. Time can progress at a state by t only if all the intermediate states reached satisfy the associated time progress condition.
At transitions, clock values can be tested and modified. This is usually done by associating with transitions guards (conditions on clocks) and assignments. If a guard is true from an automaton state and a given clock valuation, the corresponding transition can be executed by modifying clocks as specified by the corresponding assignment."
1997,Relating Time Progress and Deadlines in Hybrid Systems.,"Abstract
Time progress conditions in hybrid systems are usually specified in terms of invariants, predicates characterizing states where time can continuously progress or dually, deadline conditions, predicates characterizing states where time progress immediately stops. The aim of this work is the study of relationships between general time progress conditions and these generated by using state predicates. It is shown that using deadline conditions or invariants allows to characterize all practically interesting time progress conditions. The study is performed by using a Galois connection between the corresponding lattices. We provide conditions for the connection to be a homomorphism and apply the results to the compositional description of hybrid systems."
1996,Research Directions for Concurrency.,n/a
1996,Research Directions for Formal Methods.,n/a
1996,Formal Methods for the Validation of Fault Tolerance in Autonomous Spacecraft.,"Abstract:
One of the major challenges to be faced in the design of new-generation spacecrafts comes with the requirement to increase the capacity of autonomous operation, in particular in presence of abnormal events. Formal methods are becoming more accepted in the space industry as a possible way to manage induced systems complexity. The Data Management System Design Validation (DDV) study has accomplished an experimental junction between the spacecraft autonomy trends and emerging formal methodologies. A methodological framework applicable to the early life cycle phases of fault-tolerant systems engineering has been defined. It focuses on the verification of fault tolerance properties using model-based formalisms. The Specification and Design Language (SDL) was selected for this study as the best suited language with respect to the application. This work has resulted in an executable specification establishing the tolerated behaviours of spacecraft computers in presence of faults. Fault tolerance properties have been checked, in spite of limitations inherent to model-based formalisms, by using an appropriate verification process."
1996,Compositional Specification of Timed Systems (Extended Abstract).,n/a
1995,Property Preserving Abstractions for the Verification of Concurrent Systems.,"Abstract
We study property preserving transformations for reactive systems. The main idea is the use of simulations parameterized by Galois connections (Œ±, Œ≥), relating the lattices of properties of two systems. We propose and study a notion of preservation of properties expressed by formulas of a logic, by a function Œ± mapping sets of states of a systemS into sets of states of a systemS'. We give results on the preservation of properties expressed in sublanguages of the branching time Œº-calculus when two systemsS andS' are related via (Œ±, Œ≥)-simulations. They can be used to verify a property for a system by verifying the same property on a simpler system which is an abstraction of it. We show also under which conditions abstraction of concurrent systems can be computed from the abstraction of their components. This allows a compositional application of the proposed verification method.
This is a revised version of the papers [2] and [16]; the results are fully developed in [28]."
1995,The Algorithmic Analysis of Hybrid Systems.,"Abstract
We present a general framework for the formal specification and algorithmic analysis of hybrid systems. A hybrid system consists of a discrete program with an analog environment. We model hybrid systems as finite automata equipped with variables that evolve continuously with time according to dynamical laws. For verification purposes, we restrict ourselves to linear hybrid systems, where all variables follow piecewise-linear trajectories. We provide decidability and undecidability results for classes of linear hybrid systems, and we show that standard program-analysis techniques can be adapted to linear hybrid systems. In particular, we consider symbolic model-checking and minimization procedures that are based on the reachability analysis of an infinite state space. The procedures iteratively compute state sets that are definable as unions of convex polyhedra in multidimensional real space. We also present approximation techniques for dealing with systems for which the iterative procedures do not converge."
1995,Specification and Verification of Timed Systems.,"We present a survey of recent results on the specification and verification of timed systems. Three different classes of formalisms are considered: Algebraic formalisms including operators that allow to express timing constraints like delays, timeouts, watchdogs. These formalisms can be considered as timed process algebras whose the most realistic representatives are the timed extensions of the Lotos language. Transition based formalisms which can be considered as extensions of automata or Petri nets with timing constraints. This class includes timed Petri nets and extensions of automata with continuous variables measuring the time elapsed such as timed automata and hybrid automata. Logical formalisms which are languages of the formulas of a logic with operators expressing timing constraints. Representatives of these formalisms are real-time temporal logics that are extensions of temporal logics with quantitative time and the Calculus of Durations. We show that as in the untimed case, all these formalisms admit a general common model: labeled transition systems with timed transitions. The existence of a common semantic framework allows a comparison of the classes. We focus on two particular problems: The translation of algebraic languages into transition based ones. This is a central problem for the compilation of algebraic timed languages into an executable model and it raises problems of compositionality, efficiency and optimality of the generated model. The verification by comparison of two transition-based descriptions or by comparison of a transition based description against a logical specification."
1995,Real-time systems specification and verification.,"We have developed a formal semantic model for real-time concurrency under limited parallelism. The model addresses memory access mechanisms, limited parallelism under asynchronous processors. In the framework of the model, various scheduling paradigms can be imposed. We formulated a language concept of tri-sections. The concept combines nondeterministic multiway synchronization of processes and processor holding into a single primitive construct. The use of the concept has been demonstrated with a process control system, resource allocation problems, and elevator systems. The concept allows the construction of maximally parallel regions in an otherwise limited parallel execution model. In a semantic sense, the achieves a reduction in the complexity of the limited parallelism models. We provided a formal design of a dialog system using the Z notation. Dialog systems are very much like operating system in the concepts they provide. The specification addresses the invariant properties which need to be satisfied by the various components of the system. In particular, the properties address object relationships in regard to their layout on the graphical interface, presentation of the visual aspects of the objects, activation and execution of programs attached to the objects, and concurrency supported by the system."
1995,On the Synthesis of Discrete Controllers for Timed Systems (An Extended Abstract).,"Abstract
This paper presents algorithms for the automatic synthesis of real-time controllers by finding a winning strategy for certain games defined by the timed-automata of Alur and Dill. In such games, the outcome depends on the players' actions as well as on their timing. We believe that these results will pave the way for the application of program synthesis techniques to the construction of real-time embedded systems from their specifications."
1994,Symbolic Model Checking for Real-Time Systems.,"Abstract
We describe finite-state programs over real-numbered time in a guarded-command language with real-valued clocks or, equivalently, as finite automata with real-valued clocks. Model checking answers the question which states of a real-time program satisfy a branching-time specification (given in an extension of CTL with clock variables). We develop an algorithm that computes this set of states symbolically as a fixpoint of a functional on state predicates, without constructing the state space. For this purpose, we introduce a Œº-calculus on computation trees over real-numbered time. Unfortunately, many standard program properties, such as response for all nonzeno execution sequences (during which time diverges), cannot be characterized by fixpoints: we show that the expressiveness of the timed Œº-calculus is incomparable to the expressiveness of timed CTL. Fortunately, this result does not impair the symbolic verification of ""implementable"" real-time programs-those whose safety constraints are machine-closed with respect to diverging time and whose fairness constraints are restricted to finite upper bounds on clock values. All timed CTL properties of such programs are shown to be computable as finitely approximable fixpoints in a simple decidable theory."
1994,"The Algebra of Timed Processes, ATP: Theory and Application.","Abstract
The algebra of timed processes, ATP, uses a notion of discrete global time and suggests a conceptual framework for introducing time by extending untimed languages. The action vocabularly of ATP contains a special element representing the progress of time. The algebra has, apart from standard operators of process algebras such as prefixing by an action, alternative choice, and parallel composition, a primitive unit-delay operator. For two arguments, processes P and Q, this operator gives a process which behaves as P before the execution of a time event and behaves as Q afterwards. It is shown that several d-unit delay constructs such as timeouts and watchdogs can be expressed in terms of the unit-delay operator and standard process algebra operators. A sound and complete axiomatization for bisimulation semantics is studied and two examples illustrating the adequacy of the language for the description of timed systems are given. Finally we provide a comparison with existing timed process algebras."
1994,Using Abstractions for the Verification of Linear Hybrid Systems.,n/a
1994,Model-Based Verification Methods and Tools (Abstract).,"Abstract
We describe established verification methods in the framework of communicating concurrent systems, focusing on model-based approaches implemented by existing tools for automatic verification."
1993,From ATP to Timed Graphs and Hybrid Systems.,"The paper presents results of ongoing work aiming at the unification of some behavioral description formalisms for timed systems. We propose for the algebra of timed processes ATP a very general semantics in terms of a time domain. It is then shown how ATP can be translated into a variant of timed graphs. This result allows the application of existing model-checking techniques to ATP. Finally, we propose a notion of hybrid systems as a generalization of timed graphs. Such systems can evolve, either by executing a discrete transition, or by performing some ìcontinuousî transformation. The formalisms studied admit the same class of models: time deterministic and time continuous, possibly infinitely branching transition systems labeled by actions or durations.
"
1993,On Model Checking for Real-Time Properties with Durations.,"Abstract:
The verification problem for real-time properties involving duration constraints (predicates) is addressed. The duration of a state property, along an interval of a computation sequence of a real-time system, is the time the property is true. In particular, the global time spent in such an interval is the duration of the formula 'true'. The real-time logic TCTL is extended to a duration logic called SDTL in which duration constraints can be expressed. The problem of the verification of SDTL formulas with respect to a class of timed models of reactive systems is investigated. New model checking procedures are proposed for the most significant properties expressible in SDTL, including eventuality and invariance properties. Such results are provided for the two cases of discrete and dense time.< >"
1992,Compiling Real-Time Specifications into Extended Automata.,"Abstract:
A method for the implementation and analysis of real-time systems, based on the compilation of specification extended automata is proposed. The method is illustrated for a simple specification language that can be viewed as the extension of a language for the description of systems of communicating processes, by adding timeout and watchdog constructs. The main result is that such a language can be compiled into timed automata, which are extended automata with timers. Timers are special state variables that can be set to zero by transitions, and whose values measure the time elapsed since their last reset. Timed automata do not make any assumption about the nature of time and adopt an event-driven execution mode. Their complexity does not depend on the values of the parameters of timeouts and watchdogs used in specifications. These features allow the application on timed automata of efficient code generation and analysis techniques. In particular, it is shown how symbolic model-checking of real-time properties can be directly applied to this model.< >"
1992,Property Preserving Simulations.,"Abstract
We study property preserving transformations for reactive systems. A key idea is the use of <œï, œà>-simulations which are simulations parameterized by a Galois connection (œï, œà), relating the lattices of properties of two systems.
We propose and study a notion of preservation of properties expressed by formulas of a logic, by a function œï mapping sets of states of a system S into sets of states of a system S'. Roughly speaking, œï preserves f if the satisfaction of f at some state of S implies that f is satisfied by any state in the image of this state by œï.
The main results concern the preservation of properties expressed in sublanguages of the branching time Œº-calculus when two systems S and S' are related via <œï,œà>-simulations. They can be used in particular to verify a property for a system by proving this property on a simpler system which is an abstraction of it."
1992,An Approach to the Description and Analysis of Hybrid Systems.,n/a
1992,Integration Graphs: A Class of Decidable Hybrid Systems.,"Abstract
Integration Graphs are a computational model developed in the attempt to identify simple Hybrid Systems with decidable analysis problems. We start with the class of constant slope hybrid systems (cshs), in which the right hand side of all differential equations is an integer constant. We refer to continuous variables whose right hand side constants are always 1 as timers. All other continuous variables are called integrators. The first result shown in the paper is that simple questions such as reachability of a given state are undecidable for even this simple class of systems.
To restrict the model even further, we impose the requirement that no test that refers to integrators may appear within a loop in the graph. This restricted class of cshs is called integration graphs. The main results of the paper are that the reachability problem of integration graphs is decidable for two special cases: The case of a single timer and the case of a single test involving integrators.
The expressive power of the integration graphs formalism is demonstrated by showing that some typical problems studied within the context of the Calculus of Durations and Timed Statecharts can be formulated as reachability problems for restricted integration graphs, and a high fraction of these fall into the subclasses of a single timer or a single dangerous test."
1992,A Toolbox for the Verification of LOTOS Programs.,"This paper presents the tools ALDEBARAN, CESAR, CESAR.ADT and CLEOPATRE which constitute a tool- box for compiling and verifying LOTOS programs. The principles of these tools are described, as well as their performances and limitations. Finally, the formal verification of the ret/REL atomic multicast protocol is given as an example to illustrate the practical use of the tool- box. "
1992,Symbolic Model Checking for Real-time Systems.,"Abstract:
Finite-state programs over real-numbered time in a guarded-command language with real-valued clocks are described. Model checking answers the question of which states of a real-time program satisfy a branching-time specification. An algorithm that computes this set of states symbolically as a fixpoint of a functional on state predicates, without constructing the state space, is given.< >"
1991,An Overview and Synthesis on Timed Process Algebras.,"Abstract
We present an overview and synthesis of existing results about process algebras for the specification and analysis of timed systems. The motivation is double: present an overview of some relevant and representative approaches and suggest a unifying framework for them.
After presenting fundamental assumptions about timed systems and the nature of abstract time, we propose a general model for them: transition systems whose labels are either elements of a vocabulary of actions or elements of a time domain. Many properties of this model are studied concerning their impact on description capabilities and on realisability issues.
An overview of the language features of the process algebras considered is presented, by focusing on constructs used to express time constraints. The presentation is organised as an exercise of building a timed process algebra from a standard process algebra for untimed systems. The overview is completed by a discussion about description capabilities according to semantic and pragmatic criteria."
1991,An Algebra of Boolean Processes.,"Abstract
This work has been motivated by the study of the S/R models which allow to represent systems as a set of communicating state machines cooperating through a shared memory.
We show that S/R models can be expressed in terms of a process algebra called Boolean SCCS which is a special case of Milner's SCCS, in the sense that the actions are elements of some boolean algebra. We define for Boolean SCCS an operational and a symbolic semantics modulo strong bisimulation equivalence. A complete axiomatisation of bisimulation and simulation equivalences on this algebra is proposed.
Furthermore, we propose a very general renaming operator, and show by means of examples that it allows the definition of abstractions."
1991,Safety for Branching Time Semantics.,"Abstract
We study in a first part of this paper safety and liveness properties for any given program semantics. We give a topological definition of these properties using a safety preorder. Then, we consider the case of branching time semantics where a program is modeled by a set of infinite computation trees modulo bisimulation. We propose and study a safety preorder for this semantics based on simulation and dealing with silent actions. We focus on regular safety properties and characterize them by both tree-automata and formulas of a branching time logic. We show that verifying safety properties on trees reduces to simulation testing."
1991,An Overview and Synthesis on Timed Process Algebras.,"Abstract
We present an overview and synthesis of existing results about process algebras for the specification and analysis of timed systems. The motivation is double: present an overview of some relevant and representative approaches and suggest a unifying framework for them.
After presenting fundamental assumptions about timed systems and the nature of abstract time, we propose a general model for them: transition systems whose labels are either elements of a vocabulary of actions or elements of a time domain. Many properties of this model are studied concerning their impact on description capabilities and on realisability issues.
An overview of the language features of the process algebras considered is presented, by focusing on constructs used to express time constraints. The presentation is organised as an exercise of building a timed process algebra from a standard process algebra for untimed systems. The overview is completed by a discussion about description capabilities according to semantic and pragmatic criteria."
1991,From ATP to Timed Graphs and Hybrid Systems.,"Abstract
The paper presents results of ongoing work aiming at the unification of some behavioural description formalisms for timed systems.
We propose for ATP a very general semantics in terms of a time domain.
It is then shown how ATP can be translated into a variant of timed graphs. This result allows the application of existing model-checking techniques to ATP.
Finally, we propose a notion of hybrid systems as a generalisation of timed graphs. Such systems can evolve, either by executing a discrete transition, or by performing some ‚Äúcontinuous‚Äù transformation.
The formalisms studied admit the same class of models: time deterministic and time continuous, possibly infinitely branching transition systems labelled by actions or durations."
1991,Verification for Finite Systems (Extended Abstract).,n/a
1990,ATP: an Algebra for Timed Processes.,n/a
1990,Compilation and verification of LOTOS specifications.,"The ISO specification language Lotos is a Formal Description Technique for concurrent systems. This paper presents the main features of the CÊsar system, intended for formal verification of Lotos specifications by model-checking. This tool compiles a subset of Lotos into extended Petri Nets, then into state graphs, which can be verified by using either temporal logics or automata equivalences. The design choices and the principles of functioning of CÊsar are described and compared to those of other Lotos tools. The paper also proposes ideas to deal with the state explosion problem arising in verification by model-checking. "
1988,A logig for the description of behaviours and properties of concurrent systems.,"Abstract
We present two logic LSP (Logic of Sequential Processes) and LP (Logic of Processes) which are propositional Œº-calculi with both logical operators and standard operators of process algebras such as prefixing, non-deterministic choice, parallel composition and restriction. The process algebra operators are extended on unions of bisimulation classes.
LSP is an extension of an algebra of sequential processes with strong bisimulation. A deductive system is proposed for this logic and a comparison with the propositional Œº-calculus of Kozen is carried out.
LP is an extension of an algebra of communicating processes with strong bisimulation. A deductive system is proposed for this logic and its use is illustrated by an example."
1987,Readiness Semantics for Regular Processes with Silent Actions.,n/a
1987,Verification in XESAR of the Sliding Window Protocol.,n/a
1987,An Expressive Logic for a Process Algebra with Silent Actions.,n/a
1986,A Logic for the Specification and Proof of Regular Controllable Processes of CCS.,"Summary
This work has been motivated by the following general problem: find logics for the specification and proof of programs, described by terms of some algebra with given congruence relation. This relation is supposed to define a satisfactory concept for the behavioural comparison of programs. We require these logics to be adequate with respect to the term language, in the sense that two programs, behaviourally equivalent satisfy the same formulas and conversely. The term language considered is the subset of controllable, regular terms of CCS, on a vocabulary of actions A, with observational congruence. A term is said to be controllable if it is congruent to some term without occurrence of œÑ. We obtain an adequate logic whose language of formulas is obtained from constants true, false and ¬¶Nil¬¶ by using operators ‚à®, ‚àß, fixpoint operators, + and a for a‚ààA; the latter can be considered as extensions of the operators + and a for a‚ààA of CCS. As a result, controllable CCS terms can be considered as formulas of this logic and the problem of program verification is reduced to the proof of the validity of a formula."
1986,A Modal Characterization of Observational Congruence on Finite Terms of CCS.,"We propose a translation method of finite terms of CCS into formulas of a modal language representing their class of observational congruence. For this purpose, we define a modal language and a function associating with any finite term of CCS a formula of the language, satisfied by the term. Furthermore, this function is such that two terms are congruent if and only if the corresponding formulas are equivalent. The translation method consists in associating with operations on terms (action, +) operations on the corresponding formulas. This work is a first step towards the definition of a modal language with modalities expressing both possibility and inevitability and which is compatible with observational congruence."
1986,A Logic for the Description of Non-deterministic Programs and Their Properties.,"We present a logic, called Synchronization Tree Logic (STL), for the specification and proof of programs described in a simple term language obtained from a constant Nil by using a set A of unary operators, a binary operator + and recursion. The elements of A represent names of actions, + represents non-deterministic choice, and Nil is the program preforming no action. The language of formulas of the logic proposed, contains the term language used for the description of programs, i.e., programs are formulas of the logic. This provides a uniform frame to deal with programs and their properties as the verification of anassertion t ‚ä® f (t is a program, f is a formula) is reduced to the proof of the validity of the formula t ‚äÉ f. We propose a sound and under some conditions complete deductive system for synchronization tree logics and discuss their relation with modal logics used for the specification of programs."
1985,From Synchronization Tree Logic to Acceptance Model Logic.,n/a
1984,A Modal Characterization of Observational Congruence on Finite Terms of CCS.,"Abstract
We propose, a translation method of finite terms of CCS into formulas of a modal language representing their class of observational congruence. For this purpose, we define a modal language and a function associating with any finite term of CCS a formula of the language, satisfied by the term. Furthermore, this function is such that two terms are congruent if and only if the corresponding formulas are equivalent. The translation method consists in associating with operations on terms (action,+) operations on the corresponding formulas.
This work is a first step towards the definition of a modal language with modalities expressing both possibility and inevitability and which is compatible with observational congruence."
1983,Fairness and Related Properties in Transition Systems - A Temporal Logic to Deal with Fairness.,"In this paper we propose a notion of fairness for transition systems and a logic for proving properties under the fairness assumption corresponding to this notion.

We start from an informal characterization of the unfairness as the situation where some event becomes possible infinitely often but has only a finite number of occurrences, which induces various definitions of fairness by considering different classes of events. It results from the comparison of these definitions that the concept of fairness which is useful is ìfair reachabilityî of a given set of states P in a system, i.e. reachability of states of P when considering only the computations such that if, during their execution, reaching states of P is possible infinitely often, then states of P are visited infinitely often.

This definition of fairness suggests the introduction of a branching time logic FCL, the temporal operators of which express, for a given set of states P, the modalities ìit is possible that Pî and ìit is inevitable that Pî by considering fair reachability of P. The main result is that, given a transition system S and a formula f of FCL expressing some property of S under the assumption of fairness, there exists a formula f? belonging to a branching time logic CL such that: f is valid for S in FCL iff f? is valid for S in CL. This result shows that proving a property under the assumption of fairness is equivalent to proving some other property without this assumption and that the study of FCL can be made via the ìunfairî logic CL, easier to study and for which several results already exist.

Finally, the proposed notion of fairness is compared to other related notions such as the absence of livelock, the absence of starvation and the finite delay property."
1983,An Example of Specification and Verification in Cesar.,n/a
1983,Property Preserving Homomorphisms of Transition Systems.,"Abstract
We study functions preserving properties of transition systems described by formulas of a logic.
Let L be a logic for which transition systems constitute a class of models. A formula F of L defines for a given transition system S and interpretation i, a property ; a state q of S satisfies the property represented by F iff
. Given two transition systems S1 and S2 with sets of states respectively Q1 and Q2 and a function f, f : 2Q1‚Üí2Q2, we say that f preserves the property represented by F iff
The results presented concern the characterization of functions f which preserve properties independently of the particular choice of S1 and S2 provided that the transition systems be related via homomorphisms of a certain type."
1982,Global and Local Invariants in Transition Systems.,"Given a transition system and a cover P of the set of its states, a set of local invariants with respect to P is defined as a set of predicates in bijection with the set of the blocks of P and in such a way that a local invariant be true every time the system is in a state belonging to the corresponding block of the cover. This definition is proved to be sufficiently general in the sense that any proof made by using global invariants can be also made by using sets of local invariants with respect to any cover P. The same result is proved for two more restrictive definitions of the notion of local invariant by using well-known properties of connections between lattices. Finally, it is shown that the notion of invariant assertion, commonly used for proving programs, can be deduced from the definition of local invariant when a transition system represents a program. In this case, the fixed point equations characterizing local invariants can be simplified to obtain semantical equations of programs."
1982,A Unified Approach for Studying the Properties of Transition Systems.,"Abstract
In this paper a systematic method for generating, comparing and proving the properties of transition systems is presented. It is assumed that any property of a system can be defined by giving a set of ‚Äòtarget‚Äô states and a type of reachability. Ten different types of reachability are proposed; by appropriately choosing the set of target states, a family of ten potentially different properties is generated. The main conclusion is that the reachability types and therefore the system properties, can be characterized by simple relations involving the set of the possible initial states and fixed points of certain continuous predicate trasformers depending on the set of target states. As a consequence, in order to prove a given property it is sufficient to compute iteratively greatest or least fixed points of continuous predicate transformers.
Some examples are presented which show how the results can be applied to prove the properties of concurrent systems represented by non-deterministic models."
1982,A Temporal Logic to Deal with Fairness in Transition Systems.,"Abstract:
In this paper, we propose a notion of fairness for transition systems and a logic for proving properties under the fairness assumption corresponding to this notion. We consider that the concept of fairness which is useful is ""fair reachability"" of a given set of states P in a system, i.e. reachability of states of P when considering only the computations such that if, during their execution, reaching states of P is possible infinitely often, then states of P are visited infinitely often. This definition of fairness suggests the introduction of a branching time logic FCL, the temporal operators of which express, for a given set of states P, the modalities ""it is possible that P"" and ""it is inevitable that P"" by considering fair reachability of P. The main result is that, given a transition system S and a formula f of FCL expressing some property of S under the assumption of fairness, there exists a formula f‚Ä≤ belonging to a branching time logic CL such that : f is valid for S in FCL iff f‚Ä≤ is valid for S in CL. This result shows that proving a property under the assumption of fairness is equivalent to proving some other property without this assumption and that the study of FCL can be made via the ""unfair"" logic CL, easier to study and for which several results already exist."
1982,Global and Local Invariants in Transition Systems.,"Abstract
Given a transition system and a cover P of the set of its states, a set of local invariants with respect to P is defined as a set of predicates in bijection with the blocks of P and in such a way that a local invariant be true every time the system is in a state belonging to the corresponding block of the cover.
This definition is proved to be sufficiently general in the sense that any proof made by using global invariants can be also made by using sets of local invariants. The same result is proved for two more restrictive definitions of the notion of local invariant by using well-known properties of connections between lattices.
Finally, it is shown how the theory of connections can provide a general frame for tackling the problem of decomposing a global assertion into a logically equivalent set of local assertions."
1982,Comments on Schiffers.,"Abstract
Interaction Systems (IS) are a tool for the specification of concurrent systems. They allow a progressive construction of solutions by introducing mutual exclusion constraints and excitation relations. This tool seems to be interesting because it uses very few primitive notions and provides fair analysis facilities. However, the following critiques can be formulated as far as its adequacy for solving problem study 1 (PSl) is concerned."
1982,Specification and verification of concurrent systems in CESAR.,"Abstract
The aim of this paper is to illustrate by an example, the alternating bit protocol, the use of CESAR, an interactive system for aiding the design of distributed applications.
CESAR allows the progressive validation of the algorithmic description of a system of communicating sequential processes with respect to a given set of specifications. The algorithmic description is done in a high level language inspired from CSP and specifications are a set of formulas of a branching time logic, the temporal operators of which can be computed iteratively as fixed points of monotonic predicate transformers. The verification of a system consists in obtaining by automatic translation of its description program an Interpreted Petri Net representing it and evaluating each formula of the specifications."
1981,Iterative Methods for the Analysis of Petri Nets.,"Abstract
The aim of this paper is to show how the iterative methods for the analysis of discrete systems presented in [1][2][3] can be applied to Petri nets and their extensions. The results given in this paper have been obtained by direct application of those exposed in the references."
1980,Deadlocks and Livelocks in Transition Systems.,n/a
1979,Use of Petri nets for performance evaluation.,n/a
1979,Performance Evaluation of Systems Using Nets.,"Abstract
This paper presents a method for computing firing frequencies corresponding to steady state functionings of Timed Place-Transition Nets (TPIN). Two different models of TPIN's ‚Äî the one with delays associated to its places and the other with delays associated to its transitions ‚Äî are compared and proved to be equivalent. Given a TPIN it is provided a set of relations established between its initial marking, the firing frequences of its transitions and the delays associated to its places. Furthermore, for given initial marking and delays it is shown that maximal firing frequencies can be computed as solutions of a set of n linear equations, where n is the number of places of the TPIN. The presented results are illustrated by two applications."
1979,Survey of French Research and Applications Based on Petri Nets.,n/a
1978,Synchronized Petri Nets: A Model for the Description of Non-Autonomous Systems.,"Abstract
We introduce and study the functioning of non-autonomous Petri Nets (PN). The Synchronized Petri Nets (SPN) are defined as being PN's such that transition finings are synchronized on the occurrences of external events. We show that the nesults concerning the verification of characteristic properties (eive, bounded, persistent) by autonomous PN's are only partially valid for this mode of functioning. The model of Labeled SPN is proposed and studied as a tool for the description and analysis of non-autonomous systems."
1978,Structural Properties of Petri Nets.,"Abstract
Several necessary conditions for structural liveness and a necessary and sufficient condition for structural boundedness are given. These conditions can be verified by using techniques of linear algebra and could be used for proving liveness and boundedness depending on a given marking. Structural boundedness and liveness are related to the existence of deadlocks traps absorbers and generators of a special type in a PN. A necessary condition for a PN to be structurally bounded and live is that it be both invariant and consistent. Thus invariance and consistency, which imply also the strong connexity of the graphic representation, are necessary conditions for evitating pathological situations such as structural unboundedness and structural unliveness."
1977,Use of Petri Nets for Performance Evaluation.,n/a
1976,A Design Tool for the Multilevel Description and Simulation of Systems of Interconnected Modules.,"We suggest a methodology and a language to permit the study of a system's behavior (functional validation, evaluation of global performances, critical situations). Every system is regarded as an interconnection of communicating modules functioning in a synchronous or asynchronous manner. The control section and the data section of each module are described separately in terms of respectively non-procedural and procedural sub-languages."
