2014,Author retrospective for PTRAN's analysis and optimization techniques.,"The PTRAN (Parallel Translator) system at IBM had as its goal the analysis and optimization of sequential programs for parallel architectures. In this paper, we give our perspective on what has changed since PTRAN, and what is still relevant."
2012,Programming Languages - Past Achievements and Future Challenges.,"The design of programming languages and their compile-time and run-time implementation are closely related, and are dependent on the underlying computational model. In the 1960s, 70s, and 80s many languages were designed, and many implementation strategies and computational models were explored. Since then, the commercial world has largely settled on a few legacy languages. Meanwhile, both the capabilities of computing systems and the ways in which they are used have changed dramatically. The panelists will summarize the lessons they have learned about language design, and also what has not been learned. They will consider how those lessons can be applied to the myriad application domains, architectural frameworks, user needs, and economic considerations that exist today, and will speculate about the future."
2008,Compilers and parallel computing systems.,"Abstract:
Increasing the delivered performance of computers by running programs in parallel is an old idea with a new urgency. Multi cores (multi processors) on chips have emerged as a way to increase performance wherever chips are used. The talk will focus on the role programming languages and compilers must play in delivering parallel performance to users and applications. The speakerpsilas personal experiences with languages and compilers for high performance systems will provide the basis for her observations. The talk is intended to encourage the exploration of new approaches."
2008,Compilers and parallel computing systems.,Increasing the delivered performance of computers by running programs in parallel is an old idea with a new urgency. Multi cores (multi processors) on chips have emerged as a way to increase performance wherever chips are used. The talk will focus on the role programming languages and compilers must play in delivering parallel performance to users and applications. The speaker's personal experiences with languages and compilers for high performance systems will provide the basis for her observations. The talk is intended to encourage the exploration of new approaches.
2001,Blue Gene: A vision for protein science using a petaflop supercomputer.,"Abstract:
In December 1999, IBM announced the start of a five-year effort to build a massively parallel computer, to be applied to the study of biomolecular phenomena such as protein folding. The project has two main goals: to advance our understanding of the mechanisms behind protein folding via large-scale simulation, and to explore novel ideas in massively parallel machine architecture and software. This project should enable biomolecular simulations that are orders of magnitude larger than current technology permits. Major areas of investigation include: how to most effectively utilize this novel platform to meet our scientific goals, how to make such massively parallel machines more usable, and how to achieve performance targets, with reasonable cost, through novel machine architectures. This paper provides an overview of the Blue Gene project at IBM Research. It includes some of the plans that have been made, the intended goals, and the anticipated challenges regarding the scientific work, the software applic ation, and the hardware design."
2000,"Not Now, Not Like This.",n/a
1999,Turning Points in Interaction with Computers.,"Abstract:
The development of interfaces by which humans and computers interact has brought about some of the most significant turning points in computing in the last 38 years. The work on interfaces in programming languages, office automation, and human factors has enabled more and more people to interact effectively with computers, but there is more work to do. The IBM Systems Journal has published many papers that reflect results of work in this area, and readers can see a representative selection of those papers in this section of this issue."
1988,An Overview of the PTRAN Analysis System for Multiprocessing.,"PTRAN (Parallel TRANslator) is a system for automatically restructuring sequential FORTRAN programs for execution on parallel architectures. This paper describes PTRAN-A: the currently operational analysis phase of PTRAN. The analysis is both broad and deep, incorporating interprocedural information into dependence analysis. The system is organized around a persistent database of program and procedure information. PTRAN incorporates several new, fast algorithms in a pragmatic design.
"
1988,A framework for determining useful parallelism.,"An approach to finding and forming parallel processes for both sequential and parallel programs is presented. The approach is presented in a framework that can create useful parallelism for a variety of parallel architectures. The framework makes use of a control dependence graph to capture maximal parallelism, a process tree to expose useful parallelism, renaming and storage segregation to reduce data dependencies, and an architecture-specific cost analyzer to evaluate the effectiveness of the potential processes. The framework is currently being implemented."
1987,An Overview of the PTRAN Analysis System for Multiprocessing.,"Abstract
PTRAN (Parallel TRANslator) is a system for automatically restructuring sequential FORTRAN programs for execution on parallel architectures. This paper describes PTRAN-A: the currently operational analysis phase of PTRAN. The analysis is both broad and deep, incorporating interprocedural information into dependence analysis. The system is organized around a persistent database of program and procedure information. PTRAN incorporates several new, fast algorithms in a pragmatic design."
1982,A technological review of the FORTRAN I compiler.,The FORTRAN I compiler functions and organizations are described and shown to form the basis for many of the techniques used in modern compilers.
1981,The History of Language Processor Technology in IBM.,"Abstract:
The history of language processor technology in IBM is described in this paper. Most of the paper is devoted to compiler technology; interpreters, assemblers, and macro systems are discussed briefly. The emphasis is on scientific contributions and technological advances from a historical perspective. The synergistic relationship between theory and practice is a subtheme."
1980,The Experimental Compiling System.,"Abstract:
The Experimental Compiling System (ECS) described here represents a new compiler construction methodology that uses a compiler base which can be augmented to create a compiler for any one of a wide class of source languages. The resulting compiler permits the user to select code quality ranging from highly optimized to interpretive. The investigation is concentrating on easy expression and efficient implementation of language semantics; syntax analysis is ignored."
1979,Automatic storage optimization (with retrospective).,n/a
1976,A Program Data Flow Analysis Procedure.,The global data relationships in a program can be exposed and codified by the static analysis methods described in this paper. A procedure is given which determines all the definitions which can possibly “reach” each node of the control flow graph of the program and all the definitions that are “live” on each edge of the graph. The procedure uses an “interval” ordered edge listing data structure and handles reducible and irreducible graphs indistinguishably.
1974,Interprocedural Analysis and the Information derived by it.,"Abstract
Well structured programs are usually expressed as a system of functionally oriented procedures. By analyzing and transforming an entire system of procedures, linkages can be modified or eliminated and interprocedural data dependencies documented to the user. This paper presents some of the methods being developed to effect such interprocedural analysis and transformations."
1974,Interprocedural Data Flow Analysis.,n/a
1971,A Basis for Program Optimization.,n/a
