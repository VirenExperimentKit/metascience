2013,The society of intelligent veillance.,"Abstract:
The Society of Mind is the theory, emerging in the 1970s, that natural intelligence arises from the interactions of numerous simple agents, each of which, taken individually, is ‚Äúmindless‚Äù, but, collectively, give rise to intelligence: ‚ÄúWhat magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle.‚Äù [Minsky 1988]."
2012,Human and Machine Intelligence.,"In his 1950 Mind paper, Alan Turing reframed the question of whether machines could think as an operational or behavioral question: Could a computer be built that was indistinguishable from people in playing the ""imitation game,"" now known as ""the Turing Test""? He conjectured that by the end of the 20th century ""one [would] be able to speak of machines thinking without expecting to be contradicted"" and that computers would succeed in the Turing Test.
Turing's first conjecture proved right. Although his second has not yet been realized, research in Artifi cial Intelligence (AI) has generated a variety of algorithms and techniques regularly deployed in systems enabling them to behave in ways that are broadly considered to be intelligent. The performances of Watson, Siri, and driverless cars are but a few examples in the public eye. This session's panelists will highlight some of the major accomplishments of research in AI and its infl uential role in the development of computer science and computer systems more broadly, considering not only progress in individual subfi elds, but also designs for integrating these into well-functioning systems. They will also consider the ways in which AI theories and methods have infl uenced research on human cognition in behavioral sciences and neuroscience as well as scientifi c research more generally, and they will discuss major challenges and opportunities for the decades ahead."
2010,Intimacy versus privacy.,"When you talk to a person, it's safe to assume that you both share large bodies of ""common sense knowledge."" But when you converse with a programmed computer, neither of you is likely to know much about what the other one knows.
Indeed, in some respects this is desirable - as when we're concerned with our privacy. We don't want strangers to know our most personal goals, or all the resources that we may control.
However, when we turn to our computers for help, we'll want that relationship to change - because now it is in our interest for those systems to understand our aims and goals, as well as our fears and phobias. Indeed, the extents to which those processes ""know us as individuals"".
Issues like these will always arise whenever we need a new interface - and as one of my teachers wrote long ago, ""The hope is that, in not too many years, human brains and computing machines will be coupled together very tightly, and that the resulting partnership will think as no human brain has ever thought and process data in a way not approached by the information-handling machines we know today.""1
Indeed, the '60s and '70s saw substantial advancestowars this but it seems to me that then progress slowed down. If so, perhaps this was partly because the AI community moved from semantic and heuristic methods towards more formal (but less flexible) statistical schemes. So nowI'd like to see more researchers remedy this by developing systems that use more commonsense knowledge."
2006,"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955.","Abstract
The 1956 Dartmouth summer research project on artificial intelligence was initiated by this August 31, 1955 proposal, authored by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon. The original typescript consisted of 17 pages plus a title page. Copies of the typescript are housed in the archives at Dartmouth College and Stanford University. The first 5 papers state the proposal, and the remaining pages give qualifications and interests of the four who proposed the study. In the interest of brevity, this article reproduces only the proposal itself, along with the short autobiographical statements of the proposers."
2006,1956-1966 How Did It All Begin? - Issues Then and Now.,"Abstract
Many computer programs today show skills that appear to rival those of outstanding human consultants. However, while each such program does certain things well, it is helpless at doing anything else. Why do our present-day programs lack the versatility and resourcefulness that a typical person shows? Clearly, those programs are deficient in both commonsense knowledge and commonsense reasoning. I‚Äôll argue that this has happened because the field of AI has evolved in a backwards direction, as compared with how a typical person develops-and that this is because our AI programmers have not appreciated the importance of making their system able to use more ‚Äôreflective‚Äô ways to think."
2004,The St. Thomas Common Sense Symposium: Designing Architectures for Human-Level Intelligence.,"Abstract
To build a machine that has ""common sense"" was once a principal goal in the field of artificial intelligence. But most researchers in recent years have retreated from that ambitious aim. Instead, each developed some special technique that could deal with some class of problem well, but does poorly at almost everything else. We are convinced, however, that no one such method will ever turn out to be ""best,"" and that instead, the powerful AI systems of the future will use a diverse array of resources that, together, will deal with a great range of problems. To build a machine that's resourceful enough to have humanlike common sense, we must develop ways to combine the advantages of multiple methods to represent knowledge, multiple ways to make inferences, and multiple ways to learn. We held a two-day symposium in St. Thomas, U.S. Virgin Islands, to discuss such a project -- - to develop new architectural schemes that can bridge between different strategies and representations. This article reports on the events and ideas developed at this meeting and subsequent thoughts by the authors on how to make progress."
2002,An architecture of diversity for commonsense reasoning.,"Although computers excel at certain bounded tasks that are difficult for humans, such as solving integrals, they have difficulty performing commonsense tasks that are easy for humans, such as understanding stories. In this Technical Forum contribution, we discuss commonsense reasoning and what makes it difficult for computers. We contend that commonsense reasoning is too hard a problem to solve using any single artificial intelligence technique. We propose a multilevel architecture consisting of diverse reasoning and representation techniques that collaborate and reflect in order to allow the best techniques to be used for the many situations that arise in commonsense reasoning. We present story understandingóspecifically, understanding and answering questions about progressively harder childrenís textsóas a task for evaluating and scaling up a commonsense reasoning system."
2000,Deep issues: commonsense-based interfaces.,n/a
1993,"The future merging of science, art and psychology.",n/a
1993,"Allen Newell, Unified Theories of Cognition.",n/a
1991,Logical Versus Analogical or Symbolic Versus Connectionist or Neat Versus Scruffy.,"Abstract
Engineering and scientific education condition us to expect everything, including intelligence, to have a simple, compact explanation. Accordingly, when people new to AI ask ""What's AI all about,"" they seem to expect an answer that defines AI in terms of a few basic mathematical laws. Today, some researchers who seek a simple, compact explanation hope that systems modeled on neural nets or some other connectionist idea will quickly overtake more traditional systems based on symbol manipulation. Others believe that symbol manipulation, with a history that goes back millennia, remains the only viable approach. Marvin Minsky subscribes to neither of these extremist views. Instead, he argues that AI must use many approaches. AI is not like circuit theory and electromagnetism. There is nothing wonderfully unifying like Kirchhoff's laws are to circuit theory or Maxwell's equations are to electromagnetism. Instead of looking for a ""right way,"" the time has come to build systems out of diverse components, some connectionist and some symbolic, each with its own diverse justification."" - Patrick Winston"
1991,Multiple Approaches to Multiple Agent Problem Solving.,n/a
1989,Virtual environments and interactivity: windows to the future.,"I really apologize. I promised everyone I would come out wearing the data suit, but it just slipped my mind and I never got around to it. Actually Marvin Minsky was saying that the thing to do would be to come out with nothing on because that would be the perfect interface to the computer. So I kind of shunned the whole thing off at that point.We just heard Nicholas Negroponte ask us -- ""how do we communicate with computers?"" Well, that's why this panel is here today. We'll be discussing virtual environments and interactivity with some of the people who have been doing a lot of work in this field. I was interviewing a lot of people last night at the parties about virtual environments and I realized that everyone has their own idea of what their virtual environment will be. Some want to interact more, others less. Some want little people running around on the screen bringing them all sorts of messages or images. We'll be hearing about a lot of different types of interactivity on our panel today.I'd like to point out that Margaret's slide should also include the MIT Media Lab as well as UNC.I'm going to show some tapes and do some talking later on so I'd like start of by introducing Jaron Lanier. He's the guy with the dreadlocks you've seen at the Silicon Graphics booth. He has an amazing collection of musical instruments from all over the world and when he plays them, he transports you to other times and other places. He's a designer of programming languages and he started VPL, the company that brought you the glove, Jaron."
1983,Introduction to the COMTEX Microfiche Edition of the Early MIT Artificial Intelligence Memos.,"Abstract
These are the voyages of the MIT Artificial Intelligence Laboratory, and these remarks may help to understand the context of this collection, though in many ways the memoranda speak quite clearly for themselves and my comments are not, in any case, to be regarded as history, for I have written them quite hastily, in much the same spirit of the memos themselves, when it was our strategy in those early days to be unscholarly: we tended to assume, for better or for worse, that everything we did was so likely to be new that there was little need for caution or for reviewing literature or for double -checking anything. As luck would have it, that almost always turned out true."
1982,Why People Think Computers Can't.,"Abstract
Today, surrounded by so many automatic machines industrial robots, and the R2-D2's of Star wars movies, most people think AI is much more advanced than it is. But still, many ""computer experts"" don‚Äôt believe that machines will ever ""really think."" I think those specialists are too used to explaining that there's nothing inside computers but little electric currents. This leads them to believe that there can‚Äôt be room left for anything else- like minds, or selves. And there are many other reasons why so many experts still maintain that machines can never be creative, intuitive, or emotional, and will never really think, believe, or understand anything. This essay explains why they are wrong."
1980,K-Lines: A theory of Memory.,"Most theories of memory suggest that when we learn or memorize something, some drepresentation of that something is constructed, stored and later retrieved. This raises questions like: How is information represented?

How is it stored?

How is it retrieved?

Then, how is it used?

This paper tries to deal with all these at once. When you get an idea and want to ìrememberî it, you create a ìK?lineî for it. When later activated, the K?line induces a partial mental state resembling the one that created it. A ìpartial mental stateî is a subset of those mental agencies operating at one moment. This view leads to many ideas about the development, structure and physiology of memory, and about how to implement framelike representations in a distributed processor.
"
1977,History of Artificial Intelligence.,n/a
1977,Plain Talk about Neurodevelopmental Epistemology.,n/a
1966,Unrecognizable Sets of Numbers.,"When is a set A of positive integers, represented as binary numbers, ‚Äúregular‚Äù in the sense that it is a set of sequences that can be recognized by a finite-state machine? Let &pgr; A(n) be the number of members of A less than the integer n. It is shown that the asymptotic behavior of &pgr; A(n) is subject to severe restraints if A is regular. These constraints are violated by many important natural numerical sets whose distribution functions can be calculated, at least asymptotically. These include the set P of prime numbers for which &pgr; P(n) @@@@ n/log n for large n, the set of integers A(k) of the form nk for which &pgr; A(k)n) @@@@ nP/k, and many others. The technique cannot, however, yield a decision procedure for regularity since for every infinite regular set A there is a nonregular set A‚Ä≤ for which | &pgr; A(n) ‚Äî &pgr; A‚Ä≤(n) | ‚â§ 1, so that the asymptotic behaviors of the two distribution functions are essentially identical."
1964,Universality of Tag Systems with P=2.,"By a simple direct construction it is shown that computations done by Turing machines can be duplicated by a very simple symbol manipulation process. The process is described by a simple form of Post canonical system with some very strong restrictions. This system is monogenic: each formula (string of symbols) of the system can be affected by one and only one production (rule of inference) to yield a unique result. Accordingly, if we begin with a single axiom (initial string) the system generates a simply ordered sequence of formulas, and this operation of a monogenic system brings to mind the idea of a machine. The Post canonical system is further restricted to the ‚ÄúTag‚Äù variety, described briefly below. It was shown in [1] that Tag systems are equivalent to Turing machines. The proof in [1] is very complicated and uses lemmas concerned with a variety of two-tape nonwriting Turing machines. The proof here avoids these otherwise interesting machines and strengthens the main result; obtaining the theorem with a best possible deletion number P = 2. Also, the representation of the Turing machine in the present system has a lower degree of exponentiation, which may be of significance in applications. These systems seem to be of value in establishing unsolvability of combinatorial problems."
1962,Symposium on Artificial Intelligence.,n/a
