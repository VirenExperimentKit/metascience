2018,A Survey of Presence and Related Concepts.,"The presence construct, most commonly defined as the sense of ìbeing there,î has driven research and development of virtual environments (VEs) for decades. Despite that, there is not widespread agreement on how to define or operationalize this construct. The literature contains many different definitions of presence and many proposed measures for it. This article reviews many of the definitions, measures, and models of presence from the literature. We also review several related constructs, including social presence, copresence, immersion, agency, transportation, reality judgment, and embodiment. In addition, we present a meta-analysis of existing presence models and propose a model of presence informed by Slaterís Place Illusion and Plausibility Illusion constructs.
"
2018,[email protected]: celebrating ivan sutherland's 1968 head-mounted 3D display system.,n/a
2018,Immersion and coherence in a stressful virtual environment.,"ABSTRACT
We report on the design and results of two experiments investigating Slater's Place Illusion (PI) and Plausibility Illusion (Psi) in a virtual visual cliff environment. PI (the illusion of being in a place) and Psi (the illusion that the depicted events are actually happening) were proposed by Slater as orthogonal components of virtual experience which contribute to realistic response in a VE. To that end, we identified characteristics of a virtual reality experience that we expected to influence one or the other of PI and Psi. We designed two experiments in which each participant experienced a given VE in one of four conditions chosen from a 2√ó2 design: high or low levels of PI-eliciting characteristics (that is, immersion) and high or low levels of Psi-eliciting characteristics. Following Skarbez, we use the term ""coherence"" for those characteristics which contribute to Psi, parallel to the use of ""immersion"" for characteristics that contribute to PI. We collected both questionnaire-based and physiological metrics. Several existing presence questionnaires could not reliably distinguish the effects of PI from those of Psi. They did, however, indicate that high levels of PI-eliciting characteristics and Psi-eliciting characteristics together result in higher presence, compared any of the other three conditions. This suggests that ""breaks in PI"" and ""breaks in Psi"" belong to a broader category of ""breaks in experience,"" any of which result in a degraded user experience. Participants' heart rates, however, responded markedly differently in the two Psi conditions; no such difference was observed across the PI conditions. This indicates that a VE that exhibits unusual or confusing behavior can cause stress in a user that affects physiological responses, and that one must take care to eliminate such confusing behaviors if one is using physiological measurement as a proxy for subjective experience in a VE."
2017,A Psychophysical Experiment Regarding Components of the Plausibility Illusion.,"Abstract:
We report on the design and results of an experiment investigating factors influencing Slater's Plausibility Illusion (Psi) in virtual environments (VEs). Slater proposed Psi and Place Illusion (PI) as orthogonal components of virtual experience which contribute to realistic response in a VE. PI corresponds to the traditional conception of presence as ‚Äúbeing there,‚Äù so there exists a substantial body of previous research relating to PI, but very little relating to Psi. We developed this experiment to investigate the components of plausibility illusion using subjective matching techniques similar to those used in color science. Twenty-one participants each experienced a scenario with the highest level of coherence (the extent to which a scenario matches user expectations and is internally consistent), then in eight different trials chose transitions from lower-coherence to higher-coherence scenarios with the goal of matching the level of Psi they felt in the highest-coherence scenario. At each transition, participants could change one of the following coherence characteristics: the behavior of the other virtual humans in the environment, the behavior of their own body, the physical behavior of objects, or the appearance of the environment. Participants tended to choose improvements to the virtual body before any other improvements. This indicates that having an accurate and well-behaved representation of oneself in the virtual environment is the most important contributing factor to Psi. This study is the first to our knowledge to focus specifically on coherence factors in virtual environments."
2017,Coherence changes gaze behavior in virtual human interactions.,"Abstract:
We discuss the design and results of an experiment investigating Plausibility Illusion in virtual human (VH) interactions, in particular, the coherence of conversation with a VH. This experiment was performed in combination with another experiment evaluating two display technologies. As that aspect of the study is not relevant to this poster, it will be mentioned only in the Materials section. Participants who interacted with a low-coherence VH looked around the room markedly more than participants interacting with a high-coherence VH, demonstrating that the level of coherence of VHs can have a detectable effect on user behavior and that head and gaze behavior can be used to evaluate the quality of a VH interaction."
2017,Immersion and coherence in a visual cliff environment.,"Abstract:
We report on the design and results of an experiment investigating Slater's Place Illusion (PI) and Plausibility Illusion (Psi) in a virtual visual cliff environment. Existing presence questionnaires could not reliably distinguish the effects of PI from those of Psi. They did, however, indicate that high levels of PI-eliciting characteristics and Psi-eliciting characteristics together result in higher presence, compared to any of the other three conditions. Also, participants' heart rates responded markedly differently in the two Psi conditions; no such difference was observed across the PI conditions."
2013,Redirected Touching: Training and adaptation in warped virtual spaces.,"Redirected Touching is a technique in which virtual space is warped to map many virtual objects onto one real object that serves as a passive haptic prop. Recent work suggests that this mapping can often be predictably unnoticeable and have little effect on task performance. We investigated training and adaptation on a rapid aiming task in a real environment, an unwarped virtual environment, and a warped virtual environment. Participants who experienced a warped virtual space reported an initial strange sensation, but adapted to the warped space after short repeated exposure. Our data indicate that all the virtual training was less effective than real-world training, but after adaptation, participants trained as well in a warped virtual space as in an unwarped one."
2013,Filling the gaps: Hybrid vision and inertial tracking.,"Existing head-tracking systems all suffer from various limitations, such as latency, cost, accuracy, or drift. I propose to address these limitations by using depth cameras and existing 3D reconstruction algorithms to simultaneously localize the camera position and build a map of the environment, providing stable and drift-free tracking. This method is enabled by the recent proliferation of light-weight, inexpensive depth cameras. Because these cameras have a relatively slow frame rate, I combine this technique with a low-latency inertial measurement unit to estimate movement between frames. Using the generated environment model, I further propose a collision avoidance system for use with real walking."
2012,Scene-motion thresholds during head yaw for immersive virtual environments.,"In order to better understand how scene motion is perceived in immersive virtual environments, we measured scene-motion thresholds under different conditions across three experiments. Thresholds were measured during quasi-sinusoidal head yaw, single left-to-right or right-to-left head yaw, different phases of head yaw, slow to fast head yaw, scene motion relative to head yaw, and two scene-illumination levels. We found that across various conditions (1) thresholds are greater when the scene moves with head yaw (corresponding to gain <1.0) than when the scene moves against head yaw (corresponding to gain >1.0), and (2) thresholds increase as head motion increases.
"
2012,Redirected touching: The effect of warping space on task performance.,"Passive haptic feedback in virtual environments is compelling, but changes to virtual objects require changes to associated real objects. Recent work suggests that by leveraging visual dominance, virtual space can be warped to map a variety of virtual objects onto a single real object. However, it is unknown whether users can interact with a warped virtual space as effectively as with an unwarped one. We present a study in which we measured task performance using the Fitts'-law-based ISO 9241-9 multidirectional tapping task. With a few caveats, results suggest that for certain tasks, warped virtual objects are no worse than unwarped virtual objects. We also present preliminary exploratory data on how well people can detect discrepancies due to space-warping."
2012,Computer Architecture.,"ABSTRACT
Sixty-five years ago, Alan Turing produced a proposal for the construction of a general-purpose computer, the Automatic Computing Engine, or ACE. Subsequently built at the U.K. National Physical Laboratory, it was briefly the fastest computer in the world. Although its architecture was quite different from the arrangement proposed by Von Neumann and others that eventually came to dominate the computing landscape, examining it gives us a chance to understand some of the tradeoffs that early computer architects explored.
The panel will examine the ACE to provide a setting for the discussions that follow, in which they will explore some of the architectural tradeoffs that have been made in the past, are still being made today, and which will shape the direction of computing in the future. What would Alan Turing have thought about the impact that computers have had on society? What would he have thought about the warehouse-scale computing that makes possible a realization of Vannevar Bush's 1945 Memex vision? What about the possibility of quantum computing? The panelists will discuss these topics as well as the progress and future of academic computer architecture research."
2012,The teacher's job is to design learning experiences; not primarily to impart information.,"ABSTRACT
The primary job of the teacher is to make learning happen; that is a design task. Most of us learned most of what we know by what we did, not by what we heard or read. A corollary is that the careful designing of exercises, assignments, projects, even quizzes, makes more difference than the construction of lectures. A second corollary is that project courses that go deeply into narrow aspects of a subject seem to stick longer and deeper than approaches aiming at comprehensive coverage. How to strike a balance? I've taught a first software engineering laboratory course 22 times, and an advanced computer architecture course about ten times. Here are some techniques that work for me."
2012,Reliable forward walking parameters from head-track data alone.,Head motion during real walking is complex: The basic translational path is obscured by head bobbing. Many VE applications would be improved if a bobbing-free path were available. This paper introduces a model that describes head position while walking in terms of a bobbing free path and the head bobs. We introduce two methods to approximate the model from head-track data.
2011,An initial exploration of conversational errors as a novel method for evaluating virtual human experiences.,"We present a new method for evaluating user experience in interactions with virtual humans (VHs). We code the conversational errors made by the VH. These errors, in addition to the duration of the interaction and the numbers of statements made by the participant and the VH, provide objective, quantitative data about the virtual social interaction. We applied this method to a set of previously collected interactions between medical students and VH patients and present preliminary results. The error metrics do not correlate with traditional measures of the quality of a virtual experience, e.g. presence and copresence questionnaires. The error metrics were significantly correlated with scores on the Maastricht Assessment of Simulated Patients (MaSP), a scenario-appropriate measure of simulation quality, suggesting further investigation is warranted."
2010,Stretch-ing Is Great Exercise‚Äî It Gets You in Shape to Win.,"Abstract:
IBM's Project Stretch (1955-1961) lost the company some $35 million big 1960 dollars. Yet the project, a bold adventure into transistorized computers, drove into existence new technologies in circuits, packaging, memory, and I/O upon which IBM built its successful second-generation computer product lines. The architectural, instruction-pipelining, arithmetic, and software innovations were crucial for IBM's third-generation System/360 product family and even for its later RISC innovation."
2010,Matching actual treadmill walking speed and visually perceived walking speed in a projection virtual environment.,"ABSTRACT
When developing our Immersive Virtual Environment Rehabilitation Treadmill (IVERT) system (Figure 1), we observed the well known phenomenon of visuals feeling ""too slow"" compared to walking speed (Durgin 2005). The work reported here was motivated by needing a factor, the optical flow multiplier (OFM), to multiply by the treadmill speed to generate a viewpoint/visual speed that ""felt right"" to the IVERT users. Our most frequent use case will be the therapist setting the treadmill speed and then the program multiplying treadmill speed by the OFM to generate the viewpoint speed."
2010,GUD WIP: Gait-Understanding-Driven Walking-In-Place.,"Many Virtual Environments require walking interfaces to explore virtual worlds much larger than available real-world tracked space. We present a model for generating virtual locomotion speeds from Walking-In-Place (WIP) inputs based on walking biomechanics. By employing gait principles, our model - called Gait-Understanding-Driven Walking-In-Place (GUD WIP) - creates output speeds which better match those evident in Real Walking, and which better respond to variations in step frequency, including realistic starting and stopping. The speeds output by our implementation demonstrate considerably less within-step fluctuation than a good current WIP system - Low-Latency, Continuous-Motion (LLCM) WIP - while still remaining responsive to changes in user input. We compared resulting speeds from Real Walking, GUD WIP, and LLCM-WIP via user study: The average output speeds for Real Walking and GUD WIP respond consistently with changing step frequency - LLCM-WIP is far less consistent. GUD WIP produces output speeds that are more locally consistent (smooth) and step-frequency-to-walk-speed consistent than LLCM-WIP."
2007,MACBETH: Management of Avatar Conflict by Employment of a Technique Hybrid.,"Since virtual objects do not prevent users from penetrating them, a virtual environment user may place his real hand inside a virtual object. If the virtual environment system prevents the user's hand avatar from penetrating the object, the hand avatar must be placed somewhere other than the user's real hand position. I propose a technique, named MACBETH (Management of Avatar Conflict By Employment of a Technique Hybrid) for managing the position of a user's hand avatar in a natural manner after it has been separated from the user's real hand due to collision with a virtual object. This technique balances visual/proprioceptive discrepancy in position and velocity by choosing each so that they are equally detectable.
To gather the necessary information to implement MACBETH, I performed user studies to determine users' detection thresholds for visual/proprioceptive discrepancy in hand position and velocity. I then ran a user study to evaluate MACBETH against two other techniques for managing the hand avatar position: the rubber-band and incremental-motion techniques. Users rated MACBETH as more natural than the other techniques and preferred MACBETH over both. Users performed better on a hand navigation task with MACBETH than with the incremental-motion technique and performed equally well as with the rubber-band technique."
2007,Retrospectives on Peopleware.,"Abstract:
Since its publication twenty years ago, ""Peopleware Productive Projects and Teams"" (Dorset House, 1987), by Tom DeMarco and Tim Lister, has enlightened software professionals and non-professionals alike. Peopleware introduced among other topics - ""team gel"", design patterns, the ""Furniture Police"" - to the software engineering community and suggested that ""sociology matters more than technology or even money."" This unique session with the pioneers of our profession is an opportunity to learn, reflect, and share experiences -- looking forward to the future. This compendium consists of brief bios and first person retrospectives on ""Peopleware""."
2007,Collaboration and telecollaboration in design.,"ABSTRACT
A new characteristic of design in the 20th century is the dominant use of teams to do design. We design with teams both because we are in a hurry and because our creations require more skills than one mind can master. Yet we want our designs to have excellence, and that requires conceptual integrity. Achieving conceptual integrity in team design is then a formidable challenge.
Telecollaboration is now, in the 21st century, not only possible but even fashionable. The mantra of ""telecollaboration"" assumes implicitly that collaboration is a good thing per se. The more one collaborates, the better. This is far from self-evident; it probably is not true. Nevertheless, there are parts of the design process where collaboration not only shares out the work, but also produces a better design. Here telecollaboration can be most fruitful. Analysis of these aspects of design inevitably generates opinions on how design should be done and taught."
2007,"""No silver bullet"" reloaded: retrospective on ""essence and accidents of software engineering"".","ABSTRACT
Twenty years after the paper No Silver Bullet: Essence and Accidents of Software Engineering by Frederick P. Brooks first appeared in IEEE Computer in April 1987 (following its 1986 publication in Information Processing, ISBN 0444-7077-3) does the premise hold that the complexity of software is not accidental? How have the ""hopes for silver"" which included high-level language advances, object-oriented programming, artificial intelligence, expert systems, great designers, etc. - evolved? Panelists will discuss what has changed and/or stayed the same in the past twenty years - and the paper's influence on the community."
2007,MACBETH: The avatar which I see before me and its movement toward my hand.,"Abstract:
When a virtual environment system prevents a user's avatar hand from penetrating virtual objects, the seen and felt positions of the hand separate. We propose a new method for reducing this position discrepancy as quickly as possible without introducing perceptible discrepancy between the seen and felt motion of the user's hand. We performed a user study to compare this new method to two previous methods of dealing with position discrepancy. Our method showed statistically significant improvements in user-reported naturalness and user preference and showed no loss in user performance"
2006,The Hand Is More Easily Fooled than the Eye: Users Are More Sensitive to Visual Interpenetration than to Visual-Proprioceptive Discrepancy.,"A virtual environment (VE) user's avatar may penetrate virtual objects. Some VE designers prevent visual interpenetration, assuming that prevention improves user experience. However, preventing visual avatar interpenetration causes a discrepancy between visual and proprioceptive cues. We investigated users' detection thresh-olds for visual interpenetration and visual-proprioceptive discrepancy and found that users are much less sensitive to visual-proprioceptive discrepancy than to visual interpenetration. We propose using this result to better deal with user penetration of virtual objects.
"
2006,"Perceptual sensitivity to visual/kinesthetic discrepancy in hand speed, and why we might care.","ABSTRACT
We investigated the ability of a user in a head-mounted display virtual environment to detect a virtual hand avatar moving at a speed different than that of the real hand. We measured discrepancy detection thresholds for each of the six cardinal directions of 3-space (left, right, up, down, toward, and away). For each of these six directions we measured two discrepancy detection thresholds: one for when the avatar hand moved more quickly than the real hand and one for when it moved more slowly. We found a trend that users are less sensitive to increases in hand avatar speed than they are to decreases. The amount the hand avatar speed can be increased without a user noticing is surprisingly large. This information is useful for techniques that require introducing hand-avatar motion discrepancy, such as a technique for recovering from the position discrepancy introduced by simulated surface constraints."
2005,The Hand is Slower than the Eye: A Quantitative Exploration of Visual Dominance over Proprioception.,"Without force feedback, a head-mounted display user's avatar may penetrate virtual objects. Some virtual environment designers prevent visual interpenetration, making the assumption that prevention improves user experience. However, preventing visual avatar interpenetration causes discrepancy between visual and proprioceptive cues. We investigated users' detection thresholds for visual interpenetration (the depth at which they see that two objects have interpenetrated) and sensory discrepancy (the displacement at which they notice mismatched visual and proprioceptive cues). We found that users are much less sensitive to visual-proprioceptive conflict than they are to visual interpenetration. We present our plan for using this result to create a better technique for dealing with virtual object penetration."
2005,Comparing VE Locomotion Interfaces.,"To compare and evaluate locomotion interfaces for users who are (virtually) moving on foot in VEs, we performed a study to characterize task behavior and task performance with different visual and locomotion interfaces. In both a computer-generated environment and a corresponding real environment, study participants walked to targets on walls and stopped as close to them as they could without making contact. In each of five experimental conditions participants used a combination of one of three locomotion interfaces (really walking, walking-in-place, and joystick flying), and one of three visual conditions (head-mounted display, unrestricted natural vision, or field-of-view-restricted natural vision). We identified metrics and collected data that captured task performance and the underlying kinematics of the task. Our results show: 1) Over 95% of the variance in simple motion paths is captured in three critical values: peak velocity; when, in the course of a motion, the peak velocity occurs; and peak deceleration. 2) Correlations of those critical value data for the conditions taken pairwise suggest a coarse ordering of locomotion interfaces by ""naturalness."" 3) Task performance varies with interface condition, but correlations of that value for conditions taken pairwise do not cluster by naturalness. 4) The perceptual variable, r (also known as the time-to-contact) calculated at the point of peak deceleration has higher correlation with task performance than r calculated at peak velocity."
2003,Three great challenges for half-century-old computer science.,n/a
2003,Effects of Handling Real Objects and Self-Avatar Fidelity on Cognitive Task Performance and Sense of Presence in Virtual Environments.,"Immersive virtual environments (VEs) provide participants with computer-generated environments filled with virtual objects to assist in learning, training, and practicing dangerous and/or expensive tasks. But does having every object being virtual inhibit the interactivity and level of immersion? If participants spend most of their time and cognitive load on learning and adapting to interacting with virtual objects, does this reduce the effectiveness of the VE?

We conducted a study that investigated how handling real objects and self-avatar visual fidelity affects performance and sense of presence on a spatial cognitive manual task. We compared participants' performance of a block arrangement task in both a real-space environment and several virtual and hybrid environments. The results showed that manipulating real objects in a VE brings task performance closer to that of real space, compared to manipulating virtual objects. There was no signifi-cant difference in reported sense of presence, regardless of the self-avatar's visual fidelity or the presence of real objects.
"
2003,Incorporating dynamic real objects into immersive virtual environments.,"We present algorithms that enable virtual objects to interact with and respond to virtual representations, avatars, of real objects. These techniques allow dynamic real objects, such as the user, tools, and parts, to be visually and physically incorporated into the virtual environment (VE). The system uses image-based object reconstruction and a volume query mechanism to detect collisions and to determine plausible collision responses between virtual objects and the avatars. This allows our system to provide the user natural interactions with the VE.We have begun a collaboration with NASA Langley Research Center to apply the hybrid environment system to a satellite payload assembly verification task. In an informal case study, NASA LaRC payload designers and engineers conducted common assembly tasks on payload models. The results suggest that hybrid environments could provide significant advantages for assembly verification and layout evaluation tasks."
2003,Incorporating dynamic real objects into immersive virtual environments.,"ABSTRACT
We present algorithms that enable virtual objects to interact with and respond to virtual representations, avatars, of real objects. These techniques allow dynamic real objects, such as the user, tools, and parts, to be visually and physically incorporated into the virtual environment (VE). The system uses image-based object reconstruction and a volume query mechanism to detect collisions and to determine plausible collision responses between virtual objects and the avatars. This allows our system to provide the user natural interactions with the VE.We have begun a collaboration with NASA Langley Research Center to apply the hybrid environment system to a satellite payload assembly verification task. In an informal case study, NASA LaRC payload designers and engineers conducted common assembly tasks on payload models. The results suggest that hybrid environments could provide significant advantages for assembly verification and layout evaluation tasks."
2003,Effects of Handling Real Objects and Avatar Fidelity On Cognitive Task Performance in Virtual Environments.,"Immersive virtual environments (VEs) provide participants with computer-generated environments filled with virtual objects to assist in learning, training, and practicing dangerous and/or expensive tasks. But for certain tasks, does having every object being virtual inhibit the interactivity? Further, does the virtual object's visual fidelity affect performance? Overall VE effectiveness may be reduced if users spend most of their time and cognitive capacity learning how to interact and adapting to interacting with a purely virtual environment. We investigated how handling real objects and how self-avatar visual fidelity affects performance on a spatial cognitive task in an immersive VE. We compared participants' performance on a block arrangement task in both a real-space environment and several virtual and hybrid environments. The results showed that manipulating real objects in a VE brings task performance closer to that of real space, compared to manipulating virtual objects."
2003,Effect of Latency on Presence in Stressful Virtual Environments.,"Previous research has shown that even low end-to-end latency can have adverse effects on performance in virtual environments (VE). This paper reports on an experiment investigating the effect of latency on other metrics of VE effectiveness: physiological response, simulator sickness, and self-reported sense of presence. The VE used in the study includes two rooms: the first is normal and non-threatening; the second is designed to evoke a fear/stress response. Participants were assigned to either a low latency (/spl sim/50 ms) or high latency (/spl sim/90 ms) group. Participants in the low latency condition had a higher self-reported sense of presence and a statistically higher change in heart rate between the two rooms than did those in the high latency condition. There were no significant relationships between latency and simulator sickness."
2002,Physiological measures of presence in stressful virtual environments.,"A common measure of the quality or effectiveness of a virtual environment (VE) is the mount of presence it evokes in users. Presence is often defined as the sense of being there in a VE. There has been much debate about the best way to measure presence, and presence researchers need, and have sought, a measure that is reliable, valid, sensitive, and objective.We hypothesized that to the degree that a VE seems real, it would evoke physiological responses similar to those evoked by the corresponding real environment, and that greater presence would evoke a greater response. To examine this, we conducted three experiments, the results of which support the use of physiological reaction as a reliable, valid, sensitive, and objective presence measure. The experiments compared participants' physiological reactions to a non-threatening virtual room and their reactions to a stressful virtual height situation. We found that change in heart rate satisfied our requirements for a measure of presence, change in skin conductance did to a lesser extent, and that change in skin temperature did not. Moreover, the results showed that inclusion of a passive haptic element in the VE significantly increased presence and that for presence evoked: 30FPS > 20FPS > 15FPS.
"
2002,Physiological reaction and presence in stressful virtual environments.,"ABSTRACT
A common metric of VE quality is presence --- the degree to which the user feels like they are in the virtual scene as opposed to the real world. Presence is important for many VE applications [Hodges et al. 1994]. Since presence is a subjective condition, it is most commonly measured by self-reporting, either during the VE experience or immediately afterwards by questionnaires. There is vigorous debate in the literature as to how to best measure presence [Meehan 2001]."
2000,Architecture of the IBM System/360.,"Abstract:
The architecture of the newly announced IBM System/360 features four innovations: 1. An approach to storage which permits and exploits very large capacities, hierarchies of speeds, read-only storage for microprogram control, flexible storage protection, and simple program relocation. 2. An input/output system offering new degrees of concurrent operation, compatible channel operation, data rates approaching 5,000,000 characters/second, integrated design of hardware and software, a new low-cost, multiple-channel package sharing main-frame hardware, new provisions for device status information, and a standard channel interface between central processing unit and input/output devices. 3. A truly general-purpose machine organization offering new supervisor facilities, powerful logical processing operations, and a wide variety of data formats. 4. Strict upward and downward machine-language compatibility over a line of six models having a performance range factor of 50. This paper discusses in detail the objectives of the design and the rationale for the main features of the architecture. Emphasis is given to the problems raised by the need for compatibility among central processing units of various size and by the conflicting demands of commercial, scientific, real-time, and logical information processing. A tabular summary of the architecture is shown in the Appendices."
1999,What's Real About Virtual Reality?,"Abstract:
The author presents a personal assessment of the state of the art of VR. In 1994, he surveyed the field of VR. His assessment then was that VR almost worked, but that we were not yet there. There were lots of demos and pilot systems, but except for vehicle simulators and entertainment applications, VR was not yet in production use doing real work. This year he was invited to do an up-to-date assessment of VR, with funding to visit major centers in North America and Europe. Every one of the component technologies has made big strides. Moreover, I found that there now exist some VR applications routinely operated for the results they produce."
1999,NSF workshop on a software research program for the 21st century.,n/a
1999,MMR: an interactive massive model rendering system using geometric and image-based acceleration.,"We present a system for rendering very complex 3D models at interactive rates. We select a subset of the model as preferred viewpoints and partition the space into virtual cells. Each cell contains near geometry, rendered using levels of detail and visibility culling, and far geometry, rendered as a textured depth mesh. Our system automatically balances the screen-space errors resulting from geometric simplification with those from textureddepth-mesh distortion. We describe our prefetching and data management schemes, both crucial for models significantly larger than available system memory. We have successfully used our system to accelerate walkthroughs of a 13 million triangle model of a large coal-fired power plant and of a 1.7 million triangle architectural model. We demonstrate the walkthrough of a 1.3 GB power plant model with a 140 MB cache footprint."
1999,"Walking > Walking-in-Place > Flying, in Virtual Environments.","A study by Slater, et al., [1995] indicated that naive subjects in an immersive virtual environment experience a higher subjective sense of presence when they locomote by walking-in-place (virtual walking) than when they push-button-fly (along the floor plane). We replicated their study, adding real walking as a third condition. Our study confirmed their findings. We also found that real walking is significantly better than both virtual walking and flying in ease (simplicity, straightforwardness, naturalness) as a mode of locomotion. The greatest difference in subjective presence was between flyers and both kinds of walkers. In addition, subjective presence was higher for real walkers than virtual walkers, but the difference was statistically significant only in some models. Follow-on studies show virtual walking can be substantially improved by detecting footfalls with a head accelerometer. As in the Slater study, subjective presence significantly correlated with subjects' degree of association with their virtual bodies (avatars). This, our strongest statistical result, suggests that substantial potential presence gains can be had from tracking all limbs and customizing avatar appearance. An unexpected by-product was that real walking through our enhanced version of Slater's visual-cliff virtual environment (Figure 1) yielded a strikingly compelling virtual experience - The strongest we and most of our visitors have yet experienced. The most needed system improvement is the substitution of wireless technology for all links to the user"
1999,What's Real about Virtual Reality?,"Ivan Sutherland first proposed virtual reality in 1965, and in the next few years built a working system. Twenty years later, line-drawing hardware, the Polhemus tracker, and LCD tiny-TV displays made VR feasible, if costly and inadequate, for several explorers. In 1990, journalists jumped on the idea, and hype levels went out of sight. As usual with infant technologies, the realization of the early dreams and the harnessing to real work has taken longer than the wild prognostications, but it is now happening. I survey the current state-of-the-art, addressing the perennial questions of technology and applications."
1997,Moving objects in space: exploiting proprioception in virtual-environment interaction.,"Manipulation in immersive virtual environments is difficult partly because users must do without the haptic contact with real objects they rely on in the real world to orient themselves and their manipulanda. To compensate for this lack, we propose exploiting the one real object every user has in a virtual environment, his body. We present a unified framework for virtual-environment interaction based on proprioception, a person's sense of the position and orientation of his body and limbs. We describe three forms of body-relative interaction: ï Direct manipulationóways to use body sense to help control manipulation ï Physical mnemonicsóways to store/recall information relative to the body ï Gestural actionsóways to use body-relative actions to issue commands Automatic scaling is a way to bring objects instantly within reach so that users can manipulate them using proprioceptive cues. Several novel virtual interaction techniques based upon automatic scaling and our proposed framework of proprioception allow a user to interact with a virtual world intuitively, efficiently, precisely, and lazily. We report the results of both informal user trials and formal user studies of the usability of the body-relative interaction techniques presented."
1997,Pearls found on the way to the ideal interface for scanned-probe microscopes.,"Abstract:
Since 1991, our team of computer scientists, chemists and physicists have worked together to develop an advanced, virtual-environment interface to scanned-probe microscopes. The interface has provided insights and useful capabilities well beyond those of the traditional interface. This paper lists the particular visualization and control techniques that have enabled actual scientific discovery, including specific examples of insight gained using each technique. This information can help scientists determine which features are likely to be useful in their particular application, and which would be just sugar coating. It can also guide computer scientists to suggest the appropriate type of interface to help solve a particular problem. We have found benefit in advanced rendering with natural viewpoint control (but not always), from semi-automatic control techniques, from force feedback during manipulation, and from storing/replaying data for an entire experiment. These benefits come when the system is well-integrated into the existing tool and allows export of the data to standard visualization packages."
1996,The Computer Scientist as a Toolsmith II.,n/a
1996,Simplification Envelopes.,"We propose the idea of simplification envelopes for generating a hierarchy of level-of-detail approximations for a given polygonal model. Our approach guarantees that all points of an approximation are within a user-specifiable distance from the original model and that all points of the original model are within a distance from the approximation. Simplificationenvelopes provide a general framework within which a large collection of existing simplification algorithms can run. We demonstrate this technique in conjunction with two algorithms, one local, the other global. The local algorithm provides a fast method for generating approximations to large input meshes (at least hundreds of thousands of triangles). The global algorithm provides the opportunity to avoid local ìminimaî and possibly achieve better simplifications as a result. Each approximation attempts to minimize the total number of polygons required to satisfy the above constraint. The key advantages of our approach are: General technique providing guaranteed error bounds for genus-preserving simplification Automation of both the simplification process and the selection of appropriate viewing distances Prevention of self-intersection Preservation of sharp features Allows variation of approximation distance across different portions of a model"
1995,The Mythical Man-Month: After 20 Years.,"Abstract
A UK consortium has identified the special characteristics of RAD projects and published a first version of a development standard. The three critical success factors are easy access to end users, a stable and skilled development team, and a commercial application."
1995,"Defining, Computing, and Visualizing Molecular Interfaces.","A parallel, analytic approach for defining and computing the inter and intra molecular interfaces in three dimensions is described. The molecular interface surfaces are derived from approximations to the power diagrams over the participating molecular units. For a given molecular interface our approach can generate a family of interface surfaces parametrized by /spl alpha/ and /spl beta/, where /spl alpha/ is the radius of the solvent molecule (also known as the probe radius) and /spl beta/ is the interface radius that defines the size of the molecular interface. Molecular interface surfaces provide biochemists with a powerful tool to study surface complementarity and to efficiently characterize the interactions during a protein substrate docking. The complexity of our algorithm for molecular environments is O(nk log/sup 2/ k), where n is the number of atoms in the participating molecular units and k is the average number of neighboring atoms-a constant, given /spl alpha/ and /spl beta/."
1994,Computing smooth molecular surfaces.,"Abstract:
We consider how we set out to formulate a parallel analytical molecular surface algorithm that has expected linear complexity with respect to the total number of atoms in a molecule. To achieve this goal, we avoided computing the complete 3D regular triangulation over the entire set of atoms, a process that takes time O(n log n), where n is the number of atoms in the molecule. We aim to compute and display these surfaces at interactive rates, by taking advantage of advances in computational geometry, making further algorithmic improvements and parallelizing the computations.< >"
1994,Interactive Visualization of Weighted Three-Dimensional Alpha Hulls.,"ABSTRACT
An interactive visualization of weighted three-dimensional Œ±-hulls is presented for static and dynamic spheres. The Œ±-hull is analytically computed and represented by a triangulated mesh. The entire surface is computed and displayed in real-time at interactive rates. The weighted three-dimensional Œ±-hulls are equivalent to smooth molecular surfaces of biochemistry. Biochemistry applications of interactive computation and display of Œ±-hulls or smooth molecular surfaces are outlined."
1994,Research frontiers in virtual reality.,n/a
1993,VIEW: an exploratory molecular visualization system with user-definable interaction sequences.,"VIEW is an exploratory visualization system for studying the structures of molecules. The system supports a high degree of complex user interaction with the image. Visualizations are constructed by selecting drawing tools from a library. Each tool uses parameters obtained from interactive selection of on-screen geometry by the user, and from a molecular database. The system is based on a tight coupling of on-screen geometry with the underlying database. Using these links, tools can create truescale drawing elements that are constrained to database values. VIEW is highly extensible by the user or a paraprogrammer associated with the user. Drawing tools are written in a C-like programming language with constructs for managing databases, constructs for creating and altering geometry, as well as standard statements such as If-Else and For loops. An event-definition mechanism allows the user to describe actions to be performed when keys are depressed or dials turned. In addition, the user is able to specify conditional events ñ actions that are to be taken whenever a user-defined condition becomes true. These conditions are automatically evaluated by the system as part of event processing. Such conditional events allow simple simulations to be readily programmed. Applications of conditional events have included animations of protein binding activity, and an interactive ìflashlightî which highlights structures as a cursor is steered through a molecule. The system includes a development environment complete with a WYSIWYG editor, an interactive debugger, and a set of innovative graphical debugging features. ____________________ VIEW has been installed for over a year in a protein crystallography laboratory at Duke University. Graduate students and faculty have used the system both for exploring molecular structures and for producing presentation graphics. These users have developed their own set of tools and made extensive use of the tool library. In January 1993, a beta-version of the software was released to a small set of laboratories in the US and Europe. It is now generally available."
1993,The nanomanipulator: a virtual-reality interface for a scanning tunneling microscope.,"We have developed a virtual-reality interface to a scanning tunneling microscope (STM); the resulting system is called the Nanomanipulator. The user interface comprises a stereoscopic color head-mounted display, a force-feedback remote manipulator master station, and a high-performance graphics computer. It provides the illusion of a surface floating in space in front of the user. The user's hand gestures are translated into commands that are sent to the STM in real time; the returned video and haptic signals allow the user to see and feel the surface topography and to control the timing and location of voltage pulses applied between the tip of the STM probe and the sample under study.
My thesis is that a virtual-reality interface is a powerful and effective user interface to an STM--allowing qualitatively different types of experiments to be performed. The success of our investigations using this system demonstrates the validity of the thesis.
We have used the Nanomanipulator to examine various surfaces and to perform surface modification experiments. This investigation has led to new insight into the meaning of certain surface features and into the mechanisms by which voltage pulses change the tip and sample. These insights were the direct results of the real-time visualization and the more interactive nature of our system compared to standard methods.
The key to the success of the Nanomanipulator system is that it provides an intuitive two-way interface to the instrument. Raw data from an STM is not in a format easily understood by a scientist, and the Etch-a-Sketch type of controls required for positioning an STM tip are neither natural nor familiar to a user. The Nanomanipulator system acts as a translator between the instrument and the scientist, allowing the scientist to concentrate on interacting with the surface under study rather than on the computer interface or the STM itself. This system seeks to put the scientists on the surface, in control, while the experiment is happening--thus turning the STM from a remote, batch surface modifier into a real-time, user-guided surface modifier. "
1993,Fast Analytical Computation of Richard's Smooth Molecular Surface.,"An algorithm for rapid computation of Richards's smooth molecular surface is described. The entire surface is computed analytically, triangulated, and displayed at interactive rates. The faster speeds for our program have been achieved by algorithmic improvements, paralleling the computations, and by taking advantage of the special geometrical properties of such surfaces. Our algorithm is easily parallelable and it has a time complexity of O (k log k) over n processors, where n is the number of atoms of the molecule and k is the average number of neighbors per atom.< >"
1990,Towards image realism with interactive update rates in complex virtual building environments.,"ABSTRACT
Two strategies, pre-computation before display and adaptive refinement during display, are used to combine interactivity with high image quality in a virtual building simulation. Pre-computation is used in two ways. The hidden-surface problem is partially solved by automatically pre-computing potentially visible sets of the model for sets of related viewpoints. Rendering only the potentially visible subset associated with the current viewpoint, rather than the entire model, produces significant speedups on real building models. Solutions for the radiosity lighting model are pre-computed for up to twenty different sets of lights. Linear combinations of these solutions can be manipulated in real time. We use adaptive refinement to trade image realism for interactivity as the situation requires. When the user is stationary we replace a coarse model using few polygons with a more detailed model. Image-level linear interpolation smooths the transition between differing levels of image realism."
1990,Feeling and seeing: issues in force display.,"Force display technology works by using mechanical actuators to apply forces to the user, By simulating the physics of the user's virtual world, we compute these forces in real-time, then send them to the actuators so that the user feels them, The force display technology we use in the Sandpaper system is a motor-driven two-degree of freedom joystick (built by Max Behensky and Doug Milliken) . The joystick position is reported to the software, which computes the appropriate forces for the joystick's motors"
1990,Project GROPEHaptic displays for scientific visualization.,"ABSTRACT
We began in 1967 a project to develop a haptic+display for 6-D force fields of interacting protein molecules. We approached it in four stages: a 2-D system, a 3-D system tested with a simple task, a 6-D system tested with a simple task, and a full 6-D molecular docking system, our initial goal. This paper summarizes the entire project---the four systems, the evaluation experiments, the results, and our observations. The molecular docking system results are new.Our principal conclusions are:&bull; Haptic display as an augmentation to visual display can improve perception and understanding both of force fields and of world models populated with impenetrable objects.&bull; Whereas man-machine systems can outperform computer-only systems by orders of magnitude on some problems, haptic-augmented interactive systems seem to give about a two-fold performance improvement over purely graphical interactive systems. Better technology may give somewhat more, but a ten-fold improvement does not seem to be in the cards.&bull; Chemists using GROPE-III can readily reproduce the true docking positions for drugs whose docking is known (but not to them) and can find very good docks for drugs whose true docks are unknown. The present tool promises to yield new chemistry research results; it is being actively used by research chemists.&bull; The most valuable result from using GROPE-III for drug docking is probably the radically improved situation awareness that serious users report. Chemists say they have a new understanding of the details of the receptor site and its force fields, and of why a particular drug docks well or poorly.&bull; We see various scientific/education applications for haptic displays but believe entertainment, not scientific visualization, will drive and pace the technology.&bull; The hardware-software system technology we have used is barely adequate, and our experience sets priorities for future development.&bull; Some unexpected perceptual phenomena were observed. All of these worked for us, not against us."
1989,Force display performs better than visual display in a simple 6-D docking task.,"A simplified docking problem is studied. The user attempts to find the potential-energy minimum in a 6-D space defined by six Hooke's-law springs attached to a manipulable object. This space has no other local minima. A pilot-controlled experiment with seven subjects, twelve trials each, showed that performance with a force display is better (p<0.01) than performance with a visual display alone, and that subjects are able to find the zero-force position more than twice as fast with a force display alone than with a visual display alone. Also described is a way of graphically representing the resultants of a set of forces and torques acting on a body. Even though the experiment shows force display to be more effective, it also shows that the simple 6-D docking task can reliably be done with this visual display alone.< >"
1988,Using a manipulator for force display in molecular docking.,"Abstract:
A real-time molecular docking system is developed that uses an electrically coupled remote manipulator as a force display. The system, which uses integrates interactive computer graphics and high-speed calculation of the interaction forces between a drug and a receptor site in a molecule, is designed to be a tool for molecular scientists. The manipulator is used to generate the forces and torques exerted on the drug molecule when it is aligned with the receptor site by the user's hand. The manipulator serves both as an input device for 6-D manipulation and as an output device for generating forces. Preliminary testing indicates that the system might enhance the biochemist's understanding and performance.< >"
1987,No Silver Bullet - Essence and Accidents of Software Engineering.,n/a
1986,No Silver Bullet - Essence and Accidents of Software Engineering (Invited Paper).,n/a
1986,Walkthrough - a dynamic graphics system for simulating virtual buildings.,"ABSTRACT
As part of our graphics research into virtual worlds, we are building a tool for an architect and his client to use for rapid prototyping of buildings by visually ‚Äúwalking through‚Äù them in order to refine specifications.
Our first prototype simulated the new UNC Computer Science building with some 8000 polygons. BSP-tree software on the Adage Ikonas gave a colored, shaded perspective view every 3-5 seconds while the user moved a cursor in real-time over floorplans shown on the Vector-General 3300.
The current (third) version uses Pixel-Planes to generate 9 updates/second, view images shown 4' x 6' by projector.
Active short- and long-term research questions include speed-up, stereo, a 6-DoF interface with eye-level defaults, and an interactive model-building, model-changing system."
1985,"Fast Spheres, Shadows, Textures, Transparencies, and Image Enhancements in Pixel-Planes.","ABSTRACT
Pixel-planes is a logic-enhanced memory system for raster graphics and imaging. Although each pixel-memory is enhanced with a one-bit ALU, the system's real power comes from a tree of one-bit adders that can evaluate linear expressions Ax+By+C for every pixel (x,y) simultaneously, as fast as the ALUs and the memory circuits can accept the results. We and others have begun to develop a variety of algorithms that exploit this fast linear expression evaluation capability. In this paper we report some of those results. Illustrated in this paper is a sample image from a small working prototype of the Pixel-planes hardware and a variety of images from simulations of a full-scale system. Timing estimates indicate that 30,000 smooth shaded triangles can be generated per second, or 21,000 smooth-shaded and shadowed triangles can be generated per second, or over 25,000 shaded spheres can be generated per second. Image-enhancement by adaptive histogram equalization can be performed within 4 seconds on a 512x512 image."
1985,"Fast spheres, shadows, textures, transparencies, and imgage enhancements in pixel-planes.","ABSTRACT
Pixel-planes is a logic-enhanced memory system for raster graphics and imaging. Although each pixel-memory is enhanced with a one-bit ALU, the system's real power comes from a tree of one-bit adders that can evaluate linear expressions Ax+By+C for every pixel (x,y) simultaneously, as fast as the ALUs and the memory circuits can accept the results. We and others have begun to develop a variety of algorithms that exploit this fast linear expression evaluation capability. In this paper we report some of those results. Illustrated in this paper is a sample image from a small working prototype of the Pixel-planes hardware and a variety of images from simulations of a full-scale system. Timing estimates indicate that 30,000 smooth shaded triangles can be generated per second, or 21,000 smooth-shaded and shadowed triangles can be generated per second, or over 25,000 shaded spheres can be generated per second. Image-enhancement by adaptive histogram equalization can be performed within 4 seconds on a 512x512 image."
1983,"Processor Products-Final Report of the SPREAD Task Group, December 28, 1961.","Abstract:
This report recommends a new (in 1961) family of compatible processors for the IBM product line."
1977,"The Computer ""Scientist"" as Toolsmith-Studies in Interactive Computer Graphics.",n/a
1975,A Course of Study in Computer Hardware Architecture.,"The subject of computer architecture as currently taught in most computer engineering and computer science programs is a mixture of architectural principles, organizational strategies, and implementation techniques. This blurring of the hierarchy of system levels that characterize the structure of a computer has made it very difficult for students ( and. often instructors as well) to determine what were the forces that led to the design decisions they have seen reflected in machines."
1971,"Computer structures: past, present and future (abstract).","ABSTRACT
First, Blaauw's law of the persistence of established technology leads me to predict that both c.p.u. architecture and technology will change little by 1975, and will be surprisingly similar in 1980."
1971,GROPE-1: A Computer Display to the Sense of Feel.,n/a
1970,Computer-Man Communication: Using Graphics in the Instructional Process.,"The ultimate purpose of most information-processing systems is to convey information to the human mind. This is also the purpose of any method of instruction. This chapter is a progress report on a group of experiments and projects at a laboratory, each of which explores a different aspect of the application of computer graphics to instruction. The concept behind all of this is that the human mind can be considered to have many input channels of various bandwidths and impedances. The most effective processes of communicating with the mind will be those that use many channels and low-impedance ones. Recently, computer systems have incorporated graphical display devices and audio answerback devices as additional means of providing information to the user. In Prokop's and Oliver's experiments reported in this chapter, strong effects offering substantial improvement in instructional effectiveness and computer‚Äìman communication are found. These modes of the use of computer graphics appear to be more promising for the college-teaching application than conventional computer-assisted instructions (CAIs), which are found to have weaker effects."
1970,Decision making with computer graphics in an inventory control environment.,"ABSTRACT
Computer-driven displays have long been thought to help decision making. But the justification for using these devices in decision-making has been long on intuition and short on quantitative analysis. To see if this intuition was right, we conducted an experiment."
1969,Introducing computing to smaller colleges and universities - a progress report.,"By technical means that are now routine, computer service for smaller colleges and universities can be provided by remote terminals of a central facility. Access, however, is not enoughóeffective organizational and educational methodology for introducing computing at such institutions must also be developed. The experience of two years with a statewide network involving 41 institutions is discussed. Lessons include the importance of a separate organization representing the small colleges, the necessity for on-campus training for the institutions, the need for some special programming and documentation to support such users, and the development of curriculum by evolutionary means.
"
1969,Evaluation of an interactive display system for teaching numerical analysis.,"ABSTRACT
The purpose of this study was to develop, use, and evaluate an interactive display system for teaching selected topics in elementary numerical analysis. We were interested in giving students a thorough intuitive understanding of the pertinent mathematical functions and in measuring the learning effects of an on-line graphical capability."
1968,"Organizational, financial and political aspects of a three-university computing center.",n/a
1964,Architecture of the IBM System/360.,"Abstract:
The architecture of the newly announced IBM System/360 features four innovations: 1. An approach to storage which permits and exploits very large capacities, hierarchies of speeds, read-only storage for microprogram control, flexible storage protection, and simple program relocation. 2. An input/output system offering new degrees of concurrent operation, compatible channel operation, data rates approaching 5,000,000 characters/second, integrated design of hardware and software, a new low-cost, multiple-channel package sharing main-frame hardware, new provisions for device status information, and a standard channel interface between central processing unit and input/output devices. 3. A truly general-purpose machine organization offering new supervisor facilities, powerful logical processing operations, and a wide variety of data formats. 4. Strict upward and downward machine-language compatibility over a line of six models having a performance range factor of 50. This paper discusses in detail the objectives of the design and the rationale for the main features of the architecture. Emphasis is given to the problems raised by the need for compatibility among central processing units of various size and by the conflicting demands of commercial, scientific, real-time, and logical information processing. A tabular summary of the architecture is shown in the Appendices."
1964,The Structure of SYSTEM/360 Part I: Outline of the Logical Structure.,"Abstract:
In the SYSTEM/36O logical structure, processing efficiency and versatility are served by multiple accumulators, binary addressing, bit-manipulation operations, automatic indexing, fixed and variable field lengths, decimal and hexadecimal radices, and floating-point as well as fixed-point arithmetic. The provisions for program interruption, storage protection, and flexible CPU states contribute to effective operation. Base-register addressing, the standard interface between channels and input/output control units, and the machine-language compatibility among models contribute to flexible configurations and to orderly system expansion."
1960,The Execute Operations-A Fourth Mode of Instruction Sequencing.,n/a
1959,Processing Data in Bits and Pieces.,"A data-handling unit is described which permits binary or decimal arithmetic to be performed on data fields of any length from one to sixty-four bits. Within the field, character structure can be further specified: these processing entities, called bytes, may be from one to eight bits long. Fields may be stored with or without algebraic sign. On all operations, the relative offset or shift between the operand from memory and that from the accumulator can be specified. Besides the arithmetic operations, three new logical instructions allow any of the sixteen logical connectives of two variables to operate upon each pair of bits in the memory and accumulator operands. The variable field length, variable byte-size features, extend the use of connective operations to a surprisingly wide variety of logical, house-keeping, and editing tasks. These arithmetic and connective instructions are general and powerful programming tools which greatly simplify complex manipulations. Programming of typical tasks, with both the new instructions and with the instruction set of a conventionally-organized computer, has shown that the new set requires substantially fewer instructions to be written, stored, and executed. Furthermore, the new instruction set has considerably fewer distinct operations than the more conventional set. This is possible because the general-purpose instructions of the new set replace many ad hoc instructions which deal with pieces of instructions or data words, or which perform shifting, packing, or editing functions. The initial application of the variable field length data-processing unit is in the IBM Stretch computer."
1959,Processing data in bits and pieces.,"A data-handling unit is described which permits binary or decimal arithmetic to be performed on data fields of any length from one to sixty-four bits. Within the field, character structure can be further specified: these processing entities, called bytes, may be from one to eight bits long. Fields may be stored with or without algebraic sign. On all operations, the relative offset or shift between the operand from memory and that from the accumulator can be specified. Besides the arithmetic operations, three new logical instructions allow any of the sixteen logical connectives of two variables to operate upon each pair of bits in the memory and accumulator operands. The variable field length, variable byte-size features, extend the use of connective operations to a surprisingly wide variety of logical, house-keeping, and editing tasks. These arithmetic and connective instructions are general and powerful programming tools which greatly simplify complex manipulations. Programming of typical tasks, with both the new instructions and with the instruction set of a conventionally-organized computer, has shown that the new set requires substantially fewer instructions to be written, stored, and executed. Furthermore, the new instruction set has considerably fewer distinct operations than the more conventional set. This is possible because the general-purpose instructions of the new set replace many ad hoc instructions which deal with pieces of instructions or data words, or which perform shifting, packing, or editing functions. The initial application of the variable field length data-processing unit is in the IBM Stretch computer."
1957,An experiment in musical composition.,"Abstract:
The high-order probabilities of element sequences can be determined from a sample of linear structures and can be used for synthesis of new structures. From theoretical considerations one can identify the qualitative conditions for satisfactory output. The theoretical concepts can be tested and quantitative parameters determined by experiment. Such an experiment has been performed by analyzing written music and by testing the analysis through the synthesis of new musical compositions, using a digital computer. A sample of 37 melodies was analyzed for the probabilities of the elements, element pairs (digrams), trigrams, and so on to the eighth order. The tables derived were used for the synthesis of original melodies by a random process. The theory and the experimental verification are considered in detail. The experimental results presented include comparative statistics of the successful syntheses using each of the eight orders of analysis, examples of melodies generated by low, medium, and high-order synthesis, and confirmation of degeneracy and other effects predicted by the theory."
