2009,A grounding framework.,"Abstract
In order for an agent to achieve its objectives, make sound decisions, communicate and collaborate with others effectively it must have high quality representations. Representations can encapsulate objects, situations, experiences, decisions and behavior just to name a few. Our interest is in designing high quality representations, therefore it makes sense to ask of any representation; what does it represent; why is it represented; how is it represented; and importantly how well is it represented. This paper identifies the need to develop a better understanding of the grounding process as key to answering these important questions. The lack of a comprehensive understanding of grounding is a major obstacle in the quest to develop genuinely intelligent systems that can make their own representations as they seek to achieve their objectives. We develop an innovative framework which provides a powerful tool for describing, dissecting and inspecting grounding capabilities with the necessary flexibility to conduct meaningful and insightful analysis and evaluation. The framework is based on a set of clearly articulated principles and has three main applications. First, it can be used at both theoretical and practical levels to analyze grounding capabilities of a single system and to evaluate its performance. Second, it can be used to conduct comparative analysis and evaluation of grounding capabilities across a set of systems. Third, it offers a practical guide to assist the design and construction of high performance systems with effective grounding capabilities."
2008,The well-designed child.,"Abstract
This article is inspired by recent psychological studies confirming that a child is not born a blank slate but has important innate capabilities. An important part of the “learning” required to deal with the three-dimensional world of objects, processes, and other beings was done by evolution. Each child need not do this learning itself. By the 1950s there were already proposals to advance artificial intelligence by building a child machine that would learn from experience just as a human child does. What innate knowledge the child machine should be equipped with was ignored. I suppose the child machine was supposed to be a blank slate. Whatever innate knowledge a human baby may possess, we are interested in a well-designed that has all we can give it. To some extent, this paper is an exercise in wishful thinking. The innate mental structure that equips a child to interact successfully with the world includes more than the universal grammar of linguistic syntax postulated by Noam Chomsky. The world itself has structures, and nature has evolved brains with ways of recognizing them and representing information about them. For example, objects continue to exist when not being perceived, and children (and dogs) are very likely “designed” to interpret sensory inputs in terms of such persistent objects. Moreover, objects usually move continuously, passing through intermediate points, and perceiving motion that way may also be innate. What a child learns about the world is based on its innate mental structure. This article concerns designing adequate mental structures including a language of thought. This designer stance applies to designing robots, but we also hope it will help understand universal human mental structures. We consider what structures would be useful and how the innateness of a few of the structures might be tested experimentally in humans and animals. In the course of its existence we'll want our robot child to change. Some of the changes will be development, others learning. However, this article mainly takes a static view, because we don't know how to treat growth and development and can do only a little with learning."
2007,From here to human-level AI.,"Abstract
Human-level AI will be achieved, but new ideas are almost certainly needed, so a date cannot be reliably predicted—maybe five years, maybe five hundred years. I'd be inclined to bet on this 21st century.
It is not surprising that human-level AI has proved difficult and progress has been slow—though there has been important progress. The slowness and the demand to exploit what has been discovered has led many to mistakenly redefine AI, sometimes in ways that preclude human-level AI—by relegating to humans parts of the task that human-level computer programs would have to do. In the terminology of this paper, it amounts to settling for a bounded informatic situation instead of the more general common sense informatic situation.
Overcoming the “brittleness” of present AI systems and reaching human-level AI requires programs that deal with the common sense informatic situation—in which the phenomena to be taken into account in achieving a goal are not fixed in advance.
We discuss reaching human-level AI, emphasizing logical AI and especially emphasizing representation problems of information and of reasoning. Ideas for reasoning in the common sense informatic situation include nonmonotonic reasoning, approximate concepts, formalized contexts and introspection."
2007,In Honor of Marvin Minsky's Contributions on his 80th Birthday.,"Abstract
Marvin Lee Minsky, a founder of the field of artificial intelligence and professor at MIT, celebrated his 80th birthday on August 9, 2007. This article seizes an opportune time to honor Marvin and his contributions and influence in artificial intelligence, science, and beyond. The article provides readers with some personal insights of Minsky from Danny Hillis, John McCarthy, Tom Mitchell, Erik Mueller, Doug Riecken, Aaron Sloman, and Patrick Henry Winston -- all members of the AI community that Minsky helped to found. The article continues with a brief resume of Minsky's research, which spans an enormous range of fields. It concludes with a short biographical account of Minsky's personal history."
2007,Elephant 2000: a programming language based on speech acts.,"ABSTRACT
Elephant 2000 is a proposed programming language good for writing and verifying programs that interact with people (e.g., transaction processing) or interact with programs belonging to other organizations (e.g., electronic data interchange). Communication inputs and outputs are in an I/O language whose sentences are meaningful speech acts identified in the language as questions, answers, offers, acceptances, declinations, requests, permissions, and promises. The correctness of programs is partly defined in terms of proper performance of the speech acts. Answers should be truthful and responsive, and promises should be kept. Sentences of logic expressing these forms of correctness can be generated automatically from the form of the program.
Elephant source programs may not need data structures, because they can refer directly to the past. Thus a program can say that an airline passenger has a reservation if he has made one and hasn't cancelled it. Elephant programs themselves can be represented as sentences of logic. Their extensional properties follow from this representation without an intervening theory of programming or anything like Hoare axioms.
Elephant programs that interact non-trivially with the outside world can have both input-output specifications, relating the programs inputs and outputs, and accomplishment specifications concerning what the program accomplishes in the world. These concepts are respectively generalizations of the philosophers' illocutionary and perlocutionary speech acts.
Programs that engage in commercial transactions assume obligations on behalf of their owners in exchange for obligations assumed by other entities. It may be part of the specifications of an Elephant 2000 program that these obligations are exchanged as intended, and this too can be expressed by a logical sentence.
Human speech acts involve intelligence. Elephant 2000 is on the borderline of AI, but the talk emphasizes the Elephant usages that do not require AI."
2006,"Jon Doyle, Extending Mechanics to Minds: The Mechanical Foundations of Psychology and Economics, Cambridge University Press (2006).",n/a
2006,"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955.","Abstract
The 1956 Dartmouth summer research project on artificial intelligence was initiated by this August 31, 1955 proposal, authored by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon. The original typescript consisted of 17 pages plus a title page. Copies of the typescript are housed in the archives at Dartmouth College and Stanford University. The first 5 papers state the proposal, and the remaining pages give qualifications and interests of the four who proposed the study. In the interest of brevity, this article reproduces only the proposal itself, along with the short autobiographical statements of the proposers."
2006,Did Something Go Wrong?,"The premise of this symposium seems to be that something went wrong with AI. Otherwise things would be better. What would be better isn't stated. From my point of view what would have been decisively better is to have achieved human-level AI. However, I suspect some people of being disappointed that the AI companies didn't make enough money."
2006,Challenges to Machine Learning: Relations Between Reality and Appearance.,"Abstract
Machine learning research, e.g. as described in [4], has as its goal the discovery of relations among observations, i.e. appearances. This is inadequate for science, because there is a reality behind appearance, e.g. material objects are built up from atoms. Atoms are just as real as dogs, only harder to observe, and the atomic theory arose long before there was any idea of how big atoms were. This article discusses how atoms were discovered, as an example of discovering the reality behind appearance. We also present an example of the three-dimensional reality behind a two-dimensional appearance, and how that reality is inferred by people and might be inferred by computer programs. Unfortunately, it is necessary to discuss the philosophy of appearance and reality, because the mistaken philosophy of taking the world (or particular phenomena) as a structure of sense data has been harmful in artificial intelligence and machine learning research, just as behaviorism and logical positivism harmed psychology."
2005,The Future of AI - A Manifesto.,"Abstract
The long-term goal of AI is human-level AI. This is still not directly definable, although we still know of human abilities that even the the best present programs on the fastest computers have not been able to emulate, such as playing master-level go and learning science from the Internet. Basic researchers in AI should measure their work as to the extent to which it advances this goal."
2004,The Tower of Stanford: 10956.,n/a
2004,"Historical Remarks on Nonmonotonic Reasoning, Especially Circumscription.","Humanshave always done nonmonotonic reasoning, but rigorous monotonic reasoning in reaching given conclusions has been deservedly more respected and admired. Euclid contains the first extended monotonically reasoned text available to a large public. I suspect that even Euclid did nonmonotonic reasoning in arguing for the postulates. It is unfortunate that the rigorous monotonic reasoning of Euclid has been deemphasized in education, because Euclid generates in people who are not mathematically minded a respect for rigor. Conclusions derived by monotonic logical reasoning from precisely stated premises have always been the ideal. When people jump to conclusions, they are criticized for the gaps in their reasoning, because the conclusions are not guaranteed to follow from the premises. Worse yet, the premises are often unstated. The inability to base all conclusions on logical reasoning from precise and agreed premises has been long noted. There are two main reactions. One is to try to develop other principles of reasoning, and the other is to abandon logic — a big mistake."
2004,"The Web - Early Visions, Present Reality, the Grander Future.",
2003,2003 AAAI Spring Symposium Series.,"Abstract
The Association for the Advancement of Artificial Intelligence, in cooperation with Stanford University's Department of Computer Science, presented the 2003 Spring Symposium Series, Monday through Wednesday, 24-26 March 2003, at Stanford University. The titles of the eight symposia were Agent-Mediated Knowledge Management, Computational Synthesis: From Basic Building Blocks to High- Level Functions, Foundations and Applications of Spatiotemporal Reasoning (FASTR), Human Interaction with Autonomous Systems in Complex Environments, Intelligent Multimedia Knowledge Management, Logical Formalization of Commonsense Reasoning, Natural Language Generation in Spoken and Written Dialogue, and New Directions in Question-Answering Motivation."
2003,Problems and projections in CS for the next 49 year.,n/a
2003,Varieties of Contexts.,"Abstract
We believe that a deeper understanding of the uses of contexts, in terms of its impact on knowledge representation structures, as reflected by a corpus of examples, is vital to the programme of formalizing contexts in Artificial Intelligence. In this paper, we examine a number of examples from the literature from the perspective of identifying general usage patterns. We identify four important varieties of contexts — Projection Contexts, Approximation Contexts, Ambiguity Contexts and Mental State Contexts. We define each type, describe sub-types, list benchmark examples of each sub-type, discuss their practical uses and the requirements they make of the underlying logic. We pay particular attention to the problem of lifting, i.e., of using information obtained from one context in another and describe how these different varieties of contexts tend to require different kinds of lifting rules."
2003,Advice about logical AI.,"Abstract:
Formalized nonmonotonic reasoning emerged in relation to the study of artificial intelligence. The paper discusses some uses of nonmonotonic reasoning that has become a mathematical subject, observations regarding AI, and the problems logical AI encountered before it can reach human level intelligence."
2002,An architecture of diversity for commonsense reasoning.,n/a
2002,Problem 10956.,n/a
2002,Actions and Other Events in Situation Calculus.,n/a
2001,Phenomenal data-mining.,"ABSTRACT
Phenomenal data mining finds relations between the data and the phenomena that give rise to data rather than just relations among the data..Science and common sense both tell us that the facts about the world are not directly observable but can be inferred from observations about the effects of actions. What people infer about the world is not just relations among observations but relations among entities that are much more stable than observations. For example, 3-dimensional objects are more stable than the image on a person's retina, the information directly obtained from feeling an object or on an image scanned into a computer..This talk concerns what can be inferred by programs about phenomena from data and what facts are relevant to doing this. In order to infer phenomena from data, facts about their relations must be supplied. Sometimes these facts can be implicit in the programs that look for the phenomena, but more generality is achieved if the facts are represented as sentences of logic in a knowledge base used by the programs..Creating knowledge bases containing both common sense knowledge and knowledge of the domain of the data will be a lot of work. This is unavoidable..The result of phenomenal data-mining can include an extended database with additional fields on existing relations and new relations. Thus the relations describing supermarket baskets can be extended with a customer field, and new relations about customers and their properties can be introduced.."
2000,"Review: M. Shanahan, Solving the Frame Problem.",n/a
2000,Deep issues: phenomenal data mining.,n/a
2000,Free will - even for robots.,n/a
2000,Phenomenal Data Mining: From Data to Phenomena.,n/a
2000,Approximate Objects and Approximate Theories.,n/a
1999,Useful Counterfactuals.,n/a
1998,Combining Narratives.,n/a
1997,"Modality, Si! Modal Logic, No!",n/a
1996,What Computers Still Can't Do.,n/a
1996,From Here to Human-Level AI.,n/a
1995,What has AI in Common with Philosophy?,n/a
1995,Making Robots Conscious of Their Mental States.,n/a
1993,History of Circumscription.,n/a
1993,Notes on Formalizing Context.,n/a
1992,The beginnings at MIT.,n/a
1992,Arthur Samuel: Pioneer in Machine Learning.,"Abstract:
Professor Emeritus Arthur L. Samuel died July 29, 1990, in Stanford, california at the age of 89. He was a pioneer of artificial intelligence research whose life spanned a broad personal and scientific history."
1991,Arthur L. Samuel: Pioneer in Machine Learning.,n/a
1990,In Memoriam: Arthur Samuel - Pioneer in Machine Learning.,"Abstract
Arthur Samuel (1901-1990) was a pioneer of artificial intelligence research. From 1949 through the late 1960s, he did the best work in making computers learn from their expe-rience. His vehicle for this work was the game of checkers."
1990,Lessons from the Lighthill Flap.,n/a
1989,The Fruitfly on the Fly.,n/a
1987,Generality in Artificial Intelligence.,n/a
1986,Applications of Circumscription to Formalizing Common-Sense Knowledge.,"Abstract
We present a new and more symmetric version of the circumscription method of non-monotonic reasoning first described by McCarthy [9] and some applications to formalizing common-sense knowledge. The applications in this paper are mostly based on minimizing the abnormality of different aspects of various entities. Included are non-monotonic treatments of “is-a” hierarchies, the unique names hypothesis, and the frame problem. The new circumscription may be called formula circumscription to distinguish it from the previously defined domain circumscription and predicate circumscription. A still more general formalism called prioritized circumscription is briefly explored."
1986,Mental Situation Calculus.,n/a
1985,What is Common Sense and How to Formalize it? (Condensed Slides).,n/a
1984,We Need Better Standards for Artificial Intelligence Research - President's Message.,"Abstract
If we had better standards for evaluating research results in AI the field would progress faster."
1984,Queue-based Multi-processing Lisp.,n/a
1984,Applications of Circumscription to Formalizing Common Sense Knowledge.,n/a
1983,Artificial Intelligence Needs More Emphasis on Basic Research - President's Quarterly Message.,"Abstract
Too few people are doing basic research in AI relative to the number working on applications. The ratio of basic/applied is less in AI than in the older sciences and than in computer science generally. This is unfortunate, because reaching human level artificial intelligence will require fundamental conceptual advances."
1980,Circumscription - A Form of Non-Monotonic Reasoning.,"Abstract
Humans and intelligent computer programs must often jump to the conclusion that the objects they can determine to have certain properties or relations are the only objects that do. Circumscription formalizes such conjectural reasoning."
1980,Addendum: Circumscription and other Non-Monotonic Formalisms.,n/a
1980,Research in Progress in Robotics at Stanford University.,"Abstract
The Robotics Project (the ""Hand-Eye Project"") evolved within the Stanford Artificial Intelligence Laboratory under the guidance of John McCarthy, Les Earnest, Jerry Feldman, and Tom Binford. Major efforts have been undertaken to isolate and solve fundamental problems in computer vision, manipulation, and autonomous vehicles. Generalized cones were introduced for modeling the geometry of 3-dimensional objects, and programs were constructed which learned structural descriptions of objects from laser-ranging data (""structured light""). Stereo vision and texture have been examined. Several generations of robot programming languages have resulted in AL, an intermediate-level language for commanding manipulation. A computer-controlled roving vehicle (""the cart"") detected obstacles (using 9-eyed stereo) and planned paths to avoid them."
1979,First Order Programming Logic.,"ABSTRACT
First Order Programming Logic is a simple, yet powerful formal system for reasoning about recursive programs. In its simplest form, it has one major limitation: it cannot establish any property of the least fixed point of a recursive program which is false for some other fixed point. To rectify this weakness, we present two intuitively distinct approaches to strengthening First Order Programming Logic and prove that either extension makes the logic relatively complete. In the process, we prove that the two approaches are formally equivalent. The relative completeness of the extended logic is significant because it suggests it can establish all ""ordinary"" properties (obviously we cannot escape the Godelian incompleteness inherent in any programming logic) of recursive programs including those which compute partial functions.The second contribution of this paper is to establish that First Order Programming Logic is applicable to iterative programs as well. In particular, we show that the intermittent assertions method--an informal proof method for iterative programs which has not been formalized--is conveniently formalized simply as sugared First Order Programming Logic applied to the recursive translations of iterative programs."
1978,Recursive programs as functions in a first order theory.,"Abstract
Pure Lisp style recursive function programs are represented in a new way by sentences and schemata of first order logic. This permits easy and natural proofs of extensional properties of such programs by methods that generalize structural induction. It also systematizes known methods such as recursion induction, subgoal induction, inductive assertions by interpreting them as first order axiom schemata. We discuss the metatheorems justifying the representation and techniques for proving facts about specific programs. We also give a simpler version of the Gödel-Kleene way of representing computable functions by first order sentences.
Robert Cartwright's current address is Department of Computer Science, Upson Hall, Cornell University, Ithaca, NY 14853. John McCarthy's current address is Department of Computer Science, Stanford University, Stanford, CA 94305."
1977,Knowledge Representation.,n/a
1977,Epistemological Problems of Artificial Intelligence.,n/a
1976,Computer power and human reason.,n/a
1976,Stanford University low overhead timesharing.,"ABSTRACT
No abstract available."
1974,"Professor Sir James Lighthill, FRS. Artificial Intelligence: A General Survey.",n/a
1967,Comments on time sharing.,n/a
1967,THOR: a display based time sharing system.,"ABSTRACT
THOR is a time sharing system for the PDP-1 computer with the capacity to run twenty user programs. The system has twenty-eight user consoles, twelve of which are combination keyboard and cathode ray tube display consoles. THOR is designed to capitalize on the display's ability to present large quantities of information quickly and to mitigate the fact that hard copy is not available at display consoles. The other sixteen consoles are Model 33 teletypes with the attendant slow presentation of information and the availability of hard copy. Because there are more consoles than user programs available, a user program may use more than one console."
1963,Revised report on the algorithm language ALGOL 60.,n/a
1963,The linking segment subprogram language and linking loader.,n/a
1963,Revised report on the algorithmic language ALGOL 60.,n/a
1962,Towards a Mathematical Science of Computation.,n/a
1960,"Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I.",n/a
1960,Report on the algorithmic language ALGOL 60.,n/a
