1994,Differential-Linear Cryptanalysis.,"Abstract
This paper introduces a new chosen text attack on iterated cryptosystems, such as the Data Encryption Standard (DES). The attack is very efficient for 8-round DES,2 recovering 10 bits of key with 80% probability of success using only 512 chosen plaintexts. The probability of success increases to 95% using 768 chosen plaintexts. More key can be recovered with reduced probability of success. The attack takes less than 10 seconds on a SUN-4 workstation. While comparable in speed to existing attacks, this 8-round attack represents an order of magnitude improvement in the amount of required text."
1992,Responses to NIST's Proposal.,n/a
1988,Time-memory-processor trade-offs.,"Abstract:
It is demonstrated that usual time-memory trade-offs offer no asymptotic advantage over exhaustive search. Instead, trade-offs between time, memory, and parallel processing are proposed. Using this approach it is shown that most searching problems allow a trade-off between C/sub s/, the cost per solution, and C/sub m/, the cost of the machine: doubling C/sub m/ increases the solution rate by a factor of four, halving C/sub s/. The machine which achieves this has an unusual architecture, with a number of processors sharing a large memory through a sorting/switching network. The implications of cryptanalysis, the knapsack problem, and multiple encryption are discussed.< >"
1987,Chosen-Key Attacks on a Block Cipher.,"This paper presents a new attack on a block cipher, which is stronger than all previously considered attacks. This “chosen-key attack” is a generalization of the well accepted chosen-text attack. We give an example of a block cipher which is strong under a chosen-text attack, but immediately vulnerable to a chosen-key attack. A general chosen-key attack breaks an n bit key cipher in 2 n/2 operations. A black-box argument shows that this is the best possible for general attacks.
"
1983,On secret sharing systems.,"Abstract:
A ""secret sharing system"" permits a secret to be shared among n trustees in such a way that any k of them can recover the secret, but any k-1 have complete uncertainty about it. A linear coding scheme for secret sharing is exhibited which subsumes the polynomial interpolation method proposed by Shamir and can also be viewed as a deterministic version of Blakley's probabilistic method. Bounds on the maximum value of n for a given k and secret size are derived for any system, linear or nonlinear. The proposed scheme achieves the lower bound which, for practical purposes, differs insignificantly from the upper bound. The scheme may be extended to protect several secrets. Methods to protect against deliberate tampering by any of the trustees are also presented."
1983,The largest super-increasing subset of a random set.,"Abstract:
It is shown that the longest super-increasing sequence which can be constructed from a set of n independent uniformly distributed random variables is almost surely asymptotic to \log_{2}n . Some extensions of this result, as well as the implications for the security of knapsack-based cryptographic systems, are discussed."
1982,Cryptographic Key Size Issues.,n/a
1982,Fast Computation of Discrete Logarithms in GF(q).,"Abstract
The Merkte-Adleman algorithm computes discrete logarithms in GF (q),the finite field with q elements, in subexponential time, when q is a prime number p. This paper shows that similar asymptotic behavior can be obtained for the logarithm problem when q = p m , in the case that m grows with p fixed. A method of partial precomputation, applicable to either problem, is also presented. The precomputation is particularly useful when many logarithms need to be computed for fixed values of p and m."
1982,Drainage and the DES.,"Abstract
In our paper, we investigate a statistical property of random functions we named drainage. (Definitions for drainage, random function, etc. will be given shortly.) Our motivation for doing so is twofold. First, it generally assumed that a good cryptographic system will exhibit no simple statistical regularity. For example, the function from key to ciphertext when a block cipher is used to encode a fixed plaintext should appear to be completely random. We were therefore interested in studying the behavior of drainage for a random function, and then comparing it to the measured behavior for a real cryptosystem, the DES. Secondly, drainage is closely related to statistical properties which are important to the performance of the generalized cryptanalytic attack proposed by Hellman [1], discussed below."
1981,On the Security of Multiple Encryption.,"Double encryption has been suggested to strengthen the Federal Data Encryption Standard (DES). A recent proposal suggests that using two 56-bit keys but enciphering 3 times (encrypt with a first key, decrypt with a second key, then encrypt with the first key again) increases security over simple double encryption. This paper shows that although either technique significantly improves security over single encryption, the new technique does not significantly increase security over simple double encryption. Cryptanalysis of the 112-bit key requires about 256 operations and words of memory, using a chosen plaintext attack. While DES is used as an example, the technique is applicable to any similar cipher.
"
1981,Another Cryptanalytic Attack on 'A Cryptosystem for Multiple Communication'.,n/a
1981,On the Necessity of Exhaustive Search for System-Invariant Cryptanalysis.,n/a
1981,Time-Memory-Processor Tradeoffs.,n/a
1980,A cryptanalytic time-memory trade-off.,"Abstract:
A probabilistic method is presented which cryptanalyzes any N key cryptosystem in N^{2/3} operational with N^{2/3} words of memory (average values) after a precomputation which requires N operations. If the precomputation can be performed in a reasonable time period (e.g, several years), the additional computation required to recover each key compares very favorably with the N operations required by an exhaustive search and the N words of memory required by table lookup. When applied to the Data Encryption Standard (DES) used in block mode, it indicates that solutions should cost between 1 and 100 each. The method works in a chosen plaintext attack and, if cipher block chaining is not used, can also be used in a ciphertext-only attack."
1980,On the Difficulty of Computing Logarithms Over GF(qm).,n/a
1979,Convolutional encoding for Wyner's wiretap channel (Corresp.).,"Abstract:
The wiretap channel introduced by Wyner is studied for the special case when the main channel is a noiseless binary channel and the wiretap channel is a binary symmetric channel. With a rate-one convolutional encoder, the steady-state uncertainty of the wiretapper is shown to depend only on the constraint length v of the code, not on the specific taps, and is complete on k successive bits provided k\leq v . During the initial transient period, the rate of growth of uncertainty does depend on the tap connections of the shift register."
1978,An improved algorithm for computing logarithms over GF(p) and its cryptographic significance (Corresp.).,"Abstract:
A cryptographic system is described which is secure if and only if computing logarithms over GF(p) is infeasible. Previously published algorithms for computing this function require O(p^{1/2}) complexity in both time and space. An improved algorithm is derived which requires O =(\log^{2} p) complexity if p - 1 has only small prime factors. Such values of p must be avoided in the cryptosystem. Constructive uses for the new algorithm are also described."
1978,The Gaussian wire-tap channel.,"Abstract:
Wyner's results for discrete memoryless wire-tap channels are extended to the Gaussian wire-tap channel. It is shown that the secrecy capacity Cs is the difference between the capacities of the main and wire.tap channels. It is further shown that Rd= Cs is the upper boundary of the achievable rate-equivocation region."
1978,Hiding information and signatures in trapdoor knapsacks.,"Abstract:
The knapsack problem is an NP-complete combinatorial problem that is strongly believed to be computationally difficult to solve in general. Specific instances of this problem that appear very difficult to solve unless one possesses ""trapdoor information"" used in the design of the problem are demonstrated. Because only the designer can easily solve problems, others can send him information hidden in the solution to the problems without fear that an eavesdropper will be able to extract the information. This approach differs from usual cryptographic systems in that a secret key is not needed. Conversely, only the designer can generate signatures for messages, but anyone can easily check their authenticity."
1978,Security in communication networks.,n/a
1977,Special Feature Exhaustive Cryptanalysis of the NBS Data Encryption Standard.,"Abstract:
For centuries, cryptography has been a valuable asset of the military and diplomatic communities. Indeed, it is so valuable that its practice has usually been shrouded in secrecy and mystery."
1977,An extension of the Shannon theory approach to cryptography.,"Abstract:
Shannon's information-theoretic approach to cryptography is reviewed and extended. It is shown that Shannon's random cipher model is conservative in that a randomly chosen cipher is essentially the worst possible. This is in contrast with error-correcting codes where a randomly chosen code is essentially the best possible. The concepts of matching a cipher to a language and of the trade-off between local and global uncertainty are also developed."
1977,A note on Wyner's wiretap channel (Corresp.).,"Abstract:
Wyner recently introduced the concept of a wiretap channel and showed that by transmitting at a rate less than capacity on the main link it was possible to keep the wiretapper's information about the entire message equal to zero. It is shown that it is possible to send at capacity on the main link and still keep the wiretapper's information equal to zero on many, large, arbitrary portions of the message."
1976,Optimal Finite Memory Learning Algorithms for the Finite Sample Problem.,This paper explores the structure and performance of optimal finite state machines used to test between two simple hypotheses. It is shown that time-invariant algorithms can use knowledge of the sample size to obtain lower error rates than in the infinite sample problem. The existence of an optimal rule is established and its structure is found for optimal time-varying algorithms. The structure of optimal time-invariant rules is partially established. The particular problem of testing between two Gaussian distributions differing only by a shift is then examined. It is shown that the minimal error rate achievable after N samples goes to zero like exp[âˆ’(ln N)1/2].
1976,Concerning a bound on undetected error probability (Corresp.).,"Abstract:
In the past, it has generally been assumed that the probability of undetected error for an (n,k) block code, used solely for error detection on a binary symmetric channel, is upperbounded by 2^{-(n-k)} . In this correspondence, it is shown that Hamming codes do indeed obey this bound, but that the bound is violated by some more general codes. Examples of linear, cyclic, and Bose-Chaudhuri-Hocquenghem (BCH) codes which do not obey the bound are given."
1976,New directions in cryptography.,"Abstract:
Two kinds of contemporary developments in cryptography are examined. Widening applications of teleprocessing have given rise to a need for new types of cryptographic systems, which minimize the need for secure key distribution channels and supply the equivalent of a written signature. This paper suggests ways to solve these currently open problems. It also discusses how the theories of communication and computation are beginning to provide the tools to solve cryptographic problems of long standing."
1976,Multiuser cryptographic techniques.,"This paper deals with new problems which arise in the application of cryptography to computer communication systems with large numbers of users. Foremost among these is the key distribution problem. We suggest two techniques for dealing with this problem. The first employs current technology and requires subversion of several separate key distribution nodes to compromise the system's security. Its disadvantage is a high overhead for single message connections. The second technique is still in the conceptual phase, but promises to eliminate completely the need for a secure key distribution channel, by making the sender's keying information public. It is also shown how such a public key cryptosystem would allow the development of an authentication system which generates an unforgeable, message dependent digital signature.
"
1975,On tree coding with a fidelity criterion.,"Abstract:
This paper reexamines Jelinek's proof that tree codes can be used to approach the rate-distortion bound. It is shown that the branching process used in Jelinek's proof is not a (strict-sense) branching process (SSBP) when the source is asymmetric. Branching processes with random environments (BPWRE) are introduced and used to extend the proof to general discrete-time memoryless sources. The theory developed indicates why a particular metric used in experiments performed better than another suggested by the original proof."
1975,Convolutional source encoding.,"Abstract:
In certain communications problems, such as remote telemetry, it is important that any operations performed at the transmitter be of a simple nature, while operations performed at the receiver can frequently be orders of magnitude more complex. Channel coding is well matched to such situations while conventional source coding is not. To overcome this difficulty of usual source coding, we propose using a convolutional encoder for joint source and channel encoding. When the channel is noiseless this scheme reduces to a convolutional source code that is simpler to encode than any other optimal noiseless source code known to date. In either case, decoding can be a minor variation on sequential decoding."
1974,Finite-memory algorithms for estimating the mean of a Gaussian distribution (Corresp.).,"Abstract:
Let \{X_n\}_{n=1}^{\infty} be independent random variables, each having a \mathcal{N}(\mu, \sigma^2) distribution. If we try to estimate \mu with an m -state learning algorithm, then the minimum mean-squared error is bounded below by that obtained by the best m -level quantizer (which requires knowledge of \mu ). Here we show that this lower bound is tight. The results are easily extended to a number of other problems, such as estimating the mean \theta of a uniform distribution."
1972,Hypothesis testing with finite memory in finite time (Corresp.).,"Abstract:
The hypothesis-testing problem has recently been studied under a finite-memory constraint. However, most work has been concerned with the large-sample theory. Here we study the small-sample theory for binary-valued observations."
1972,The effects of randomization on finite-memory decision schemes.,"Abstract:
This paper is concerned with the differences between deterministic and randomized finite-memory decision rules. It is shown that for any hypothesis-testing problem there exists a b < \infty such that, for any B , the optimal deterministic rule with B + b bits in memory has a lower error probability than the optimal randomized rule with B bits in memory. Suboptimal deterministic rules with this property are demonstrated. These deterministic rules lose at most b bits. Thus for large memories the fraction of memory, measured in bits, lost by deterministic rules is negligible."
1972,A confidence model for finite-memory learning systems (Corresp.).,"Abstract:
A confidence model for finite-memory learning systems is advanced in this correspondence. The primary difference between this and the previously used probability-of-error model is that a measure of confidence is associated with each decision and any incorrect decisions are weighted according to their confidence measure in figuring total loss. The optimal rule for this model is deterministic, whereas the previous model required randomized rules to achieve minimum error probability."
1970,The two-armed-bandit problem with time-invariant finite memory.,"Abstract:
This paper solves the classical two-armed-bandit problem under the finite-memory constraint described below. Given are probability densities p_0 and p_1 , and two experiments A and B . It is not known which density is associated with which experiment. Thus the experimental outcome Y of experiment A is as likely to be distributed according to p_0 as it is to be distributed according to p_1 . It is desired to sequentially choose an experiment to be performed on the basis of past observations according to the algorithm T_n = f(T_{n-1}, e_n, Y_n), e_n = e(T_{n-1}) , where T_n \in \{1, 2, \cdots, m\} is the state of memory at time n, e_n \in \{A, B\} is the choice of experiment, and Y_n , is the random variable observation. The goal is to maximize the asymptotic proportion r of uses of the experiment associated with density p_0 . Let l(y) = p_0 (y) / p_1 (y) , and let \bar{l} and \bar{\bar{l}} denote the almost everywhere greatest lower bound and least upper bound on l(y) . Let 1 = \max {\bar{\bar{l}}, 1/\bar{l}} . Then the optimal value of r , over all m -state algorithms (f, e) , will be shown to be l^{m-1} / (l^{m-1} + 1) . An e -optimal family of m -state algorithms will be demonstrated. In general, optimal algorithms do not exist, and e -optimal algorithms require artificial randomization."
1970,"Probability of error, equivocation, and the Chernoff bound.","Abstract:
Relationships between the probability of error, the equivocation, and the Chernoff bound are examined for the two-hypothesis decision problem. The effect of rejections on these bounds is derived. Finally, the results are extended to the case of any finite number of hypotheses."
1970,Finite-memory hypothesis testing-Comments on a critique (Corresp.).,"The hypothesis-testing problem has recently been studied under a finite-memory constraint. However, most work has been concerned with the large-sample theory. Here we study the small-sample theory for binary-valued observations."
1970,The Nearest Neighbor Classification Rule with a Reject Option.,"Abstract:
An observation comes from one of two possible classes. If all the statistics of the problem are known, Bayes' classification scheme yields the minimum probability of error. If, instead, the statistics are not known and one is given only a labeled training set, it is known that the nearest neighbor rule has an asymptotic error no greater than twice that of Bayes' rule. Here the (k,k') nearest neighbor rule with a reject option is examined. This rule looks at the k nearest neighbors and rejects if less than k' of these are from the same class; if k' or more are from one class, a decision is made in favor of that class. The error rate of such a rule is bounded in terms of the Bayes' error rate."
